bb0 at src/mm/ucontext.rs:182:13: 182:22
bb1 at src/mm/ucontext.rs:183:13: 183:27
bb3 at src/mm/ucontext.rs:183:54: 183:55
bb5 at src/mm/ucontext.rs:183:30: 183:55
bb6 at src/mm/ucontext.rs:183:54: 183:55
bb7 at src/mm/ucontext.rs:183:54: 183:55
bb8 at src/mm/ucontext.rs:184:29: 184:43
bb9 at src/mm/ucontext.rs:184:29: 184:43
bb10 at src/mm/ucontext.rs:184:50: 184:51
bb11 at src/mm/ucontext.rs:188:64: 188:65
bb12 at src/mm/ucontext.rs:188:41: 188:74
bb13 at src/mm/ucontext.rs:188:91: 188:92
bb14 at src/mm/ucontext.rs:188:21: 188:22
bb15 at src/mm/ucontext.rs:192:68: 192:69
bb16 at src/mm/ucontext.rs:192:17: 192:18
bb17 at src/mm/ucontext.rs:192:9: 192:36
bb18 at src/mm/ucontext.rs:192:9: 192:36
bb19 at src/mm/ucontext.rs:195:17: 195:18
bb20 at src/mm/ucontext.rs:196:17: 196:18
bb21 at src/mm/ucontext.rs:197:17: 197:18
bb22 at src/mm/ucontext.rs:198:17: 198:18
bb23 at src/mm/ucontext.rs:199:17: 199:18
bb24 at src/mm/ucontext.rs:200:17: 200:18
bb25 at src/mm/ucontext.rs:201:17: 201:18
bb26 at src/mm/ucontext.rs:202:17: 202:18
bb27 at src/mm/ucontext.rs:203:17: 203:18
bb28 at src/mm/ucontext.rs:207:44: 207:45
bb29 at src/mm/ucontext.rs:207:44: 207:45
bb30 at src/mm/ucontext.rs:207:20: 207:45
bb31 at src/mm/ucontext.rs:207:44: 207:45
bb32 at src/mm/ucontext.rs:207:13: 207:16
bb33 at src/mm/ucontext.rs:207:9: 279:10
bb34 at src/mm/ucontext.rs:208:29: 208:32
bb35 at src/mm/ucontext.rs:208:46: 208:47
bb36 at src/mm/ucontext.rs:211:16: 211:25
bb37 at src/mm/ucontext.rs:211:16: 211:36
bb39 at src/mm/ucontext.rs:211:66: 211:67
bb40 at src/mm/ucontext.rs:212:31: 212:32
bb41 at src/mm/ucontext.rs:211:66: 211:67
bb42 at src/mm/ucontext.rs:216:28: 216:37
bb43 at src/mm/ucontext.rs:216:47: 216:48
bb44 at src/mm/ucontext.rs:217:65: 217:66
bb45 at src/mm/ucontext.rs:218:27: 218:36
bb46 at src/mm/ucontext.rs:218:44: 218:45
bb47 at src/mm/ucontext.rs:219:30: 219:39
bb48 at src/mm/ucontext.rs:219:46: 219:47
bb49 at src/mm/ucontext.rs:222:42: 222:51
bb50 at src/mm/ucontext.rs:222:68: 222:69
bb51 at src/mm/ucontext.rs:222:69: 222:70
bb52 at src/mm/ucontext.rs:223:21: 223:22
bb53 at src/mm/ucontext.rs:223:58: 223:59
bb54 at src/mm/ucontext.rs:223:59: 223:60
bb55 at src/mm/ucontext.rs:226:43: 226:44
bb56 at src/mm/ucontext.rs:227:39: 227:40
bb57 at src/mm/ucontext.rs:231:43: 231:44
bb58 at src/mm/ucontext.rs:234:13: 275:14
bb59 at src/mm/ucontext.rs:234:19: 234:42
bb61 at src/mm/ucontext.rs:234:41: 234:42
bb62 at src/mm/ucontext.rs:235:88: 235:89
bb63 at src/mm/ucontext.rs:235:30: 235:39
bb64 at src/mm/ucontext.rs:240:32: 242:43
bb65 at src/mm/ucontext.rs:240:32: 241:79
bb68 at src/mm/ucontext.rs:242:42: 242:43
bb70 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:42: 137:43
bb71 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:54: 137:73
bb73 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:72: 137:73
bb74 at src/mm/ucontext.rs:245:64: 245:93
bb75 at src/mm/ucontext.rs:245:64: 245:93
bb76 at src/mm/ucontext.rs:245:102: 245:103
bb77 at src/mm/ucontext.rs:244:72: 244:73
bb78 at src/mm/ucontext.rs:244:85: 244:86
bb79 at src/mm/ucontext.rs:244:121: 244:122
bb80 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:140:61: 140:62
bb81 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:142:67: 142:95
bb82 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:144:13: 144:14
bb83 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:144:14: 144:15
bb84 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:72: 137:73
bb85 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:42: 137:43
bb86 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:145:10: 145:10
bb87 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:145:9: 145:10
bb89 at src/mm/ucontext.rs:242:42: 242:43
bb90 at src/mm/ucontext.rs:246:29: 246:30
bb91 at src/mm/ucontext.rs:250:33: 250:42
bb92 at src/mm/ucontext.rs:250:71: 250:72
bb94 at src/mm/ucontext.rs:253:52: 253:53
bb95 at src/mm/ucontext.rs:254:94: 254:95
bb96 at src/mm/ucontext.rs:254:45: 254:50
bb97 at src/mm/ucontext.rs:255:49: 255:50
bb98 at src/mm/ucontext.rs:256:34: 256:34
bb99 at src/mm/ucontext.rs:253:52: 253:53
bb100 at src/mm/ucontext.rs:257:29: 257:30
bb101 at src/mm/ucontext.rs:260:32: 261:78
bb104 at src/mm/ucontext.rs:262:42: 262:43
bb106 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:42: 137:43
bb107 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:54: 137:73
bb109 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:72: 137:73
bb110 at src/mm/ucontext.rs:265:64: 265:93
bb111 at src/mm/ucontext.rs:265:64: 265:93
bb112 at src/mm/ucontext.rs:265:102: 265:103
bb113 at src/mm/ucontext.rs:264:69: 264:70
bb114 at src/mm/ucontext.rs:264:82: 264:83
bb115 at src/mm/ucontext.rs:264:118: 264:119
bb116 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:140:61: 140:62
bb117 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:142:67: 142:95
bb118 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:144:13: 144:14
bb119 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:144:14: 144:15
bb120 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:72: 137:73
bb121 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:42: 137:43
bb122 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:145:10: 145:10
bb123 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:145:9: 145:10
bb125 at src/mm/ucontext.rs:262:42: 262:43
bb126 at src/mm/ucontext.rs:266:29: 266:30
bb127 at src/mm/ucontext.rs:267:25: 267:26
bb128 at src/mm/ucontext.rs:269:45: 269:63
bb129 at src/mm/ucontext.rs:269:78: 269:79
bb130 at src/mm/ucontext.rs:269:37: 269:41
bb131 at src/mm/ucontext.rs:270:29: 270:33
bb132 at src/mm/ucontext.rs:270:29: 270:49
bb133 at src/mm/ucontext.rs:270:29: 270:49
bb134 at src/mm/ucontext.rs:270:75: 270:76
bb135 at src/mm/ucontext.rs:270:76: 270:77
bb136 at src/mm/ucontext.rs:270:77: 270:78
bb137 at src/mm/ucontext.rs:271:26: 271:26
bb138 at src/mm/ucontext.rs:271:25: 271:26
bb139 at src/mm/ucontext.rs:273:18: 273:18
bb140 at src/mm/ucontext.rs:273:17: 273:18
bb141 at src/mm/ucontext.rs:274:64: 274:65
bb142 at src/mm/ucontext.rs:274:46: 274:85
bb143 at src/mm/ucontext.rs:274:85: 274:86
bb144 at src/mm/ucontext.rs:234:41: 234:42
bb145 at src/mm/ucontext.rs:276:36: 276:37
bb146 at src/mm/ucontext.rs:278:27: 278:28
bb147 at src/mm/ucontext.rs:279:9: 279:10
bb148 at src/mm/ucontext.rs:281:23: 281:24
bb149 at src/mm/ucontext.rs:282:23: 282:24
bb150 at src/mm/ucontext.rs:284:5: 284:6
bb151 at src/mm/ucontext.rs:284:5: 284:6
bb161 at src/mm/ucontext.rs:257:29: 257:30
bb162 at src/mm/ucontext.rs:273:17: 273:18
bb164 at src/mm/ucontext.rs:273:17: 273:18
bb165 at src/mm/ucontext.rs:257:29: 257:30
bb174 at src/mm/ucontext.rs:183:55: 183:56
fn mm::ucontext::InnerAddressSpace::try_clone
_0:  @ core::result::Result<alloc::sync::Arc<mm::ucontext::AddressSpace, alloc::alloc::Global>, system_error::SystemError> 
_1:  @ &'{erased} mut mm::ucontext::InnerAddressSpace 
_2:  @ ! 
_3:  @ exception::IrqFlagsGuard 
_4:  @ alloc::sync::Arc<mm::ucontext::AddressSpace, alloc::alloc::Global> 
_5:  @ core::ops::ControlFlow<core::result::Result<core::convert::Infallible, system_error::SystemError>, alloc::sync::Arc<mm::ucontext::AddressSpace, alloc::alloc::Global>> 
_6:  @ core::result::Result<alloc::sync::Arc<mm::ucontext::AddressSpace, alloc::alloc::Global>, system_error::SystemError> 
_7:  @ isize 
_8:  @ core::result::Result<core::convert::Infallible, system_error::SystemError> 
_9:  @ ! 
_10:  @ core::result::Result<core::convert::Infallible, system_error::SystemError> 
_11:  @ alloc::sync::Arc<mm::ucontext::AddressSpace, alloc::alloc::Global> 
_12:  @ libs::rwlock::RwLockWriteGuard<'{erased}, mm::ucontext::InnerAddressSpace> 
_13:  @ &'{erased} libs::rwlock::RwLock<mm::ucontext::InnerAddressSpace> 
_14:  @ &'{erased} libs::rwlock::RwLock<mm::ucontext::InnerAddressSpace> 
_15:  @ &'{erased} mm::ucontext::AddressSpace 
_16:  @ &'{erased} mm::ucontext::AddressSpace 
_17:  @ &'{erased} alloc::sync::Arc<mm::ucontext::AddressSpace, alloc::alloc::Global> 
_18:  @ () 
_19:  @ core::option::Option<mm::ucontext::UserStack> 
_20:  @ mm::ucontext::UserStack 
_21:  @ &'{erased} mm::ucontext::UserStack 
_22:  @ &'{erased} mm::ucontext::UserStack 
_23:  @ core::option::Option<&'{erased} mm::ucontext::UserStack> 
_24:  @ &'{erased} core::option::Option<mm::ucontext::UserStack> 
_25:  @ &'{erased} mut mm::ucontext::InnerAddressSpace 
_26:  @ &'{erased} mut libs::rwlock::RwLockWriteGuard<'{erased}, mm::ucontext::InnerAddressSpace> 
_27:  @ alloc::collections::BTreeMap<mm::VirtAddr, usize, alloc::alloc::Global> 
_28:  @ &'{erased} alloc::collections::BTreeMap<mm::VirtAddr, usize, alloc::alloc::Global> 
_29:  @ &'{erased} mut mm::ucontext::InnerAddressSpace 
_30:  @ &'{erased} mut libs::rwlock::RwLockWriteGuard<'{erased}, mm::ucontext::InnerAddressSpace> 
_31:  @ mm::VirtAddr 
_32:  @ &'{erased} mut mm::ucontext::InnerAddressSpace 
_33:  @ &'{erased} mut libs::rwlock::RwLockWriteGuard<'{erased}, mm::ucontext::InnerAddressSpace> 
_34:  @ mm::VirtAddr 
_35:  @ &'{erased} mut mm::ucontext::InnerAddressSpace 
_36:  @ &'{erased} mut libs::rwlock::RwLockWriteGuard<'{erased}, mm::ucontext::InnerAddressSpace> 
_37:  @ mm::VirtAddr 
_38:  @ &'{erased} mut mm::ucontext::InnerAddressSpace 
_39:  @ &'{erased} mut libs::rwlock::RwLockWriteGuard<'{erased}, mm::ucontext::InnerAddressSpace> 
_40:  @ mm::VirtAddr 
_41:  @ &'{erased} mut mm::ucontext::InnerAddressSpace 
_42:  @ &'{erased} mut libs::rwlock::RwLockWriteGuard<'{erased}, mm::ucontext::InnerAddressSpace> 
_43:  @ mm::VirtAddr 
_44:  @ &'{erased} mut mm::ucontext::InnerAddressSpace 
_45:  @ &'{erased} mut libs::rwlock::RwLockWriteGuard<'{erased}, mm::ucontext::InnerAddressSpace> 
_46:  @ mm::VirtAddr 
_47:  @ &'{erased} mut mm::ucontext::InnerAddressSpace 
_48:  @ &'{erased} mut libs::rwlock::RwLockWriteGuard<'{erased}, mm::ucontext::InnerAddressSpace> 
_49:  @ mm::VirtAddr 
_50:  @ &'{erased} mut mm::ucontext::InnerAddressSpace 
_51:  @ &'{erased} mut libs::rwlock::RwLockWriteGuard<'{erased}, mm::ucontext::InnerAddressSpace> 
_52:  @ mm::VirtAddr 
_53:  @ &'{erased} mut mm::ucontext::InnerAddressSpace 
_54:  @ &'{erased} mut libs::rwlock::RwLockWriteGuard<'{erased}, mm::ucontext::InnerAddressSpace> 
_55:  @ mm::VirtAddr 
_56:  @ &'{erased} mut mm::ucontext::InnerAddressSpace 
_57:  @ &'{erased} mut libs::rwlock::RwLockWriteGuard<'{erased}, mm::ucontext::InnerAddressSpace> 
_58:  @ () 
_59:  @ hashbrown::hash_set::Iter<'{erased}, alloc::sync::Arc<mm::ucontext::LockedVMA, alloc::alloc::Global>> 
_60:  @ hashbrown::hash_set::Iter<'{erased}, alloc::sync::Arc<mm::ucontext::LockedVMA, alloc::alloc::Global>> 
_61:  @ &'{erased} hashbrown::HashSet<alloc::sync::Arc<mm::ucontext::LockedVMA, alloc::alloc::Global>, core::hash::BuildHasherDefault<ahash::fallback_hash::AHasher>, hashbrown::raw::alloc::inner::Global> 
_62:  @ hashbrown::hash_set::Iter<'{erased}, alloc::sync::Arc<mm::ucontext::LockedVMA, alloc::alloc::Global>> 
_63:  @ () 
_64:  @ () 
_65:  @ core::option::Option<&'{erased} alloc::sync::Arc<mm::ucontext::LockedVMA, alloc::alloc::Global>> 
_66:  @ &'{erased} mut hashbrown::hash_set::Iter<'{erased}, alloc::sync::Arc<mm::ucontext::LockedVMA, alloc::alloc::Global>> 
_67:  @ &'{erased} mut hashbrown::hash_set::Iter<'{erased}, alloc::sync::Arc<mm::ucontext::LockedVMA, alloc::alloc::Global>> 
_68:  @ isize 
_69:  @ ! 
_70:  @ &'{erased} alloc::sync::Arc<mm::ucontext::LockedVMA, alloc::alloc::Global> 
_71:  @ libs::spinlock::SpinLockGuard<'{erased}, mm::ucontext::VMA> 
_72:  @ &'{erased} mm::ucontext::LockedVMA 
_73:  @ &'{erased} mm::ucontext::LockedVMA 
_74:  @ &'{erased} alloc::sync::Arc<mm::ucontext::LockedVMA, alloc::alloc::Global> 
_75:  @ () 
_76:  @ bool 
_77:  @ &'{erased} mm::VmFlags 
_78:  @ &'{erased} mm::VmFlags 
_79:  @ &'{erased} mm::ucontext::VMA 
_80:  @ &'{erased} mm::ucontext::VMA 
_81:  @ &'{erased} libs::spinlock::SpinLockGuard<'{erased}, mm::ucontext::VMA> 
_82:  @ ! 
_83:  @ () 
_84:  @ libs::spinlock::SpinLockGuard<'{erased}, mm::ucontext::VMA> 
_85:  @ &'{erased} mm::VmFlags 
_86:  @ &'{erased} mm::ucontext::VMA 
_87:  @ &'{erased} mm::ucontext::VMA 
_88:  @ &'{erased} libs::spinlock::SpinLockGuard<'{erased}, mm::ucontext::VMA> 
_89:  @ bool 
_90:  @ &'{erased} mm::VmFlags 
_91:  @ mm::VirtRegion 
_92:  @ &'{erased} mm::VirtRegion 
_93:  @ &'{erased} mm::ucontext::VMA 
_94:  @ &'{erased} mm::ucontext::VMA 
_95:  @ &'{erased} libs::spinlock::SpinLockGuard<'{erased}, mm::ucontext::VMA> 
_96:  @ mm::page::EntryFlags<arch::x86_64::mm::X86_64MMArch> 
_97:  @ &'{erased} mm::ucontext::VMA 
_98:  @ &'{erased} mm::ucontext::VMA 
_99:  @ &'{erased} libs::spinlock::SpinLockGuard<'{erased}, mm::ucontext::VMA> 
_100:  @ alloc::sync::Arc<mm::ucontext::LockedVMA, alloc::alloc::Global> 
_101:  @ mm::ucontext::VMA 
_102:  @ &'{erased} mm::ucontext::VMA 
_103:  @ &'{erased} mm::ucontext::VMA 
_104:  @ &'{erased} libs::spinlock::SpinLockGuard<'{erased}, mm::ucontext::VMA> 
_105:  @ bool 
_106:  @ &'{erased} mut hashbrown::HashSet<alloc::sync::Arc<mm::ucontext::LockedVMA, alloc::alloc::Global>, core::hash::BuildHasherDefault<ahash::fallback_hash::AHasher>, hashbrown::raw::alloc::inner::Global> 
_107:  @ &'{erased} mut mm::ucontext::InnerAddressSpace 
_108:  @ &'{erased} mut libs::rwlock::RwLockWriteGuard<'{erased}, mm::ucontext::InnerAddressSpace> 
_109:  @ alloc::sync::Arc<mm::ucontext::LockedVMA, alloc::alloc::Global> 
_110:  @ &'{erased} alloc::sync::Arc<mm::ucontext::LockedVMA, alloc::alloc::Global> 
_111:  @ mm::VirtAddr 
_112:  @ &'{erased} mm::VirtRegion 
_113:  @ mm::VirtAddr 
_114:  @ &'{erased} mm::VirtRegion 
_115:  @ mm::VirtAddr 
_116:  @ &'{erased} mut mm::page::PageMapper<arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator> 
_117:  @ &'{erased} mut mm::page::PageMapper<arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator> 
_118:  @ &'{erased} mut mm::ucontext::InnerAddressSpace 
_119:  @ &'{erased} mut libs::rwlock::RwLockWriteGuard<'{erased}, mm::ucontext::InnerAddressSpace> 
_120:  @ libs::spinlock::SpinLockGuard<'{erased}, mm::page::PageManager> 
_121:  @ () 
_122:  @ bool 
_123:  @ &'{erased} mm::VirtAddr 
_124:  @ &'{erased} mm::VirtAddr 
_125:  @ () 
_126:  @ core::option::Option<(mm::PhysAddr, mm::page::EntryFlags<arch::x86_64::mm::X86_64MMArch>)> 
_127:  @ &'{erased} mm::page::PageMapper<arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator> 
_128:  @ mm::VirtAddr 
_129:  @ isize 
_130:  @ mm::PhysAddr 
_131:  @ mm::page::EntryFlags<arch::x86_64::mm::X86_64MMArch> 
_132:  @ () 
_133:  @ bool 
_134:  @ bool 
_135:  @ &'{erased} core::option::Option<mm::page::PageFlush<arch::x86_64::mm::X86_64MMArch>> 
_136:  @ core::option::Option<mm::page::PageFlush<arch::x86_64::mm::X86_64MMArch>> 
_137:  @ &'{erased} mut mm::page::PageMapper<arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator> 
_138:  @ mm::VirtAddr 
_139:  @ mm::PhysAddr 
_140:  @ mm::page::EntryFlags<arch::x86_64::mm::X86_64MMArch> 
_141:  @ () 
_142:  @ log::Level 
_143:  @ bool 
_144:  @ &'{erased} log::Level 
_145:  @ &'{erased} log::LevelFilter 
_146:  @ log::LevelFilter 
_147:  @ bool 
_148:  @ &'{erased} log::Level 
_149:  @ &'{erased} log::LevelFilter 
_150:  @ log::LevelFilter 
_151:  @ () 
_152:  @ log::__private_api::GlobalLogger 
_153:  @ core::fmt::Arguments<'{erased}> 
_154:  @ (&'{erased} mm::VirtAddr, &'{erased} mm::PhysAddr, &'{erased} process::RawPid) 
_155:  @ &'{erased} mm::VirtAddr 
_156:  @ &'{erased} mm::PhysAddr 
_157:  @ &'{erased} process::RawPid 
_158:  @ process::RawPid 
_159:  @ &'{erased} process::ProcessControlBlock 
_160:  @ &'{erased} process::ProcessControlBlock 
_161:  @ &'{erased} alloc::sync::Arc<process::ProcessControlBlock, alloc::alloc::Global> 
_162:  @ alloc::sync::Arc<process::ProcessControlBlock, alloc::alloc::Global> 
_163:  @ [core::fmt::rt::Argument<'{erased}>; 3_usize] 
_164:  @ core::fmt::rt::Argument<'{erased}> 
_165:  @ &'{erased} mm::VirtAddr 
_166:  @ core::fmt::rt::Argument<'{erased}> 
_167:  @ &'{erased} mm::PhysAddr 
_168:  @ core::fmt::rt::Argument<'{erased}> 
_169:  @ &'{erased} process::RawPid 
_170:  @ &'{erased} [&'{erased} str; 4_usize] 
_171:  @ &'{erased} [&'{erased} str; 4_usize] 
_172:  @ [&'{erased} str; 4_usize] 
_173:  @ &'{erased} [core::fmt::rt::Argument<'{erased}>; 3_usize] 
_174:  @ &'{erased} [core::fmt::rt::Argument<'{erased}>; 3_usize] 
_175:  @ log::Level 
_176:  @ &'{erased} (&'{erased} str, &'{erased} str, &'{erased} core::panic::Location<'{erased}>) 
_177:  @ &'{erased} (&'{erased} str, &'{erased} str, &'{erased} core::panic::Location<'{erased}>) 
_178:  @ (&'{erased} str, &'{erased} str, &'{erased} core::panic::Location<'{erased}>) 
_179:  @ &'{erased} str 
_180:  @ &'{erased} str 
_181:  @ &'{erased} core::panic::Location<'{erased}> 
_182:  @ &'{erased} core::panic::Location<'{erased}> 
_183:  @ () 
_184:  @ mm::page::EntryFlags<arch::x86_64::mm::X86_64MMArch> 
_185:  @ mm::page::EntryFlags<arch::x86_64::mm::X86_64MMArch> 
_186:  @ () 
_187:  @ bool 
_188:  @ &'{erased} mm::page::EntryFlags<arch::x86_64::mm::X86_64MMArch> 
_189:  @ core::option::Option<mm::page::PageFlush<arch::x86_64::mm::X86_64MMArch>> 
_190:  @ &'{erased} mut mm::page::PageMapper<arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator> 
_191:  @ mm::VirtAddr 
_192:  @ mm::page::EntryFlags<arch::x86_64::mm::X86_64MMArch> 
_193:  @ isize 
_194:  @ mm::page::PageFlush<arch::x86_64::mm::X86_64MMArch> 
_195:  @ () 
_196:  @ mm::page::PageFlush<arch::x86_64::mm::X86_64MMArch> 
_197:  @ bool 
_198:  @ &'{erased} core::option::Option<mm::page::PageFlush<arch::x86_64::mm::X86_64MMArch>> 
_199:  @ core::option::Option<mm::page::PageFlush<arch::x86_64::mm::X86_64MMArch>> 
_200:  @ &'{erased} mut mm::page::PageMapper<arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator> 
_201:  @ mm::VirtAddr 
_202:  @ mm::PhysAddr 
_203:  @ mm::page::EntryFlags<arch::x86_64::mm::X86_64MMArch> 
_204:  @ () 
_205:  @ log::Level 
_206:  @ bool 
_207:  @ &'{erased} log::Level 
_208:  @ &'{erased} log::LevelFilter 
_209:  @ log::LevelFilter 
_210:  @ bool 
_211:  @ &'{erased} log::Level 
_212:  @ &'{erased} log::LevelFilter 
_213:  @ log::LevelFilter 
_214:  @ () 
_215:  @ log::__private_api::GlobalLogger 
_216:  @ core::fmt::Arguments<'{erased}> 
_217:  @ (&'{erased} mm::VirtAddr, &'{erased} mm::PhysAddr, &'{erased} process::RawPid) 
_218:  @ &'{erased} mm::VirtAddr 
_219:  @ &'{erased} mm::PhysAddr 
_220:  @ &'{erased} process::RawPid 
_221:  @ process::RawPid 
_222:  @ &'{erased} process::ProcessControlBlock 
_223:  @ &'{erased} process::ProcessControlBlock 
_224:  @ &'{erased} alloc::sync::Arc<process::ProcessControlBlock, alloc::alloc::Global> 
_225:  @ alloc::sync::Arc<process::ProcessControlBlock, alloc::alloc::Global> 
_226:  @ [core::fmt::rt::Argument<'{erased}>; 3_usize] 
_227:  @ core::fmt::rt::Argument<'{erased}> 
_228:  @ &'{erased} mm::VirtAddr 
_229:  @ core::fmt::rt::Argument<'{erased}> 
_230:  @ &'{erased} mm::PhysAddr 
_231:  @ core::fmt::rt::Argument<'{erased}> 
_232:  @ &'{erased} process::RawPid 
_233:  @ &'{erased} [&'{erased} str; 4_usize] 
_234:  @ &'{erased} [&'{erased} str; 4_usize] 
_235:  @ [&'{erased} str; 4_usize] 
_236:  @ &'{erased} [core::fmt::rt::Argument<'{erased}>; 3_usize] 
_237:  @ &'{erased} [core::fmt::rt::Argument<'{erased}>; 3_usize] 
_238:  @ log::Level 
_239:  @ &'{erased} (&'{erased} str, &'{erased} str, &'{erased} core::panic::Location<'{erased}>) 
_240:  @ &'{erased} (&'{erased} str, &'{erased} str, &'{erased} core::panic::Location<'{erased}>) 
_241:  @ (&'{erased} str, &'{erased} str, &'{erased} core::panic::Location<'{erased}>) 
_242:  @ &'{erased} str 
_243:  @ &'{erased} str 
_244:  @ &'{erased} core::panic::Location<'{erased}> 
_245:  @ &'{erased} core::panic::Location<'{erased}> 
_246:  @ () 
_247:  @ core::option::Option<alloc::sync::Arc<mm::page::Page, alloc::alloc::Global>> 
_248:  @ &'{erased} mut mm::page::PageManager 
_249:  @ &'{erased} mut mm::page::PageManager 
_250:  @ &'{erased} mut libs::spinlock::SpinLockGuard<'{erased}, mm::page::PageManager> 
_251:  @ &'{erased} mm::PhysAddr 
_252:  @ &'{erased} mm::PhysAddr 
_253:  @ isize 
_254:  @ alloc::sync::Arc<mm::page::Page, alloc::alloc::Global> 
_255:  @ () 
_256:  @ &'{erased} mut mm::page::InnerPage 
_257:  @ &'{erased} mut mm::page::InnerPage 
_258:  @ &'{erased} mut libs::rwlock::RwLockWriteGuard<'{erased}, mm::page::InnerPage> 
_259:  @ libs::rwlock::RwLockWriteGuard<'{erased}, mm::page::InnerPage> 
_260:  @ &'{erased} mm::page::Page 
_261:  @ &'{erased} mm::page::Page 
_262:  @ &'{erased} alloc::sync::Arc<mm::page::Page, alloc::alloc::Global> 
_263:  @ alloc::sync::Arc<mm::ucontext::LockedVMA, alloc::alloc::Global> 
_264:  @ &'{erased} alloc::sync::Arc<mm::ucontext::LockedVMA, alloc::alloc::Global> 
_265:  @ mm::VirtAddr 
_266:  @ usize 
_267:  @ usize 
_268:  @ &'{erased} mm::VirtAddr 
_269:  @ (usize, bool) 
_270:  @ ! 
_271:  @ () 
_272:  @ ! 
_273:  @ () 
_274:  @ libs::spinlock::SpinLockGuard<'{erased}, mm::page::PageManager> 
_275:  @ () 
_276:  @ libs::spinlock::SpinLockGuard<'{erased}, mm::ucontext::VMA> 
_277:  @ () 
_278:  @ libs::rwlock::RwLockWriteGuard<'{erased}, mm::ucontext::InnerAddressSpace> 
_279:  @ () 
_280:  @ exception::IrqFlagsGuard 
_281:  @ alloc::sync::Arc<mm::ucontext::AddressSpace, alloc::alloc::Global> 
_282:  @ &'{erased} [&'{erased} str; 4_usize] 
_283:  @ &'{erased} log::LevelFilter 
_284:  @ &'{erased} [&'{erased} str; 4_usize] 
_285:  @ &'{erased} log::LevelFilter 
_286:  @ &'{erased} mm::VirtAddr 
_287:  @ &'{erased} mm::PhysAddr 
_288:  @ &'{erased} process::RawPid 
_289:  @ &'{erased} mm::VirtAddr 
_290:  @ &'{erased} mm::PhysAddr 
_291:  @ &'{erased} process::RawPid 
_292:  @ bool 
_293:  @ bool 
_294:  @ bool 
_295:  @ bool 
_296:  @ bool 
_297:  @ bool 
_298:  @ bool 
_299:  @ isize 
_300:  @ isize 
_301:  @ isize 
_302:  @ isize 
_303:  @ isize 
_304:  @ isize 
_305:  @ isize 
_306:  @ isize 
_307:  @ isize 
_308:  @ isize 
_309:  @ isize 

bb 0 {
CleanUp: false
    Assign((_294, const false)) @ _294=const false @ Use
    Assign((_298, const false)) @ _298=const false @ Use
    Assign((_297, const false)) @ _297=const false @ Use
    Assign((_296, const false)) @ _296=const false @ Use
    Assign((_295, const false)) @ _295=const false @ Use
    Assign((_292, const false)) @ _292=const false @ Use
    Assign((_293, const false)) @ _293=const false @ Use
    StorageLive(_3) @ StorageLive
    Assign((_294, const true)) @ _294=const true @ Use
    _3 = <arch::x86_64::interrupt::X86_64InterruptArch as exception::InterruptArch>::save_and_disable_irq() -> [return: bb1, unwind continue] @ Call: FnDid: 16949
}
bb 1 {
CleanUp: false
    StorageLive(_4) @ StorageLive
    StorageLive(_5) @ StorageLive
    StorageLive(_6) @ StorageLive
    _6 = mm::ucontext::AddressSpace::new(const false) -> [return: bb2, unwind: bb176] @ Call: FnDid: 25059
}
bb 2 {
CleanUp: false
    _5 = <core::result::Result<alloc::sync::Arc<mm::ucontext::AddressSpace>, system_error::SystemError> as core::ops::Try>::branch(move _6) -> [return: bb3, unwind: bb176] @ Call: FnDid: 4199
}
bb 3 {
CleanUp: false
    StorageDead(_6) @ StorageDead
    Assign((_7, discriminant(_5))) @ _7=discriminant(_5) @ Discriminant
    switchInt(move _7) -> [0: bb5, 1: bb6, otherwise: bb4] @ SwitchInt
}
bb 4 {
CleanUp: false
    unreachable @ Unreachable
}
bb 5 {
CleanUp: false
    StorageLive(_11) @ StorageLive
    Assign((_11, move ((_5 as Continue).0: alloc::sync::Arc<mm::ucontext::AddressSpace>))) @ _11=move ((_5 as Continue).0: alloc::sync::Arc<mm::ucontext::AddressSpace>) @ Use
    Assign((_4, move _11)) @ _4=move _11 @ Use
    StorageDead(_11) @ StorageDead
    Assign((_301, discriminant(_5))) @ _301=discriminant(_5) @ Discriminant
    StorageDead(_5) @ StorageDead
    StorageLive(_12) @ StorageLive
    StorageLive(_13) @ StorageLive
    StorageLive(_14) @ StorageLive
    StorageLive(_15) @ StorageLive
    StorageLive(_16) @ StorageLive
    StorageLive(_17) @ StorageLive
    Assign((_17, &_4)) @ _17=&_4 @ Ref
    _16 = <alloc::sync::Arc<mm::ucontext::AddressSpace> as lazy_static::__Deref>::deref(move _17) -> [return: bb8, unwind: bb159] @ Call: FnDid: 3903
}
bb 6 {
CleanUp: false
    StorageLive(_8) @ StorageLive
    Assign((_8, move ((_5 as Break).0: core::result::Result<core::convert::Infallible, system_error::SystemError>))) @ _8=move ((_5 as Break).0: core::result::Result<core::convert::Infallible, system_error::SystemError>) @ Use
    StorageLive(_10) @ StorageLive
    Assign((_10, move _8)) @ _10=move _8 @ Use
    _0 = <core::result::Result<alloc::sync::Arc<mm::ucontext::AddressSpace>, system_error::SystemError> as core::ops::FromResidual<core::result::Result<core::convert::Infallible, system_error::SystemError>>>::from_residual(move _10) -> [return: bb7, unwind: bb174] @ Call: FnDid: 4202
}
bb 7 {
CleanUp: false
    StorageDead(_10) @ StorageDead
    StorageDead(_8) @ StorageDead
    Assign((_299, discriminant(_5))) @ _299=discriminant(_5) @ Discriminant
    StorageDead(_5) @ StorageDead
    goto -> bb150 @ Goto
}
bb 8 {
CleanUp: false
    Assign((_15, &(*_16))) @ _15=&(*_16) @ Ref
    _14 = <mm::ucontext::AddressSpace as lazy_static::__Deref>::deref(move _15) -> [return: bb9, unwind: bb159] @ Call: FnDid: 3903
}
bb 9 {
CleanUp: false
    Assign((_13, &(*_14))) @ _13=&(*_14) @ Ref
    StorageDead(_17) @ StorageDead
    StorageDead(_15) @ StorageDead
    _12 = libs::rwlock::RwLock::<mm::ucontext::InnerAddressSpace>::write(move _13) -> [return: bb10, unwind: bb159] @ Call: FnDid: 5165
}
bb 10 {
CleanUp: false
    Assign((_298, const true)) @ _298=const true @ Use
    StorageDead(_13) @ StorageDead
    StorageDead(_16) @ StorageDead
    StorageDead(_14) @ StorageDead
    StorageLive(_18) @ StorageLive
    StorageLive(_19) @ StorageLive
    StorageLive(_20) @ StorageLive
    StorageLive(_21) @ StorageLive
    StorageLive(_22) @ StorageLive
    StorageLive(_23) @ StorageLive
    StorageLive(_24) @ StorageLive
    Assign((_24, &((*_1).3: core::option::Option<mm::ucontext::UserStack>))) @ _24=&((*_1).3: core::option::Option<mm::ucontext::UserStack>) @ Ref
    _23 = core::option::Option::<mm::ucontext::UserStack>::as_ref(move _24) -> [return: bb11, unwind: bb173] @ Call: FnDid: 10149
}
bb 11 {
CleanUp: false
    StorageDead(_24) @ StorageDead
    _22 = core::option::Option::<&mm::ucontext::UserStack>::unwrap(move _23) -> [return: bb12, unwind: bb173] @ Call: FnDid: 10157
}
bb 12 {
CleanUp: false
    Assign((_21, &(*_22))) @ _21=&(*_22) @ Ref
    StorageDead(_23) @ StorageDead
    _20 = mm::ucontext::UserStack::clone_info_only(move _21) -> [return: bb13, unwind: bb173] @ Call: FnDid: 25199
}
bb 13 {
CleanUp: false
    StorageDead(_21) @ StorageDead
    Assign((_19, core::option::Option::<mm::ucontext::UserStack>::Some(move _20))) @ _19=core::option::Option::<mm::ucontext::UserStack>::Some(move _20) @ Aggregate
    StorageDead(_20) @ StorageDead
    StorageLive(_25) @ StorageLive
    StorageLive(_26) @ StorageLive
    Assign((_26, &mut _12)) @ _26=&mut _12 @ Ref
    _25 = <libs::rwlock::RwLockWriteGuard<'_, mm::ucontext::InnerAddressSpace> as core::ops::DerefMut>::deref_mut(move _26) -> [return: bb14, unwind: bb173] @ Call: FnDid: 3915
}
bb 14 {
CleanUp: false
    StorageDead(_26) @ StorageDead
    Assign((((*_25).3: core::option::Option<mm::ucontext::UserStack>), move _19)) @ ((*_25).3: core::option::Option<mm::ucontext::UserStack>)=move _19 @ Use
    StorageDead(_19) @ StorageDead
    StorageDead(_25) @ StorageDead
    StorageDead(_22) @ StorageDead
    Assign((_18, const ())) @ _18=const () @ Use
    StorageDead(_18) @ StorageDead
    StorageLive(_27) @ StorageLive
    StorageLive(_28) @ StorageLive
    Assign((_28, &(((*_1).1: mm::ucontext::UserMappings).1: alloc::collections::BTreeMap<mm::VirtAddr, usize>))) @ _28=&(((*_1).1: mm::ucontext::UserMappings).1: alloc::collections::BTreeMap<mm::VirtAddr, usize>) @ Ref
    _27 = <alloc::collections::BTreeMap<mm::VirtAddr, usize> as core::clone::Clone>::clone(move _28) -> [return: bb15, unwind: bb173] @ Call: FnDid: 3116
}
bb 15 {
CleanUp: false
    Assign((_297, const true)) @ _297=const true @ Use
    StorageDead(_28) @ StorageDead
    StorageLive(_29) @ StorageLive
    StorageLive(_30) @ StorageLive
    Assign((_30, &mut _12)) @ _30=&mut _12 @ Ref
    _29 = <libs::rwlock::RwLockWriteGuard<'_, mm::ucontext::InnerAddressSpace> as core::ops::DerefMut>::deref_mut(move _30) -> [return: bb16, unwind: bb171] @ Call: FnDid: 3915
}
bb 16 {
CleanUp: false
    StorageDead(_30) @ StorageDead
    drop((((*_29).1: mm::ucontext::UserMappings).1: alloc::collections::BTreeMap<mm::VirtAddr, usize>)) -> [return: bb17, unwind: bb18] @ Drop
}
bb 17 {
CleanUp: false
    Assign((_297, const false)) @ _297=const false @ Use
    Assign(((((*_29).1: mm::ucontext::UserMappings).1: alloc::collections::BTreeMap<mm::VirtAddr, usize>), move _27)) @ (((*_29).1: mm::ucontext::UserMappings).1: alloc::collections::BTreeMap<mm::VirtAddr, usize>)=move _27 @ Use
    Assign((_297, const false)) @ _297=const false @ Use
    StorageDead(_27) @ StorageDead
    StorageDead(_29) @ StorageDead
    StorageLive(_31) @ StorageLive
    Assign((_31, copy ((*_1).7: mm::VirtAddr))) @ _31=copy ((*_1).7: mm::VirtAddr) @ Use
    StorageLive(_32) @ StorageLive
    StorageLive(_33) @ StorageLive
    Assign((_33, &mut _12)) @ _33=&mut _12 @ Ref
    _32 = <libs::rwlock::RwLockWriteGuard<'_, mm::ucontext::InnerAddressSpace> as core::ops::DerefMut>::deref_mut(move _33) -> [return: bb19, unwind: bb173] @ Call: FnDid: 3915
}
bb 18 {
CleanUp: true
    Assign((_297, const false)) @ _297=const false @ Use
    Assign(((((*_29).1: mm::ucontext::UserMappings).1: alloc::collections::BTreeMap<mm::VirtAddr, usize>), move _27)) @ (((*_29).1: mm::ucontext::UserMappings).1: alloc::collections::BTreeMap<mm::VirtAddr, usize>)=move _27 @ Use
    goto -> bb171 @ Goto
}
bb 19 {
CleanUp: false
    StorageDead(_33) @ StorageDead
    Assign((((*_32).7: mm::VirtAddr), move _31)) @ ((*_32).7: mm::VirtAddr)=move _31 @ Use
    StorageDead(_31) @ StorageDead
    StorageDead(_32) @ StorageDead
    StorageLive(_34) @ StorageLive
    Assign((_34, copy ((*_1).6: mm::VirtAddr))) @ _34=copy ((*_1).6: mm::VirtAddr) @ Use
    StorageLive(_35) @ StorageLive
    StorageLive(_36) @ StorageLive
    Assign((_36, &mut _12)) @ _36=&mut _12 @ Ref
    _35 = <libs::rwlock::RwLockWriteGuard<'_, mm::ucontext::InnerAddressSpace> as core::ops::DerefMut>::deref_mut(move _36) -> [return: bb20, unwind: bb173] @ Call: FnDid: 3915
}
bb 20 {
CleanUp: false
    StorageDead(_36) @ StorageDead
    Assign((((*_35).6: mm::VirtAddr), move _34)) @ ((*_35).6: mm::VirtAddr)=move _34 @ Use
    StorageDead(_34) @ StorageDead
    StorageDead(_35) @ StorageDead
    StorageLive(_37) @ StorageLive
    Assign((_37, copy ((*_1).2: mm::VirtAddr))) @ _37=copy ((*_1).2: mm::VirtAddr) @ Use
    StorageLive(_38) @ StorageLive
    StorageLive(_39) @ StorageLive
    Assign((_39, &mut _12)) @ _39=&mut _12 @ Ref
    _38 = <libs::rwlock::RwLockWriteGuard<'_, mm::ucontext::InnerAddressSpace> as core::ops::DerefMut>::deref_mut(move _39) -> [return: bb21, unwind: bb173] @ Call: FnDid: 3915
}
bb 21 {
CleanUp: false
    StorageDead(_39) @ StorageDead
    Assign((((*_38).2: mm::VirtAddr), move _37)) @ ((*_38).2: mm::VirtAddr)=move _37 @ Use
    StorageDead(_37) @ StorageDead
    StorageDead(_38) @ StorageDead
    StorageLive(_40) @ StorageLive
    Assign((_40, copy ((*_1).5: mm::VirtAddr))) @ _40=copy ((*_1).5: mm::VirtAddr) @ Use
    StorageLive(_41) @ StorageLive
    StorageLive(_42) @ StorageLive
    Assign((_42, &mut _12)) @ _42=&mut _12 @ Ref
    _41 = <libs::rwlock::RwLockWriteGuard<'_, mm::ucontext::InnerAddressSpace> as core::ops::DerefMut>::deref_mut(move _42) -> [return: bb22, unwind: bb173] @ Call: FnDid: 3915
}
bb 22 {
CleanUp: false
    StorageDead(_42) @ StorageDead
    Assign((((*_41).5: mm::VirtAddr), move _40)) @ ((*_41).5: mm::VirtAddr)=move _40 @ Use
    StorageDead(_40) @ StorageDead
    StorageDead(_41) @ StorageDead
    StorageLive(_43) @ StorageLive
    Assign((_43, copy ((*_1).4: mm::VirtAddr))) @ _43=copy ((*_1).4: mm::VirtAddr) @ Use
    StorageLive(_44) @ StorageLive
    StorageLive(_45) @ StorageLive
    Assign((_45, &mut _12)) @ _45=&mut _12 @ Ref
    _44 = <libs::rwlock::RwLockWriteGuard<'_, mm::ucontext::InnerAddressSpace> as core::ops::DerefMut>::deref_mut(move _45) -> [return: bb23, unwind: bb173] @ Call: FnDid: 3915
}
bb 23 {
CleanUp: false
    StorageDead(_45) @ StorageDead
    Assign((((*_44).4: mm::VirtAddr), move _43)) @ ((*_44).4: mm::VirtAddr)=move _43 @ Use
    StorageDead(_43) @ StorageDead
    StorageDead(_44) @ StorageDead
    StorageLive(_46) @ StorageLive
    Assign((_46, copy ((*_1).8: mm::VirtAddr))) @ _46=copy ((*_1).8: mm::VirtAddr) @ Use
    StorageLive(_47) @ StorageLive
    StorageLive(_48) @ StorageLive
    Assign((_48, &mut _12)) @ _48=&mut _12 @ Ref
    _47 = <libs::rwlock::RwLockWriteGuard<'_, mm::ucontext::InnerAddressSpace> as core::ops::DerefMut>::deref_mut(move _48) -> [return: bb24, unwind: bb173] @ Call: FnDid: 3915
}
bb 24 {
CleanUp: false
    StorageDead(_48) @ StorageDead
    Assign((((*_47).8: mm::VirtAddr), move _46)) @ ((*_47).8: mm::VirtAddr)=move _46 @ Use
    StorageDead(_46) @ StorageDead
    StorageDead(_47) @ StorageDead
    StorageLive(_49) @ StorageLive
    Assign((_49, copy ((*_1).9: mm::VirtAddr))) @ _49=copy ((*_1).9: mm::VirtAddr) @ Use
    StorageLive(_50) @ StorageLive
    StorageLive(_51) @ StorageLive
    Assign((_51, &mut _12)) @ _51=&mut _12 @ Ref
    _50 = <libs::rwlock::RwLockWriteGuard<'_, mm::ucontext::InnerAddressSpace> as core::ops::DerefMut>::deref_mut(move _51) -> [return: bb25, unwind: bb173] @ Call: FnDid: 3915
}
bb 25 {
CleanUp: false
    StorageDead(_51) @ StorageDead
    Assign((((*_50).9: mm::VirtAddr), move _49)) @ ((*_50).9: mm::VirtAddr)=move _49 @ Use
    StorageDead(_49) @ StorageDead
    StorageDead(_50) @ StorageDead
    StorageLive(_52) @ StorageLive
    Assign((_52, copy ((*_1).10: mm::VirtAddr))) @ _52=copy ((*_1).10: mm::VirtAddr) @ Use
    StorageLive(_53) @ StorageLive
    StorageLive(_54) @ StorageLive
    Assign((_54, &mut _12)) @ _54=&mut _12 @ Ref
    _53 = <libs::rwlock::RwLockWriteGuard<'_, mm::ucontext::InnerAddressSpace> as core::ops::DerefMut>::deref_mut(move _54) -> [return: bb26, unwind: bb173] @ Call: FnDid: 3915
}
bb 26 {
CleanUp: false
    StorageDead(_54) @ StorageDead
    Assign((((*_53).10: mm::VirtAddr), move _52)) @ ((*_53).10: mm::VirtAddr)=move _52 @ Use
    StorageDead(_52) @ StorageDead
    StorageDead(_53) @ StorageDead
    StorageLive(_55) @ StorageLive
    Assign((_55, copy ((*_1).11: mm::VirtAddr))) @ _55=copy ((*_1).11: mm::VirtAddr) @ Use
    StorageLive(_56) @ StorageLive
    StorageLive(_57) @ StorageLive
    Assign((_57, &mut _12)) @ _57=&mut _12 @ Ref
    _56 = <libs::rwlock::RwLockWriteGuard<'_, mm::ucontext::InnerAddressSpace> as core::ops::DerefMut>::deref_mut(move _57) -> [return: bb27, unwind: bb173] @ Call: FnDid: 3915
}
bb 27 {
CleanUp: false
    StorageDead(_57) @ StorageDead
    Assign((((*_56).11: mm::VirtAddr), move _55)) @ ((*_56).11: mm::VirtAddr)=move _55 @ Use
    StorageDead(_55) @ StorageDead
    StorageDead(_56) @ StorageDead
    StorageLive(_58) @ StorageLive
    StorageLive(_59) @ StorageLive
    StorageLive(_60) @ StorageLive
    StorageLive(_61) @ StorageLive
    Assign((_61, &(((*_1).1: mm::ucontext::UserMappings).0: hashbrown::HashSet<alloc::sync::Arc<mm::ucontext::LockedVMA>>))) @ _61=&(((*_1).1: mm::ucontext::UserMappings).0: hashbrown::HashSet<alloc::sync::Arc<mm::ucontext::LockedVMA>>) @ Ref
    _60 = hashbrown::HashSet::<alloc::sync::Arc<mm::ucontext::LockedVMA>>::iter(move _61) -> [return: bb28, unwind: bb173] @ Call: FnDid: 1615
}
bb 28 {
CleanUp: false
    StorageDead(_61) @ StorageDead
    _59 = <hashbrown::hash_set::Iter<'_, alloc::sync::Arc<mm::ucontext::LockedVMA>> as core::iter::IntoIterator>::into_iter(move _60) -> [return: bb29, unwind: bb173] @ Call: FnDid: 9224
}
bb 29 {
CleanUp: false
    StorageDead(_60) @ StorageDead
    StorageLive(_62) @ StorageLive
    Assign((_62, move _59)) @ _62=move _59 @ Use
    goto -> bb30 @ Goto
}
bb 30 {
CleanUp: false
    StorageLive(_64) @ StorageLive
    StorageLive(_65) @ StorageLive
    StorageLive(_66) @ StorageLive
    StorageLive(_67) @ StorageLive
    Assign((_67, &mut _62)) @ _67=&mut _62 @ Ref
    Assign((_66, &mut (*_67))) @ _66=&mut (*_67) @ Ref
    _65 = <hashbrown::hash_set::Iter<'_, alloc::sync::Arc<mm::ucontext::LockedVMA>> as core::iter::Iterator>::next(move _66) -> [return: bb31, unwind: bb173] @ Call: FnDid: 9356
}
bb 31 {
CleanUp: false
    StorageDead(_66) @ StorageDead
    Assign((_68, discriminant(_65))) @ _68=discriminant(_65) @ Discriminant
    switchInt(move _68) -> [0: bb33, 1: bb32, otherwise: bb4] @ SwitchInt
}
bb 32 {
CleanUp: false
    StorageLive(_70) @ StorageLive
    Assign((_70, copy ((_65 as Some).0: &alloc::sync::Arc<mm::ucontext::LockedVMA>))) @ _70=copy ((_65 as Some).0: &alloc::sync::Arc<mm::ucontext::LockedVMA>) @ Use
    StorageLive(_71) @ StorageLive
    StorageLive(_72) @ StorageLive
    StorageLive(_73) @ StorageLive
    StorageLive(_74) @ StorageLive
    Assign((_74, &(*_70))) @ _74=&(*_70) @ Ref
    _73 = <alloc::sync::Arc<mm::ucontext::LockedVMA> as lazy_static::__Deref>::deref(move _74) -> [return: bb34, unwind: bb173] @ Call: FnDid: 3903
}
bb 33 {
CleanUp: false
    Assign((_58, const ())) @ _58=const () @ Use
    StorageDead(_67) @ StorageDead
    StorageDead(_65) @ StorageDead
    StorageDead(_64) @ StorageDead
    StorageDead(_62) @ StorageDead
    StorageDead(_59) @ StorageDead
    StorageDead(_58) @ StorageDead
    StorageLive(_277) @ StorageLive
    StorageLive(_278) @ StorageLive
    Assign((_298, const false)) @ _298=const false @ Use
    Assign((_278, move _12)) @ _278=move _12 @ Use
    _277 = core::mem::drop::<libs::rwlock::RwLockWriteGuard<'_, mm::ucontext::InnerAddressSpace>>(move _278) -> [return: bb148, unwind: bb173] @ Call: FnDid: 2323
}
bb 34 {
CleanUp: false
    Assign((_72, &(*_73))) @ _72=&(*_73) @ Ref
    StorageDead(_74) @ StorageDead
    _71 = mm::ucontext::LockedVMA::lock_irqsave(move _72) -> [return: bb35, unwind: bb173] @ Call: FnDid: 25130
}
bb 35 {
CleanUp: false
    Assign((_296, const true)) @ _296=const true @ Use
    StorageDead(_72) @ StorageDead
    StorageDead(_73) @ StorageDead
    StorageLive(_75) @ StorageLive
    StorageLive(_76) @ StorageLive
    StorageLive(_77) @ StorageLive
    StorageLive(_78) @ StorageLive
    StorageLive(_79) @ StorageLive
    StorageLive(_80) @ StorageLive
    StorageLive(_81) @ StorageLive
    Assign((_81, &_71)) @ _81=&_71 @ Ref
    _80 = <libs::spinlock::SpinLockGuard<'_, mm::ucontext::VMA> as lazy_static::__Deref>::deref(move _81) -> [return: bb36, unwind: bb169] @ Call: FnDid: 3903
}
bb 36 {
CleanUp: false
    Assign((_79, &(*_80))) @ _79=&(*_80) @ Ref
    StorageDead(_81) @ StorageDead
    _78 = mm::ucontext::VMA::vm_flags(move _79) -> [return: bb37, unwind: bb169] @ Call: FnDid: 25162
}
bb 37 {
CleanUp: false
    Assign((_77, &(*_78))) @ _77=&(*_78) @ Ref
    StorageDead(_79) @ StorageDead
    _76 = mm::VmFlags::contains(move _77, const mm::VmFlags::VM_DONTCOPY) -> [return: bb38, unwind: bb169] @ Call: FnDid: 60147
}
bb 38 {
CleanUp: false
    switchInt(move _76) -> [0: bb41, otherwise: bb39] @ SwitchInt
}
bb 39 {
CleanUp: false
    StorageDead(_80) @ StorageDead
    StorageDead(_78) @ StorageDead
    StorageDead(_77) @ StorageDead
    StorageLive(_83) @ StorageLive
    StorageLive(_84) @ StorageLive
    Assign((_296, const false)) @ _296=const false @ Use
    Assign((_84, move _71)) @ _84=move _71 @ Use
    _83 = core::mem::drop::<libs::spinlock::SpinLockGuard<'_, mm::ucontext::VMA>>(move _84) -> [return: bb40, unwind: bb169] @ Call: FnDid: 2323
}
bb 40 {
CleanUp: false
    StorageDead(_84) @ StorageDead
    StorageDead(_83) @ StorageDead
    StorageDead(_76) @ StorageDead
    StorageDead(_75) @ StorageDead
    Assign((_296, const false)) @ _296=const false @ Use
    StorageDead(_71) @ StorageDead
    StorageDead(_70) @ StorageDead
    StorageDead(_67) @ StorageDead
    StorageDead(_65) @ StorageDead
    StorageDead(_64) @ StorageDead
    goto -> bb30 @ Goto
}
bb 41 {
CleanUp: false
    StorageDead(_80) @ StorageDead
    StorageDead(_78) @ StorageDead
    StorageDead(_77) @ StorageDead
    Assign((_75, const ())) @ _75=const () @ Use
    StorageDead(_76) @ StorageDead
    StorageDead(_75) @ StorageDead
    StorageLive(_85) @ StorageLive
    StorageLive(_86) @ StorageLive
    StorageLive(_87) @ StorageLive
    StorageLive(_88) @ StorageLive
    Assign((_88, &_71)) @ _88=&_71 @ Ref
    _87 = <libs::spinlock::SpinLockGuard<'_, mm::ucontext::VMA> as lazy_static::__Deref>::deref(move _88) -> [return: bb42, unwind: bb169] @ Call: FnDid: 3903
}
bb 42 {
CleanUp: false
    Assign((_86, &(*_87))) @ _86=&(*_87) @ Ref
    StorageDead(_88) @ StorageDead
    _85 = mm::ucontext::VMA::vm_flags(move _86) -> [return: bb43, unwind: bb169] @ Call: FnDid: 25162
}
bb 43 {
CleanUp: false
    StorageDead(_86) @ StorageDead
    StorageDead(_87) @ StorageDead
    StorageLive(_89) @ StorageLive
    StorageLive(_90) @ StorageLive
    Assign((_90, &(*_85))) @ _90=&(*_85) @ Ref
    _89 = mm::VmFlags::contains(move _90, const mm::VmFlags::VM_SHARED) -> [return: bb44, unwind: bb169] @ Call: FnDid: 60147
}
bb 44 {
CleanUp: false
    StorageDead(_90) @ StorageDead
    StorageLive(_91) @ StorageLive
    StorageLive(_92) @ StorageLive
    StorageLive(_93) @ StorageLive
    StorageLive(_94) @ StorageLive
    StorageLive(_95) @ StorageLive
    Assign((_95, &_71)) @ _95=&_71 @ Ref
    _94 = <libs::spinlock::SpinLockGuard<'_, mm::ucontext::VMA> as lazy_static::__Deref>::deref(move _95) -> [return: bb45, unwind: bb169] @ Call: FnDid: 3903
}
bb 45 {
CleanUp: false
    Assign((_93, &(*_94))) @ _93=&(*_94) @ Ref
    StorageDead(_95) @ StorageDead
    _92 = mm::ucontext::VMA::region(move _93) -> [return: bb46, unwind: bb169] @ Call: FnDid: 25161
}
bb 46 {
CleanUp: false
    StorageDead(_93) @ StorageDead
    Assign((_91, copy (*_92))) @ _91=copy (*_92) @ Use
    StorageDead(_94) @ StorageDead
    StorageDead(_92) @ StorageDead
    StorageLive(_96) @ StorageLive
    StorageLive(_97) @ StorageLive
    StorageLive(_98) @ StorageLive
    StorageLive(_99) @ StorageLive
    Assign((_99, &_71)) @ _99=&_71 @ Ref
    _98 = <libs::spinlock::SpinLockGuard<'_, mm::ucontext::VMA> as lazy_static::__Deref>::deref(move _99) -> [return: bb47, unwind: bb169] @ Call: FnDid: 3903
}
bb 47 {
CleanUp: false
    Assign((_97, &(*_98))) @ _97=&(*_98) @ Ref
    StorageDead(_99) @ StorageDead
    _96 = mm::ucontext::VMA::flags(move _97) -> [return: bb48, unwind: bb169] @ Call: FnDid: 25172
}
bb 48 {
CleanUp: false
    StorageDead(_97) @ StorageDead
    StorageDead(_98) @ StorageDead
    StorageLive(_100) @ StorageLive
    StorageLive(_101) @ StorageLive
    StorageLive(_102) @ StorageLive
    StorageLive(_103) @ StorageLive
    StorageLive(_104) @ StorageLive
    Assign((_104, &_71)) @ _104=&_71 @ Ref
    _103 = <libs::spinlock::SpinLockGuard<'_, mm::ucontext::VMA> as lazy_static::__Deref>::deref(move _104) -> [return: bb49, unwind: bb169] @ Call: FnDid: 3903
}
bb 49 {
CleanUp: false
    Assign((_102, &(*_103))) @ _102=&(*_103) @ Ref
    StorageDead(_104) @ StorageDead
    _101 = mm::ucontext::VMA::clone_info_only(move _102) -> [return: bb50, unwind: bb169] @ Call: FnDid: 25171
}
bb 50 {
CleanUp: false
    StorageDead(_102) @ StorageDead
    _100 = mm::ucontext::LockedVMA::new(move _101) -> [return: bb51, unwind: bb169] @ Call: FnDid: 25127
}
bb 51 {
CleanUp: false
    StorageDead(_101) @ StorageDead
    StorageDead(_103) @ StorageDead
    StorageLive(_105) @ StorageLive
    StorageLive(_106) @ StorageLive
    StorageLive(_107) @ StorageLive
    StorageLive(_108) @ StorageLive
    Assign((_108, &mut _12)) @ _108=&mut _12 @ Ref
    _107 = <libs::rwlock::RwLockWriteGuard<'_, mm::ucontext::InnerAddressSpace> as core::ops::DerefMut>::deref_mut(move _108) -> [return: bb52, unwind: bb158] @ Call: FnDid: 3915
}
bb 52 {
CleanUp: false
    StorageDead(_108) @ StorageDead
    Assign((_106, &mut (((*_107).1: mm::ucontext::UserMappings).0: hashbrown::HashSet<alloc::sync::Arc<mm::ucontext::LockedVMA>>))) @ _106=&mut (((*_107).1: mm::ucontext::UserMappings).0: hashbrown::HashSet<alloc::sync::Arc<mm::ucontext::LockedVMA>>) @ Ref
    StorageLive(_109) @ StorageLive
    StorageLive(_110) @ StorageLive
    Assign((_110, &_100)) @ _110=&_100 @ Ref
    _109 = <alloc::sync::Arc<mm::ucontext::LockedVMA> as core::clone::Clone>::clone(move _110) -> [return: bb53, unwind: bb158] @ Call: FnDid: 3116
}
bb 53 {
CleanUp: false
    StorageDead(_110) @ StorageDead
    _105 = hashbrown::HashSet::<alloc::sync::Arc<mm::ucontext::LockedVMA>>::insert(move _106, move _109) -> [return: bb54, unwind: bb158] @ Call: FnDid: 1672
}
bb 54 {
CleanUp: false
    StorageDead(_109) @ StorageDead
    StorageDead(_106) @ StorageDead
    StorageDead(_107) @ StorageDead
    StorageDead(_105) @ StorageDead
    StorageLive(_111) @ StorageLive
    StorageLive(_112) @ StorageLive
    Assign((_112, &_91)) @ _112=&_91 @ Ref
    _111 = mm::VirtRegion::start(move _112) -> [return: bb55, unwind: bb158] @ Call: FnDid: 25369
}
bb 55 {
CleanUp: false
    StorageDead(_112) @ StorageDead
    StorageLive(_113) @ StorageLive
    StorageLive(_114) @ StorageLive
    Assign((_114, &_91)) @ _114=&_91 @ Ref
    _113 = mm::VirtRegion::end(move _114) -> [return: bb56, unwind: bb158] @ Call: FnDid: 25370
}
bb 56 {
CleanUp: false
    StorageDead(_114) @ StorageDead
    StorageLive(_115) @ StorageLive
    Assign((_115, copy _111)) @ _115=copy _111 @ Use
    StorageLive(_116) @ StorageLive
    Assign((_116, &mut (((*_1).0: mm::ucontext::UserMapper).0: mm::page::PageMapper<arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator>))) @ _116=&mut (((*_1).0: mm::ucontext::UserMapper).0: mm::page::PageMapper<arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator>) @ Ref
    StorageLive(_117) @ StorageLive
    StorageLive(_118) @ StorageLive
    StorageLive(_119) @ StorageLive
    Assign((_119, &mut _12)) @ _119=&mut _12 @ Ref
    _118 = <libs::rwlock::RwLockWriteGuard<'_, mm::ucontext::InnerAddressSpace> as core::ops::DerefMut>::deref_mut(move _119) -> [return: bb57, unwind: bb158] @ Call: FnDid: 3915
}
bb 57 {
CleanUp: false
    StorageDead(_119) @ StorageDead
    Assign((_117, &mut (((*_118).0: mm::ucontext::UserMapper).0: mm::page::PageMapper<arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator>))) @ _117=&mut (((*_118).0: mm::ucontext::UserMapper).0: mm::page::PageMapper<arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator>) @ Ref
    StorageLive(_120) @ StorageLive
    _120 = mm::page::page_manager_lock_irqsave() -> [return: bb58, unwind: bb158] @ Call: FnDid: 24300
}
bb 58 {
CleanUp: false
    Assign((_295, const true)) @ _295=const true @ Use
    StorageLive(_121) @ StorageLive
    goto -> bb59 @ Goto
}
bb 59 {
CleanUp: false
    StorageLive(_122) @ StorageLive
    StorageLive(_123) @ StorageLive
    Assign((_123, &_115)) @ _123=&_115 @ Ref
    StorageLive(_124) @ StorageLive
    Assign((_124, &_113)) @ _124=&_113 @ Ref
    _122 = <mm::VirtAddr as core::cmp::PartialOrd>::lt(move _123, move _124) -> [return: bb60, unwind: bb167] @ Call: FnDid: 3214
}
bb 60 {
CleanUp: false
    switchInt(move _122) -> [0: bb144, otherwise: bb61] @ SwitchInt
}
bb 61 {
CleanUp: false
    StorageDead(_124) @ StorageDead
    StorageDead(_123) @ StorageDead
    StorageLive(_125) @ StorageLive
    StorageLive(_126) @ StorageLive
    StorageLive(_127) @ StorageLive
    Assign((_127, &(*_116))) @ _127=&(*_116) @ Ref
    StorageLive(_128) @ StorageLive
    Assign((_128, copy _115)) @ _128=copy _115 @ Use
    _126 = mm::page::PageMapper::<arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator>::translate(move _127, move _128) -> [return: bb62, unwind: bb167] @ Call: FnDid: 24445
}
bb 62 {
CleanUp: false
    StorageDead(_128) @ StorageDead
    StorageDead(_127) @ StorageDead
    Assign((_129, discriminant(_126))) @ _129=discriminant(_126) @ Discriminant
    switchInt(move _129) -> [1: bb63, otherwise: bb139] @ SwitchInt
}
bb 63 {
CleanUp: false
    StorageLive(_130) @ StorageLive
    Assign((_130, copy (((_126 as Some).0: (mm::PhysAddr, mm::page::EntryFlags<arch::x86_64::mm::X86_64MMArch>)).0: mm::PhysAddr))) @ _130=copy (((_126 as Some).0: (mm::PhysAddr, mm::page::EntryFlags<arch::x86_64::mm::X86_64MMArch>)).0: mm::PhysAddr) @ Use
    StorageLive(_131) @ StorageLive
    Assign((_131, copy (((_126 as Some).0: (mm::PhysAddr, mm::page::EntryFlags<arch::x86_64::mm::X86_64MMArch>)).1: mm::page::EntryFlags<arch::x86_64::mm::X86_64MMArch>))) @ _131=copy (((_126 as Some).0: (mm::PhysAddr, mm::page::EntryFlags<arch::x86_64::mm::X86_64MMArch>)).1: mm::page::EntryFlags<arch::x86_64::mm::X86_64MMArch>) @ Use
    StorageLive(_132) @ StorageLive
    StorageLive(_133) @ StorageLive
    Assign((_133, copy _89)) @ _133=copy _89 @ Use
    switchInt(move _133) -> [0: bb91, otherwise: bb64] @ SwitchInt
}
bb 64 {
CleanUp: false
    StorageLive(_134) @ StorageLive
    StorageLive(_135) @ StorageLive
    StorageLive(_136) @ StorageLive
    StorageLive(_137) @ StorageLive
    Assign((_137, &mut (*_117))) @ _137=&mut (*_117) @ Ref
    StorageLive(_138) @ StorageLive
    Assign((_138, copy _115)) @ _138=copy _115 @ Use
    StorageLive(_139) @ StorageLive
    Assign((_139, copy _130)) @ _139=copy _130 @ Use
    StorageLive(_140) @ StorageLive
    Assign((_140, copy _96)) @ _140=copy _96 @ Use
    _136 = mm::page::PageMapper::<arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator>::map_phys(move _137, move _138, move _139, move _140) -> [return: bb65, unwind: bb167] @ Call: FnDid: 24435
}
bb 65 {
CleanUp: false
    Assign((_135, &_136)) @ _135=&_136 @ Ref
    StorageDead(_140) @ StorageDead
    StorageDead(_139) @ StorageDead
    StorageDead(_138) @ StorageDead
    StorageDead(_137) @ StorageDead
    _134 = core::option::Option::<mm::page::PageFlush<arch::x86_64::mm::X86_64MMArch>>::is_none(move _135) -> [return: bb66, unwind: bb157] @ Call: FnDid: 10146
}
bb 66 {
CleanUp: false
    switchInt(move _134) -> [0: bb88, otherwise: bb67] @ SwitchInt
}
bb 67 {
CleanUp: false
    drop(_136) -> [return: bb68, unwind: bb167] @ Drop
}
bb 68 {
CleanUp: false
    StorageDead(_136) @ StorageDead
    StorageDead(_135) @ StorageDead
    StorageLive(_141) @ StorageLive
    StorageLive(_142) @ StorageLive
    Assign((_142, log::Level::Warn)) @ _142=log::Level::Warn @ Aggregate
    StorageLive(_143) @ StorageLive
    StorageLive(_144) @ StorageLive
    Assign((_144, &_142)) @ _144=&_142 @ Ref
    StorageLive(_145) @ StorageLive
    Assign((_283, const mm::ucontext::InnerAddressSpace::try_clone::promoted[1])) @ _283=const mm::ucontext::InnerAddressSpace::try_clone::promoted[1] @ Use
    Assign((_145, &(*_283))) @ _145=&(*_283) @ Ref
    _143 = <log::Level as core::cmp::PartialOrd<log::LevelFilter>>::le(move _144, move _145) -> [return: bb69, unwind: bb167] @ Call: FnDid: 3215
}
bb 69 {
CleanUp: false
    switchInt(move _143) -> [0: bb85, otherwise: bb70] @ SwitchInt
}
bb 70 {
CleanUp: false
    StorageDead(_145) @ StorageDead
    StorageDead(_144) @ StorageDead
    StorageLive(_147) @ StorageLive
    StorageLive(_148) @ StorageLive
    Assign((_148, &_142)) @ _148=&_142 @ Ref
    StorageLive(_149) @ StorageLive
    StorageLive(_150) @ StorageLive
    _150 = log::max_level() -> [return: bb71, unwind: bb167] @ Call: FnDid: 134
}
bb 71 {
CleanUp: false
    Assign((_149, &_150)) @ _149=&_150 @ Ref
    _147 = <log::Level as core::cmp::PartialOrd<log::LevelFilter>>::le(move _148, move _149) -> [return: bb72, unwind: bb167] @ Call: FnDid: 3215
}
bb 72 {
CleanUp: false
    switchInt(move _147) -> [0: bb84, otherwise: bb73] @ SwitchInt
}
bb 73 {
CleanUp: false
    StorageDead(_150) @ StorageDead
    StorageDead(_149) @ StorageDead
    StorageDead(_148) @ StorageDead
    StorageLive(_151) @ StorageLive
    StorageLive(_152) @ StorageLive
    Assign((_152, log::__private_api::GlobalLogger)) @ _152=log::__private_api::GlobalLogger @ Aggregate
    StorageLive(_153) @ StorageLive
    StorageLive(_154) @ StorageLive
    StorageLive(_155) @ StorageLive
    Assign((_155, &_115)) @ _155=&_115 @ Ref
    StorageLive(_156) @ StorageLive
    Assign((_156, &_130)) @ _156=&_130 @ Ref
    StorageLive(_157) @ StorageLive
    StorageLive(_158) @ StorageLive
    StorageLive(_159) @ StorageLive
    StorageLive(_160) @ StorageLive
    StorageLive(_161) @ StorageLive
    StorageLive(_162) @ StorageLive
    _162 = process::ProcessManager::current_pcb() -> [return: bb74, unwind: bb167] @ Call: FnDid: 29866
}
bb 74 {
CleanUp: false
    Assign((_161, &_162)) @ _161=&_162 @ Ref
    _160 = <alloc::sync::Arc<process::ProcessControlBlock> as lazy_static::__Deref>::deref(move _161) -> [return: bb75, unwind: bb156] @ Call: FnDid: 3903
}
bb 75 {
CleanUp: false
    Assign((_159, &(*_160))) @ _159=&(*_160) @ Ref
    StorageDead(_161) @ StorageDead
    _158 = process::ProcessControlBlock::raw_pid(move _159) -> [return: bb76, unwind: bb156] @ Call: FnDid: 29942
}
bb 76 {
CleanUp: false
    StorageDead(_159) @ StorageDead
    Assign((_157, &_158)) @ _157=&_158 @ Ref
    Assign((_154, (move _155, move _156, move _157))) @ _154=(move _155, move _156, move _157) @ Aggregate
    StorageDead(_157) @ StorageDead
    StorageDead(_156) @ StorageDead
    StorageDead(_155) @ StorageDead
    StorageLive(_163) @ StorageLive
    StorageLive(_164) @ StorageLive
    StorageLive(_165) @ StorageLive
    Assign((_286, deref_copy (_154.0: &mm::VirtAddr))) @ _286=deref_copy (_154.0: &mm::VirtAddr) @ CopyForDeref
    Assign((_165, &(*_286))) @ _165=&(*_286) @ Ref
    _164 = core::fmt::rt::Argument::<'_>::new_debug::<mm::VirtAddr>(move _165) -> [return: bb77, unwind: bb156] @ Call: FnDid: 11809
}
bb 77 {
CleanUp: false
    StorageDead(_165) @ StorageDead
    StorageLive(_166) @ StorageLive
    StorageLive(_167) @ StorageLive
    Assign((_287, deref_copy (_154.1: &mm::PhysAddr))) @ _287=deref_copy (_154.1: &mm::PhysAddr) @ CopyForDeref
    Assign((_167, &(*_287))) @ _167=&(*_287) @ Ref
    _166 = core::fmt::rt::Argument::<'_>::new_debug::<mm::PhysAddr>(move _167) -> [return: bb78, unwind: bb156] @ Call: FnDid: 11809
}
bb 78 {
CleanUp: false
    StorageDead(_167) @ StorageDead
    StorageLive(_168) @ StorageLive
    StorageLive(_169) @ StorageLive
    Assign((_288, deref_copy (_154.2: &process::RawPid))) @ _288=deref_copy (_154.2: &process::RawPid) @ CopyForDeref
    Assign((_169, &(*_288))) @ _169=&(*_288) @ Ref
    _168 = core::fmt::rt::Argument::<'_>::new_debug::<process::RawPid>(move _169) -> [return: bb79, unwind: bb156] @ Call: FnDid: 11809
}
bb 79 {
CleanUp: false
    StorageDead(_169) @ StorageDead
    Assign((_163, [move _164, move _166, move _168])) @ _163=[move _164, move _166, move _168] @ Aggregate
    StorageDead(_168) @ StorageDead
    StorageDead(_166) @ StorageDead
    StorageDead(_164) @ StorageDead
    StorageLive(_170) @ StorageLive
    StorageLive(_171) @ StorageLive
    Assign((_282, const mm::ucontext::InnerAddressSpace::try_clone::promoted[0])) @ _282=const mm::ucontext::InnerAddressSpace::try_clone::promoted[0] @ Use
    Assign((_171, &(*_282))) @ _171=&(*_282) @ Ref
    Assign((_170, &(*_171))) @ _170=&(*_171) @ Ref
    StorageLive(_173) @ StorageLive
    StorageLive(_174) @ StorageLive
    Assign((_174, &_163)) @ _174=&_163 @ Ref
    Assign((_173, &(*_174))) @ _173=&(*_174) @ Ref
    _153 = core::fmt::rt::<impl core::fmt::Arguments<'_>>::new_v1::<4, 3>(move _170, move _173) -> [return: bb80, unwind: bb156] @ Call: FnDid: 11836
}
bb 80 {
CleanUp: false
    StorageDead(_174) @ StorageDead
    StorageDead(_173) @ StorageDead
    StorageDead(_171) @ StorageDead
    StorageDead(_170) @ StorageDead
    StorageLive(_175) @ StorageLive
    Assign((_175, copy _142)) @ _175=copy _142 @ Use
    StorageLive(_176) @ StorageLive
    StorageLive(_177) @ StorageLive
    StorageLive(_178) @ StorageLive
    StorageLive(_179) @ StorageLive
    StorageLive(_180) @ StorageLive
    Assign((_180, const "dragonos_kernel::mm::ucontext")) @ _180=const "dragonos_kernel::mm::ucontext" @ Use
    Assign((_179, &(*_180))) @ _179=&(*_180) @ Ref
    StorageLive(_181) @ StorageLive
    StorageLive(_182) @ StorageLive
    _182 = log::__private_api::loc() -> [return: bb81, unwind: bb156] @ Call: FnDid: 184
}
bb 81 {
CleanUp: false
    Assign((_181, &(*_182))) @ _181=&(*_182) @ Ref
    Assign((_178, (move _179, const "dragonos_kernel::mm::ucontext", move _181))) @ _178=(move _179, const "dragonos_kernel::mm::ucontext", move _181) @ Aggregate
    StorageDead(_181) @ StorageDead
    StorageDead(_179) @ StorageDead
    Assign((_177, &_178)) @ _177=&_178 @ Ref
    Assign((_176, &(*_177))) @ _176=&(*_177) @ Ref
    StorageLive(_183) @ StorageLive
    Assign((_183, ())) @ _183=() @ Aggregate
    _151 = log::__private_api::log::<'_, (), log::__private_api::GlobalLogger>(move _152, move _153, move _175, move _176, move _183) -> [return: bb82, unwind: bb156] @ Call: FnDid: 178
}
bb 82 {
CleanUp: false
    StorageDead(_183) @ StorageDead
    StorageDead(_176) @ StorageDead
    StorageDead(_175) @ StorageDead
    StorageDead(_153) @ StorageDead
    StorageDead(_152) @ StorageDead
    StorageDead(_182) @ StorageDead
    StorageDead(_180) @ StorageDead
    StorageDead(_178) @ StorageDead
    StorageDead(_177) @ StorageDead
    StorageDead(_163) @ StorageDead
    drop(_162) -> [return: bb83, unwind: bb167] @ Drop
}
bb 83 {
CleanUp: false
    StorageDead(_162) @ StorageDead
    StorageDead(_160) @ StorageDead
    StorageDead(_158) @ StorageDead
    StorageDead(_154) @ StorageDead
    StorageDead(_151) @ StorageDead
    Assign((_141, const ())) @ _141=const () @ Use
    goto -> bb87 @ Goto
}
bb 84 {
CleanUp: false
    StorageDead(_150) @ StorageDead
    StorageDead(_149) @ StorageDead
    StorageDead(_148) @ StorageDead
    goto -> bb86 @ Goto
}
bb 85 {
CleanUp: false
    StorageDead(_145) @ StorageDead
    StorageDead(_144) @ StorageDead
    goto -> bb86 @ Goto
}
bb 86 {
CleanUp: false
    Assign((_141, const ())) @ _141=const () @ Use
    goto -> bb87 @ Goto
}
bb 87 {
CleanUp: false
    StorageDead(_147) @ StorageDead
    StorageDead(_143) @ StorageDead
    StorageDead(_142) @ StorageDead
    StorageDead(_141) @ StorageDead
    Assign((_132, const ())) @ _132=const () @ Use
    goto -> bb90 @ Goto
}
bb 88 {
CleanUp: false
    drop(_136) -> [return: bb89, unwind: bb167] @ Drop
}
bb 89 {
CleanUp: false
    StorageDead(_136) @ StorageDead
    StorageDead(_135) @ StorageDead
    Assign((_132, const ())) @ _132=const () @ Use
    goto -> bb90 @ Goto
}
bb 90 {
CleanUp: false
    StorageDead(_134) @ StorageDead
    goto -> bb127 @ Goto
}
bb 91 {
CleanUp: false
    StorageLive(_184) @ StorageLive
    StorageLive(_185) @ StorageLive
    Assign((_185, copy _96)) @ _185=copy _96 @ Use
    _184 = mm::page::EntryFlags::<arch::x86_64::mm::X86_64MMArch>::set_write(move _185, const false) -> [return: bb92, unwind: bb167] @ Call: FnDid: 24407
}
bb 92 {
CleanUp: false
    StorageDead(_185) @ StorageDead
    StorageLive(_186) @ StorageLive
    StorageLive(_187) @ StorageLive
    StorageLive(_188) @ StorageLive
    Assign((_188, &_131)) @ _188=&_131 @ Ref
    _187 = mm::page::EntryFlags::<arch::x86_64::mm::X86_64MMArch>::has_write(move _188) -> [return: bb93, unwind: bb167] @ Call: FnDid: 24408
}
bb 93 {
CleanUp: false
    switchInt(move _187) -> [0: bb99, otherwise: bb94] @ SwitchInt
}
bb 94 {
CleanUp: false
    StorageDead(_188) @ StorageDead
    StorageLive(_189) @ StorageLive
    StorageLive(_190) @ StorageLive
    Assign((_190, &mut (*_116))) @ _190=&mut (*_116) @ Ref
    StorageLive(_191) @ StorageLive
    Assign((_191, copy _115)) @ _191=copy _115 @ Use
    StorageLive(_192) @ StorageLive
    Assign((_192, copy _184)) @ _192=copy _184 @ Use
    _189 = mm::page::PageMapper::<arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator>::remap(move _190, move _191, move _192) -> [return: bb95, unwind: bb167] @ Call: FnDid: 24443
}
bb 95 {
CleanUp: false
    Assign((_292, const true)) @ _292=const true @ Use
    StorageDead(_192) @ StorageDead
    StorageDead(_191) @ StorageDead
    StorageDead(_190) @ StorageDead
    Assign((_193, discriminant(_189))) @ _193=discriminant(_189) @ Discriminant
    switchInt(move _193) -> [1: bb96, otherwise: bb98] @ SwitchInt
}
bb 96 {
CleanUp: false
    StorageLive(_194) @ StorageLive
    Assign((_194, move ((_189 as Some).0: mm::page::PageFlush<arch::x86_64::mm::X86_64MMArch>))) @ _194=move ((_189 as Some).0: mm::page::PageFlush<arch::x86_64::mm::X86_64MMArch>) @ Use
    StorageLive(_195) @ StorageLive
    StorageLive(_196) @ StorageLive
    Assign((_196, move _194)) @ _196=move _194 @ Use
    _195 = mm::page::PageFlush::<arch::x86_64::mm::X86_64MMArch>::flush(move _196) -> [return: bb97, unwind: bb165] @ Call: FnDid: 24472
}
bb 97 {
CleanUp: false
    StorageDead(_196) @ StorageDead
    StorageDead(_195) @ StorageDead
    Assign((_186, const ())) @ _186=const () @ Use
    StorageDead(_194) @ StorageDead
    goto -> bb161 @ Goto
}
bb 98 {
CleanUp: false
    Assign((_186, const ())) @ _186=const () @ Use
    goto -> bb161 @ Goto
}
bb 99 {
CleanUp: false
    StorageDead(_188) @ StorageDead
    Assign((_186, const ())) @ _186=const () @ Use
    goto -> bb100 @ Goto
}
bb 100 {
CleanUp: false
    StorageDead(_187) @ StorageDead
    StorageDead(_186) @ StorageDead
    StorageLive(_197) @ StorageLive
    StorageLive(_198) @ StorageLive
    StorageLive(_199) @ StorageLive
    StorageLive(_200) @ StorageLive
    Assign((_200, &mut (*_117))) @ _200=&mut (*_117) @ Ref
    StorageLive(_201) @ StorageLive
    Assign((_201, copy _115)) @ _201=copy _115 @ Use
    StorageLive(_202) @ StorageLive
    Assign((_202, copy _130)) @ _202=copy _130 @ Use
    StorageLive(_203) @ StorageLive
    Assign((_203, copy _184)) @ _203=copy _184 @ Use
    _199 = mm::page::PageMapper::<arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator>::map_phys(move _200, move _201, move _202, move _203) -> [return: bb101, unwind: bb167] @ Call: FnDid: 24435
}
bb 101 {
CleanUp: false
    Assign((_198, &_199)) @ _198=&_199 @ Ref
    StorageDead(_203) @ StorageDead
    StorageDead(_202) @ StorageDead
    StorageDead(_201) @ StorageDead
    StorageDead(_200) @ StorageDead
    _197 = core::option::Option::<mm::page::PageFlush<arch::x86_64::mm::X86_64MMArch>>::is_none(move _198) -> [return: bb102, unwind: bb155] @ Call: FnDid: 10146
}
bb 102 {
CleanUp: false
    switchInt(move _197) -> [0: bb124, otherwise: bb103] @ SwitchInt
}
bb 103 {
CleanUp: false
    drop(_199) -> [return: bb104, unwind: bb167] @ Drop
}
bb 104 {
CleanUp: false
    StorageDead(_199) @ StorageDead
    StorageDead(_198) @ StorageDead
    StorageLive(_204) @ StorageLive
    StorageLive(_205) @ StorageLive
    Assign((_205, log::Level::Warn)) @ _205=log::Level::Warn @ Aggregate
    StorageLive(_206) @ StorageLive
    StorageLive(_207) @ StorageLive
    Assign((_207, &_205)) @ _207=&_205 @ Ref
    StorageLive(_208) @ StorageLive
    Assign((_285, const mm::ucontext::InnerAddressSpace::try_clone::promoted[3])) @ _285=const mm::ucontext::InnerAddressSpace::try_clone::promoted[3] @ Use
    Assign((_208, &(*_285))) @ _208=&(*_285) @ Ref
    _206 = <log::Level as core::cmp::PartialOrd<log::LevelFilter>>::le(move _207, move _208) -> [return: bb105, unwind: bb167] @ Call: FnDid: 3215
}
bb 105 {
CleanUp: false
    switchInt(move _206) -> [0: bb121, otherwise: bb106] @ SwitchInt
}
bb 106 {
CleanUp: false
    StorageDead(_208) @ StorageDead
    StorageDead(_207) @ StorageDead
    StorageLive(_210) @ StorageLive
    StorageLive(_211) @ StorageLive
    Assign((_211, &_205)) @ _211=&_205 @ Ref
    StorageLive(_212) @ StorageLive
    StorageLive(_213) @ StorageLive
    _213 = log::max_level() -> [return: bb107, unwind: bb167] @ Call: FnDid: 134
}
bb 107 {
CleanUp: false
    Assign((_212, &_213)) @ _212=&_213 @ Ref
    _210 = <log::Level as core::cmp::PartialOrd<log::LevelFilter>>::le(move _211, move _212) -> [return: bb108, unwind: bb167] @ Call: FnDid: 3215
}
bb 108 {
CleanUp: false
    switchInt(move _210) -> [0: bb120, otherwise: bb109] @ SwitchInt
}
bb 109 {
CleanUp: false
    StorageDead(_213) @ StorageDead
    StorageDead(_212) @ StorageDead
    StorageDead(_211) @ StorageDead
    StorageLive(_214) @ StorageLive
    StorageLive(_215) @ StorageLive
    Assign((_215, log::__private_api::GlobalLogger)) @ _215=log::__private_api::GlobalLogger @ Aggregate
    StorageLive(_216) @ StorageLive
    StorageLive(_217) @ StorageLive
    StorageLive(_218) @ StorageLive
    Assign((_218, &_115)) @ _218=&_115 @ Ref
    StorageLive(_219) @ StorageLive
    Assign((_219, &_130)) @ _219=&_130 @ Ref
    StorageLive(_220) @ StorageLive
    StorageLive(_221) @ StorageLive
    StorageLive(_222) @ StorageLive
    StorageLive(_223) @ StorageLive
    StorageLive(_224) @ StorageLive
    StorageLive(_225) @ StorageLive
    _225 = process::ProcessManager::current_pcb() -> [return: bb110, unwind: bb167] @ Call: FnDid: 29866
}
bb 110 {
CleanUp: false
    Assign((_224, &_225)) @ _224=&_225 @ Ref
    _223 = <alloc::sync::Arc<process::ProcessControlBlock> as lazy_static::__Deref>::deref(move _224) -> [return: bb111, unwind: bb154] @ Call: FnDid: 3903
}
bb 111 {
CleanUp: false
    Assign((_222, &(*_223))) @ _222=&(*_223) @ Ref
    StorageDead(_224) @ StorageDead
    _221 = process::ProcessControlBlock::raw_pid(move _222) -> [return: bb112, unwind: bb154] @ Call: FnDid: 29942
}
bb 112 {
CleanUp: false
    StorageDead(_222) @ StorageDead
    Assign((_220, &_221)) @ _220=&_221 @ Ref
    Assign((_217, (move _218, move _219, move _220))) @ _217=(move _218, move _219, move _220) @ Aggregate
    StorageDead(_220) @ StorageDead
    StorageDead(_219) @ StorageDead
    StorageDead(_218) @ StorageDead
    StorageLive(_226) @ StorageLive
    StorageLive(_227) @ StorageLive
    StorageLive(_228) @ StorageLive
    Assign((_289, deref_copy (_217.0: &mm::VirtAddr))) @ _289=deref_copy (_217.0: &mm::VirtAddr) @ CopyForDeref
    Assign((_228, &(*_289))) @ _228=&(*_289) @ Ref
    _227 = core::fmt::rt::Argument::<'_>::new_debug::<mm::VirtAddr>(move _228) -> [return: bb113, unwind: bb154] @ Call: FnDid: 11809
}
bb 113 {
CleanUp: false
    StorageDead(_228) @ StorageDead
    StorageLive(_229) @ StorageLive
    StorageLive(_230) @ StorageLive
    Assign((_290, deref_copy (_217.1: &mm::PhysAddr))) @ _290=deref_copy (_217.1: &mm::PhysAddr) @ CopyForDeref
    Assign((_230, &(*_290))) @ _230=&(*_290) @ Ref
    _229 = core::fmt::rt::Argument::<'_>::new_debug::<mm::PhysAddr>(move _230) -> [return: bb114, unwind: bb154] @ Call: FnDid: 11809
}
bb 114 {
CleanUp: false
    StorageDead(_230) @ StorageDead
    StorageLive(_231) @ StorageLive
    StorageLive(_232) @ StorageLive
    Assign((_291, deref_copy (_217.2: &process::RawPid))) @ _291=deref_copy (_217.2: &process::RawPid) @ CopyForDeref
    Assign((_232, &(*_291))) @ _232=&(*_291) @ Ref
    _231 = core::fmt::rt::Argument::<'_>::new_debug::<process::RawPid>(move _232) -> [return: bb115, unwind: bb154] @ Call: FnDid: 11809
}
bb 115 {
CleanUp: false
    StorageDead(_232) @ StorageDead
    Assign((_226, [move _227, move _229, move _231])) @ _226=[move _227, move _229, move _231] @ Aggregate
    StorageDead(_231) @ StorageDead
    StorageDead(_229) @ StorageDead
    StorageDead(_227) @ StorageDead
    StorageLive(_233) @ StorageLive
    StorageLive(_234) @ StorageLive
    Assign((_284, const mm::ucontext::InnerAddressSpace::try_clone::promoted[2])) @ _284=const mm::ucontext::InnerAddressSpace::try_clone::promoted[2] @ Use
    Assign((_234, &(*_284))) @ _234=&(*_284) @ Ref
    Assign((_233, &(*_234))) @ _233=&(*_234) @ Ref
    StorageLive(_236) @ StorageLive
    StorageLive(_237) @ StorageLive
    Assign((_237, &_226)) @ _237=&_226 @ Ref
    Assign((_236, &(*_237))) @ _236=&(*_237) @ Ref
    _216 = core::fmt::rt::<impl core::fmt::Arguments<'_>>::new_v1::<4, 3>(move _233, move _236) -> [return: bb116, unwind: bb154] @ Call: FnDid: 11836
}
bb 116 {
CleanUp: false
    StorageDead(_237) @ StorageDead
    StorageDead(_236) @ StorageDead
    StorageDead(_234) @ StorageDead
    StorageDead(_233) @ StorageDead
    StorageLive(_238) @ StorageLive
    Assign((_238, copy _205)) @ _238=copy _205 @ Use
    StorageLive(_239) @ StorageLive
    StorageLive(_240) @ StorageLive
    StorageLive(_241) @ StorageLive
    StorageLive(_242) @ StorageLive
    StorageLive(_243) @ StorageLive
    Assign((_243, const "dragonos_kernel::mm::ucontext")) @ _243=const "dragonos_kernel::mm::ucontext" @ Use
    Assign((_242, &(*_243))) @ _242=&(*_243) @ Ref
    StorageLive(_244) @ StorageLive
    StorageLive(_245) @ StorageLive
    _245 = log::__private_api::loc() -> [return: bb117, unwind: bb154] @ Call: FnDid: 184
}
bb 117 {
CleanUp: false
    Assign((_244, &(*_245))) @ _244=&(*_245) @ Ref
    Assign((_241, (move _242, const "dragonos_kernel::mm::ucontext", move _244))) @ _241=(move _242, const "dragonos_kernel::mm::ucontext", move _244) @ Aggregate
    StorageDead(_244) @ StorageDead
    StorageDead(_242) @ StorageDead
    Assign((_240, &_241)) @ _240=&_241 @ Ref
    Assign((_239, &(*_240))) @ _239=&(*_240) @ Ref
    StorageLive(_246) @ StorageLive
    Assign((_246, ())) @ _246=() @ Aggregate
    _214 = log::__private_api::log::<'_, (), log::__private_api::GlobalLogger>(move _215, move _216, move _238, move _239, move _246) -> [return: bb118, unwind: bb154] @ Call: FnDid: 178
}
bb 118 {
CleanUp: false
    StorageDead(_246) @ StorageDead
    StorageDead(_239) @ StorageDead
    StorageDead(_238) @ StorageDead
    StorageDead(_216) @ StorageDead
    StorageDead(_215) @ StorageDead
    StorageDead(_245) @ StorageDead
    StorageDead(_243) @ StorageDead
    StorageDead(_241) @ StorageDead
    StorageDead(_240) @ StorageDead
    StorageDead(_226) @ StorageDead
    drop(_225) -> [return: bb119, unwind: bb167] @ Drop
}
bb 119 {
CleanUp: false
    StorageDead(_225) @ StorageDead
    StorageDead(_223) @ StorageDead
    StorageDead(_221) @ StorageDead
    StorageDead(_217) @ StorageDead
    StorageDead(_214) @ StorageDead
    Assign((_204, const ())) @ _204=const () @ Use
    goto -> bb123 @ Goto
}
bb 120 {
CleanUp: false
    StorageDead(_213) @ StorageDead
    StorageDead(_212) @ StorageDead
    StorageDead(_211) @ StorageDead
    goto -> bb122 @ Goto
}
bb 121 {
CleanUp: false
    StorageDead(_208) @ StorageDead
    StorageDead(_207) @ StorageDead
    goto -> bb122 @ Goto
}
bb 122 {
CleanUp: false
    Assign((_204, const ())) @ _204=const () @ Use
    goto -> bb123 @ Goto
}
bb 123 {
CleanUp: false
    StorageDead(_210) @ StorageDead
    StorageDead(_206) @ StorageDead
    StorageDead(_205) @ StorageDead
    StorageDead(_204) @ StorageDead
    Assign((_132, const ())) @ _132=const () @ Use
    goto -> bb126 @ Goto
}
bb 124 {
CleanUp: false
    drop(_199) -> [return: bb125, unwind: bb167] @ Drop
}
bb 125 {
CleanUp: false
    StorageDead(_199) @ StorageDead
    StorageDead(_198) @ StorageDead
    Assign((_132, const ())) @ _132=const () @ Use
    goto -> bb126 @ Goto
}
bb 126 {
CleanUp: false
    StorageDead(_197) @ StorageDead
    StorageDead(_184) @ StorageDead
    goto -> bb127 @ Goto
}
bb 127 {
CleanUp: false
    StorageDead(_133) @ StorageDead
    StorageDead(_132) @ StorageDead
    StorageLive(_247) @ StorageLive
    StorageLive(_248) @ StorageLive
    StorageLive(_249) @ StorageLive
    StorageLive(_250) @ StorageLive
    Assign((_250, &mut _120)) @ _250=&mut _120 @ Ref
    _249 = <libs::spinlock::SpinLockGuard<'_, mm::page::PageManager> as core::ops::DerefMut>::deref_mut(move _250) -> [return: bb128, unwind: bb167] @ Call: FnDid: 3915
}
bb 128 {
CleanUp: false
    Assign((_248, &mut (*_249))) @ _248=&mut (*_249) @ Ref
    StorageDead(_250) @ StorageDead
    StorageLive(_251) @ StorageLive
    StorageLive(_252) @ StorageLive
    Assign((_252, &_130)) @ _252=&_130 @ Ref
    Assign((_251, &(*_252))) @ _251=&(*_252) @ Ref
    _247 = mm::page::PageManager::get(move _248, move _251) -> [return: bb129, unwind: bb167] @ Call: FnDid: 24306
}
bb 129 {
CleanUp: false
    Assign((_293, const true)) @ _293=const true @ Use
    StorageDead(_251) @ StorageDead
    StorageDead(_248) @ StorageDead
    Assign((_253, discriminant(_247))) @ _253=discriminant(_247) @ Discriminant
    switchInt(move _253) -> [1: bb130, otherwise: bb137] @ SwitchInt
}
bb 130 {
CleanUp: false
    StorageLive(_254) @ StorageLive
    Assign((_254, move ((_247 as Some).0: alloc::sync::Arc<mm::page::Page>))) @ _254=move ((_247 as Some).0: alloc::sync::Arc<mm::page::Page>) @ Use
    StorageLive(_255) @ StorageLive
    StorageLive(_256) @ StorageLive
    StorageLive(_257) @ StorageLive
    StorageLive(_258) @ StorageLive
    StorageLive(_259) @ StorageLive
    StorageLive(_260) @ StorageLive
    StorageLive(_261) @ StorageLive
    StorageLive(_262) @ StorageLive
    Assign((_262, &_254)) @ _262=&_254 @ Ref
    _261 = <alloc::sync::Arc<mm::page::Page> as lazy_static::__Deref>::deref(move _262) -> [return: bb131, unwind: bb153] @ Call: FnDid: 3903
}
bb 131 {
CleanUp: false
    Assign((_260, &(*_261))) @ _260=&(*_261) @ Ref
    StorageDead(_262) @ StorageDead
    _259 = mm::page::Page::write_irqsave(move _260) -> [return: bb132, unwind: bb153] @ Call: FnDid: 24337
}
bb 132 {
CleanUp: false
    Assign((_258, &mut _259)) @ _258=&mut _259 @ Ref
    _257 = <libs::rwlock::RwLockWriteGuard<'_, mm::page::InnerPage> as core::ops::DerefMut>::deref_mut(move _258) -> [return: bb133, unwind: bb152] @ Call: FnDid: 3915
}
bb 133 {
CleanUp: false
    Assign((_256, &mut (*_257))) @ _256=&mut (*_257) @ Ref
    StorageDead(_260) @ StorageDead
    StorageDead(_258) @ StorageDead
    StorageLive(_263) @ StorageLive
    StorageLive(_264) @ StorageLive
    Assign((_264, &_100)) @ _264=&_100 @ Ref
    _263 = <alloc::sync::Arc<mm::ucontext::LockedVMA> as core::clone::Clone>::clone(move _264) -> [return: bb134, unwind: bb152] @ Call: FnDid: 3116
}
bb 134 {
CleanUp: false
    StorageDead(_264) @ StorageDead
    _255 = mm::page::InnerPage::insert_vma(move _256, move _263) -> [return: bb135, unwind: bb152] @ Call: FnDid: 24340
}
bb 135 {
CleanUp: false
    StorageDead(_263) @ StorageDead
    StorageDead(_256) @ StorageDead
    drop(_259) -> [return: bb136, unwind: bb153] @ Drop
}
bb 136 {
CleanUp: false
    StorageDead(_261) @ StorageDead
    StorageDead(_259) @ StorageDead
    StorageDead(_257) @ StorageDead
    StorageDead(_255) @ StorageDead
    Assign((_125, const ())) @ _125=const () @ Use
    drop(_254) -> [return: bb138, unwind: bb164] @ Drop
}
bb 137 {
CleanUp: false
    Assign((_125, const ())) @ _125=const () @ Use
    goto -> bb162 @ Goto
}
bb 138 {
CleanUp: false
    StorageDead(_254) @ StorageDead
    goto -> bb162 @ Goto
}
bb 139 {
CleanUp: false
    Assign((_125, const ())) @ _125=const () @ Use
    goto -> bb140 @ Goto
}
bb 140 {
CleanUp: false
    StorageDead(_126) @ StorageDead
    StorageDead(_125) @ StorageDead
    StorageLive(_265) @ StorageLive
    StorageLive(_266) @ StorageLive
    StorageLive(_267) @ StorageLive
    StorageLive(_268) @ StorageLive
    Assign((_268, &_115)) @ _268=&_115 @ Ref
    _267 = mm::VirtAddr::data(move _268) -> [return: bb141, unwind: bb167] @ Call: FnDid: 25246
}
bb 141 {
CleanUp: false
    StorageDead(_268) @ StorageDead
    Assign((_269, AddWithOverflow(copy _267, const <arch::x86_64::mm::X86_64MMArch as mm::MemoryManagementArch>::PAGE_SIZE))) @ _269=AddWithOverflow(copy _267, const <arch::x86_64::mm::X86_64MMArch as mm::MemoryManagementArch>::PAGE_SIZE) @ BinaryOp
    assert(!move (_269.1: bool), "attempt to compute `{} + {}`, which would overflow", move _267, const <arch::x86_64::mm::X86_64MMArch as mm::MemoryManagementArch>::PAGE_SIZE) -> [success: bb142, unwind: bb167] @ Assert
}
bb 142 {
CleanUp: false
    Assign((_266, move (_269.0: usize))) @ _266=move (_269.0: usize) @ Use
    StorageDead(_267) @ StorageDead
    _265 = mm::VirtAddr::new(move _266) -> [return: bb143, unwind: bb167] @ Call: FnDid: 25245
}
bb 143 {
CleanUp: false
    StorageDead(_266) @ StorageDead
    Assign((_115, move _265)) @ _115=move _265 @ Use
    StorageDead(_265) @ StorageDead
    Assign((_63, const ())) @ _63=const () @ Use
    StorageDead(_122) @ StorageDead
    goto -> bb59 @ Goto
}
bb 144 {
CleanUp: false
    StorageDead(_124) @ StorageDead
    StorageDead(_123) @ StorageDead
    StorageLive(_271) @ StorageLive
    Assign((_121, const ())) @ _121=const () @ Use
    StorageDead(_271) @ StorageDead
    StorageDead(_122) @ StorageDead
    StorageDead(_121) @ StorageDead
    StorageLive(_273) @ StorageLive
    StorageLive(_274) @ StorageLive
    Assign((_295, const false)) @ _295=const false @ Use
    Assign((_274, move _120)) @ _274=move _120 @ Use
    _273 = core::mem::drop::<libs::spinlock::SpinLockGuard<'_, mm::page::PageManager>>(move _274) -> [return: bb145, unwind: bb167] @ Call: FnDid: 2323
}
bb 145 {
CleanUp: false
    StorageDead(_274) @ StorageDead
    StorageDead(_273) @ StorageDead
    StorageLive(_275) @ StorageLive
    StorageLive(_276) @ StorageLive
    Assign((_296, const false)) @ _296=const false @ Use
    Assign((_276, move _71)) @ _276=move _71 @ Use
    _275 = core::mem::drop::<libs::spinlock::SpinLockGuard<'_, mm::ucontext::VMA>>(move _276) -> [return: bb146, unwind: bb167] @ Call: FnDid: 2323
}
bb 146 {
CleanUp: false
    StorageDead(_276) @ StorageDead
    StorageDead(_275) @ StorageDead
    Assign((_64, const ())) @ _64=const () @ Use
    Assign((_295, const false)) @ _295=const false @ Use
    StorageDead(_120) @ StorageDead
    StorageDead(_118) @ StorageDead
    StorageDead(_117) @ StorageDead
    StorageDead(_116) @ StorageDead
    StorageDead(_115) @ StorageDead
    StorageDead(_113) @ StorageDead
    StorageDead(_111) @ StorageDead
    drop(_100) -> [return: bb147, unwind: bb169] @ Drop
}
bb 147 {
CleanUp: false
    StorageDead(_100) @ StorageDead
    StorageDead(_96) @ StorageDead
    StorageDead(_91) @ StorageDead
    StorageDead(_89) @ StorageDead
    StorageDead(_85) @ StorageDead
    Assign((_296, const false)) @ _296=const false @ Use
    StorageDead(_71) @ StorageDead
    StorageDead(_70) @ StorageDead
    StorageDead(_67) @ StorageDead
    StorageDead(_65) @ StorageDead
    StorageDead(_64) @ StorageDead
    Assign((_63, const ())) @ _63=const () @ Use
    goto -> bb30 @ Goto
}
bb 148 {
CleanUp: false
    StorageDead(_278) @ StorageDead
    StorageDead(_277) @ StorageDead
    StorageLive(_279) @ StorageLive
    StorageLive(_280) @ StorageLive
    Assign((_294, const false)) @ _294=const false @ Use
    Assign((_280, move _3)) @ _280=move _3 @ Use
    _279 = core::mem::drop::<exception::IrqFlagsGuard>(move _280) -> [return: bb149, unwind: bb173] @ Call: FnDid: 2323
}
bb 149 {
CleanUp: false
    StorageDead(_280) @ StorageDead
    StorageDead(_279) @ StorageDead
    StorageLive(_281) @ StorageLive
    Assign((_281, move _4)) @ _281=move _4 @ Use
    Assign((_0, core::result::Result::<alloc::sync::Arc<mm::ucontext::AddressSpace>, system_error::SystemError>::Ok(move _281))) @ _0=core::result::Result::<alloc::sync::Arc<mm::ucontext::AddressSpace>, system_error::SystemError>::Ok(move _281) @ Aggregate
    StorageDead(_281) @ StorageDead
    Assign((_298, const false)) @ _298=const false @ Use
    StorageDead(_12) @ StorageDead
    goto -> bb150 @ Goto
}
bb 150 {
CleanUp: false
    StorageDead(_4) @ StorageDead
    switchInt(copy _294) -> [0: bb151, otherwise: bb163] @ SwitchInt
}
bb 151 {
CleanUp: false
    Assign((_294, const false)) @ _294=const false @ Use
    StorageDead(_3) @ StorageDead
    return @ Return
}
bb 152 {
CleanUp: true
    drop(_259) -> [return: bb153, unwind terminate(cleanup)] @ Drop
}
bb 153 {
CleanUp: true
    drop(_254) -> [return: bb164, unwind terminate(cleanup)] @ Drop
}
bb 154 {
CleanUp: true
    drop(_225) -> [return: bb167, unwind terminate(cleanup)] @ Drop
}
bb 155 {
CleanUp: true
    drop(_199) -> [return: bb167, unwind terminate(cleanup)] @ Drop
}
bb 156 {
CleanUp: true
    drop(_162) -> [return: bb167, unwind terminate(cleanup)] @ Drop
}
bb 157 {
CleanUp: true
    drop(_136) -> [return: bb167, unwind terminate(cleanup)] @ Drop
}
bb 158 {
CleanUp: true
    drop(_100) -> [return: bb169, unwind terminate(cleanup)] @ Drop
}
bb 159 {
CleanUp: true
    drop(_4) -> [return: bb176, unwind terminate(cleanup)] @ Drop
}
bb 160 {
CleanUp: true
    resume @ UnwindResume
}
bb 161 {
CleanUp: false
    Assign((_303, discriminant(_189))) @ _303=discriminant(_189) @ Discriminant
    Assign((_292, const false)) @ _292=const false @ Use
    StorageDead(_189) @ StorageDead
    goto -> bb100 @ Goto
}
bb 162 {
CleanUp: false
    Assign((_305, discriminant(_247))) @ _305=discriminant(_247) @ Discriminant
    StorageDead(_252) @ StorageDead
    StorageDead(_249) @ StorageDead
    Assign((_293, const false)) @ _293=const false @ Use
    StorageDead(_247) @ StorageDead
    StorageDead(_131) @ StorageDead
    StorageDead(_130) @ StorageDead
    goto -> bb140 @ Goto
}
bb 163 {
CleanUp: false
    drop(_3) -> [return: bb151, unwind: bb160] @ Drop
}
bb 164 {
CleanUp: true
    Assign((_307, discriminant(_247))) @ _307=discriminant(_247) @ Discriminant
    goto -> bb167 @ Goto
}
bb 165 {
CleanUp: true
    Assign((_308, discriminant(_189))) @ _308=discriminant(_189) @ Discriminant
    goto -> bb167 @ Goto
}
bb 166 {
CleanUp: true
    drop(_120) -> [return: bb158, unwind terminate(cleanup)] @ Drop
}
bb 167 {
CleanUp: true
    switchInt(copy _295) -> [0: bb158, otherwise: bb166] @ SwitchInt
}
bb 168 {
CleanUp: true
    drop(_71) -> [return: bb173, unwind terminate(cleanup)] @ Drop
}
bb 169 {
CleanUp: true
    switchInt(copy _296) -> [0: bb173, otherwise: bb168] @ SwitchInt
}
bb 170 {
CleanUp: true
    drop(_27) -> [return: bb173, unwind terminate(cleanup)] @ Drop
}
bb 171 {
CleanUp: true
    switchInt(copy _297) -> [0: bb173, otherwise: bb170] @ SwitchInt
}
bb 172 {
CleanUp: true
    drop(_12) -> [return: bb159, unwind terminate(cleanup)] @ Drop
}
bb 173 {
CleanUp: true
    switchInt(copy _298) -> [0: bb159, otherwise: bb172] @ SwitchInt
}
bb 174 {
CleanUp: true
    Assign((_309, discriminant(_5))) @ _309=discriminant(_5) @ Discriminant
    goto -> bb176 @ Goto
}
bb 175 {
CleanUp: true
    drop(_3) -> [return: bb160, unwind terminate(cleanup)] @ Drop
}
bb 176 {
CleanUp: true
    switchInt(copy _294) -> [0: bb160, otherwise: bb175] @ SwitchInt
}

