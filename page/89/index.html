<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Report #89: Dragon Bugs</title>
    <link rel="stylesheet" href="../../style.css">
</head>
<body>
    <div class="container">
        <a href="../../index.html" class="back-link">← Back to Directory</a>
        
        <h1>
            Report #89
            
                 <span class="func-name">mm::ucontext::{impl#3}::try_clone</span>
            
        </h1>


        <div class="two-column">
            
                <div class="column">
                    <div class="file-header">
                        <h2>Log Content</h2>
                        <button class="copy-btn" onclick="copyText('logContent')">Copy</button>
                    </div>
                    <pre id="logContent" class="code-block scrollable">22:08:12|RAP|WARN|: Double free detected in function &#34;try_clone&#34;
warning: Double free detected during unwinding.
   --&gt; src/mm/ucontext.rs:181:1
    |
181 | / pub fn try_clone(&amp;mut self) -&gt; Result&lt;Arc&lt;AddressSpace&gt;, SystemError&gt; {
182 | |         let irq_guard = unsafe { CurrentIrqArch::save_and_disable_irq() };
183 | |         let new_addr_space = AddressSpace::new(false)?;
184 | |         let mut new_guard = new_addr_space.write();
185 | |
186 | |         // 仅拷贝用户栈的结构体信息（元数据），实际的用户栈页面内容会在下面的 VMA 循环中处理
187 | |         unsafe {
188 | |             new_guard.user_stack = Some(self.user_stack.as_ref().unwrap().clone_info_only());
189 | |         }
190 | |
191 | |         // 拷贝空洞
192 | |         new_guard.mappings.vm_holes = self.mappings.vm_holes.clone();
193 | |
194 | |         // 拷贝其他地址空间属性
195 | |         new_guard.brk = self.brk;
196 | |         new_guard.brk_start = self.brk_start;
197 | |         new_guard.mmap_min = self.mmap_min;
198 | |         new_guard.elf_brk = self.elf_brk;
199 | |         new_guard.elf_brk_start = self.elf_brk_start;
200 | |         new_guard.start_code = self.start_code;
201 | |         new_guard.end_code = self.end_code;
202 | |         new_guard.start_data = self.start_data;
203 | |         new_guard.end_data = self.end_data;
204 | |
205 | |         // 遍历父进程的每个VMA，根据VMA属性进行适当的复制
206 | |         // 参考 Linux: https://code.dragonos.org.cn/xref/linux-6.6.21/mm/memory.c#copy_page_range
207 | |         for vma in self.mappings.vmas.iter() {
208 | |             let vma_guard = vma.lock_irqsave();
209 | |
210 | |             // VM_DONTCOPY: 跳过不复制的VMA (例如 MADV_DONTFORK 标记的)
211 | |             if vma_guard.vm_flags().contains(VmFlags::VM_DONTCOPY) {
212 | |                 drop(vma_guard);
213 | |                 continue;
214 | |             }
215 | |
216 | |             let vm_flags = vma_guard.vm_flags();
217 | |             let is_shared = vm_flags.contains(VmFlags::VM_SHARED);
218 | |             let region = *vma_guard.region();
219 | |             let page_flags = vma_guard.flags();
220 | |
221 | |             // 创建新的VMA
222 | |             let new_vma = LockedVMA::new(vma_guard.clone_info_only());
223 | |             new_guard.mappings.vmas.insert(new_vma.clone());
224 | |
225 | |             // 根据VMA类型进行不同的页面复制策略
226 | |             let start_page = region.start();
227 | |             let end_page = region.end();
228 | |             let mut current_page = start_page;
229 | |
230 | |             let old_mapper = &amp;mut self.user_mapper.utable;
231 | |             let new_mapper = &amp;mut new_guard.user_mapper.utable;
232 | |             let mut page_manager_guard = page_manager_lock_irqsave();
233 | |
234 | |             while current_page &lt; end_page {
235 | |                 if let Some((phys_addr, old_flags)) = old_mapper.translate(current_page) {
236 | |                     unsafe {
237 | |                         if is_shared {
238 | |                             // 共享映射：直接映射到相同的物理页，不使用COW
239 | |                             // 保持原有的flags
240 | |                             if new_mapper
241 | |                                 .map_phys(current_page, phys_addr, page_flags)
242 | |                                 .is_none()
243 | |                             {
244 | |                                 warn!(&#34;Failed to map shared page at {:?} to phys {:?} in child process (current_pid: {:?})&#34;,
245 | |                                       current_page, phys_addr, ProcessManager::current_pcb().raw_pid());
246 | |                             }
247 | |                         } else {
248 | |                             // 私有映射：使用COW机制
249 | |                             // 将父进程和子进程的页表项都设置为只读
250 | |                             let cow_flags = page_flags.set_write(false);
251 | |
252 | |                             // 更新父进程的页表项为只读
253 | |                             if old_flags.has_write() {
254 | |                                 if let Some(flush) = old_mapper.remap(current_page, cow_flags) {
255 | |                                     flush.flush();
256 | |                                 }
257 | |                             }
258 | |
259 | |                             // 子进程也映射为只读
260 | |                             if new_mapper
261 | |                                 .map_phys(current_page, phys_addr, cow_flags)
262 | |                                 .is_none()
263 | |                             {
264 | |                                 warn!(&#34;Failed to map COW page at {:?} to phys {:?} in child process (current_pid: {:?})&#34;,
265 | |                                       current_page, phys_addr, ProcessManager::current_pcb().raw_pid());
266 | |                             }
267 | |                         }
268 | |                         // 为新进程的VMA添加反向映射
269 | |                         if let Some(page) = page_manager_guard.get(&amp;phys_addr) {
270 | |                             page.write_irqsave().insert_vma(new_vma.clone());
271 | |                         }
272 | |                     }
273 | |                 }
274 | |                 current_page = VirtAddr::new(current_page.data() + MMArch::PAGE_SIZE);
275 | |             }
276 | |             drop(page_manager_guard);
277 | |
278 | |             drop(vma_guard);
279 | |         }
280 | |
281 | |         drop(new_guard);
282 | |         drop(irq_guard);
283 | |         return Ok(new_addr_space);
284 | |     }
    | |_____- Double free (confidence 99%): Location in file src/mm/ucontext.rs line 181.
    | MIR detail: Value _278(_, src/mm/ucontext.rs:281) and _4(new_addr_space, src/mm/ucontext.rs:183) are alias.
    | MIR detail: _278(_, src/mm/ucontext.rs:281) is dropped at BB33(src/mm/ucontext.rs:281); _4(new_addr_space, src/mm/ucontext.rs:183) is dropped at BB159(src/mm/ucontext.rs:284).
    |
22:08:12|RAP|WARN|: Use-after-free detected in function &#34;try_clone&#34;
warning: Use-after-free detected.
   --&gt; src/mm/ucontext.rs:283:16
    |
181 | pub fn try_clone(&amp;mut self) -&gt; Result&lt;Arc&lt;AddressSpace&gt;, SystemError&gt; {
182 |         let irq_guard = unsafe { CurrentIrqArch::save_and_disable_irq() };
183 |         let new_addr_space = AddressSpace::new(false)?;
184 |         let mut new_guard = new_addr_space.write();
185 |
186 |         // 仅拷贝用户栈的结构体信息（元数据），实际的用户栈页面内容会在下面的 VMA 循环中处理
187 |         unsafe {
188 |             new_guard.user_stack = Some(self.user_stack.as_ref().unwrap().clone_info_only());
189 |         }
190 |
191 |         // 拷贝空洞
192 |         new_guard.mappings.vm_holes = self.mappings.vm_holes.clone();
193 |
194 |         // 拷贝其他地址空间属性
195 |         new_guard.brk = self.brk;
196 |         new_guard.brk_start = self.brk_start;
197 |         new_guard.mmap_min = self.mmap_min;
198 |         new_guard.elf_brk = self.elf_brk;
199 |         new_guard.elf_brk_start = self.elf_brk_start;
200 |         new_guard.start_code = self.start_code;
201 |         new_guard.end_code = self.end_code;
202 |         new_guard.start_data = self.start_data;
203 |         new_guard.end_data = self.end_data;
204 |
205 |         // 遍历父进程的每个VMA，根据VMA属性进行适当的复制
206 |         // 参考 Linux: https://code.dragonos.org.cn/xref/linux-6.6.21/mm/memory.c#copy_page_range
207 |         for vma in self.mappings.vmas.iter() {
208 |             let vma_guard = vma.lock_irqsave();
209 |
210 |             // VM_DONTCOPY: 跳过不复制的VMA (例如 MADV_DONTFORK 标记的)
211 |             if vma_guard.vm_flags().contains(VmFlags::VM_DONTCOPY) {
212 |                 drop(vma_guard);
213 |                 continue;
214 |             }
215 |
216 |             let vm_flags = vma_guard.vm_flags();
217 |             let is_shared = vm_flags.contains(VmFlags::VM_SHARED);
218 |             let region = *vma_guard.region();
219 |             let page_flags = vma_guard.flags();
220 |
221 |             // 创建新的VMA
222 |             let new_vma = LockedVMA::new(vma_guard.clone_info_only());
223 |             new_guard.mappings.vmas.insert(new_vma.clone());
224 |
225 |             // 根据VMA类型进行不同的页面复制策略
226 |             let start_page = region.start();
227 |             let end_page = region.end();
228 |             let mut current_page = start_page;
229 |
230 |             let old_mapper = &amp;mut self.user_mapper.utable;
231 |             let new_mapper = &amp;mut new_guard.user_mapper.utable;
232 |             let mut page_manager_guard = page_manager_lock_irqsave();
233 |
234 |             while current_page &lt; end_page {
235 |                 if let Some((phys_addr, old_flags)) = old_mapper.translate(current_page) {
236 |                     unsafe {
237 |                         if is_shared {
238 |                             // 共享映射：直接映射到相同的物理页，不使用COW
239 |                             // 保持原有的flags
240 |                             if new_mapper
241 |                                 .map_phys(current_page, phys_addr, page_flags)
242 |                                 .is_none()
243 |                             {
244 |                                 warn!(&#34;Failed to map shared page at {:?} to phys {:?} in child process (current_pid: {:?})&#34;,
245 |                                       current_page, phys_addr, ProcessManager::current_pcb().raw_pid());
246 |                             }
247 |                         } else {
248 |                             // 私有映射：使用COW机制
249 |                             // 将父进程和子进程的页表项都设置为只读
250 |                             let cow_flags = page_flags.set_write(false);
251 |
252 |                             // 更新父进程的页表项为只读
253 |                             if old_flags.has_write() {
254 |                                 if let Some(flush) = old_mapper.remap(current_page, cow_flags) {
255 |                                     flush.flush();
256 |                                 }
257 |                             }
258 |
259 |                             // 子进程也映射为只读
260 |                             if new_mapper
261 |                                 .map_phys(current_page, phys_addr, cow_flags)
262 |                                 .is_none()
263 |                             {
264 |                                 warn!(&#34;Failed to map COW page at {:?} to phys {:?} in child process (current_pid: {:?})&#34;,
265 |                                       current_page, phys_addr, ProcessManager::current_pcb().raw_pid());
266 |                             }
267 |                         }
268 |                         // 为新进程的VMA添加反向映射
269 |                         if let Some(page) = page_manager_guard.get(&amp;phys_addr) {
270 |                             page.write_irqsave().insert_vma(new_vma.clone());
271 |                         }
272 |                     }
273 |                 }
274 |                 current_page = VirtAddr::new(current_page.data() + MMArch::PAGE_SIZE);
275 |             }
276 |             drop(page_manager_guard);
277 |
278 |             drop(vma_guard);
279 |         }
280 |
281 |         drop(new_guard);
282 |         drop(irq_guard);
283 |         return Ok(new_addr_space);
    |                ------------------ Use-after-free (confidence 99%): Location in file src/mm/ucontext.rs line 283.
    | MIR detail: Value _278(_, src/mm/ucontext.rs:281) and _281(_, src/mm/ucontext.rs:283) are alias.
    | MIR detail: _278(_, src/mm/ucontext.rs:281) is dropped at BB33(src/mm/ucontext.rs:281); _281(_, src/mm/ucontext.rs:283) is used at BB149(src/mm/ucontext.rs:284).
284 |     }
    |
22:08:12|RAP|WARN|: Dangling pointer detected in function &#34;try_clone&#34;
warning: Use-after-free detected.
   --&gt; src/mm/ucontext.rs:283:19
    |
181 | pub fn try_clone(&amp;mut self) -&gt; Result&lt;Arc&lt;AddressSpace&gt;, SystemError&gt; {
182 |         let irq_guard = unsafe { CurrentIrqArch::save_and_disable_irq() };
183 |         let new_addr_space = AddressSpace::new(false)?;
184 |         let mut new_guard = new_addr_space.write();
185 |
186 |         // 仅拷贝用户栈的结构体信息（元数据），实际的用户栈页面内容会在下面的 VMA 循环中处理
187 |         unsafe {
188 |             new_guard.user_stack = Some(self.user_stack.as_ref().unwrap().clone_info_only());
189 |         }
190 |
191 |         // 拷贝空洞
192 |         new_guard.mappings.vm_holes = self.mappings.vm_holes.clone();
193 |
194 |         // 拷贝其他地址空间属性
195 |         new_guard.brk = self.brk;
196 |         new_guard.brk_start = self.brk_start;
197 |         new_guard.mmap_min = self.mmap_min;
198 |         new_guard.elf_brk = self.elf_brk;
199 |         new_guard.elf_brk_start = self.elf_brk_start;
200 |         new_guard.start_code = self.start_code;
201 |         new_guard.end_code = self.end_code;
202 |         new_guard.start_data = self.start_data;
203 |         new_guard.end_data = self.end_data;
204 |
205 |         // 遍历父进程的每个VMA，根据VMA属性进行适当的复制
206 |         // 参考 Linux: https://code.dragonos.org.cn/xref/linux-6.6.21/mm/memory.c#copy_page_range
207 |         for vma in self.mappings.vmas.iter() {
208 |             let vma_guard = vma.lock_irqsave();
209 |
210 |             // VM_DONTCOPY: 跳过不复制的VMA (例如 MADV_DONTFORK 标记的)
211 |             if vma_guard.vm_flags().contains(VmFlags::VM_DONTCOPY) {
212 |                 drop(vma_guard);
213 |                 continue;
214 |             }
215 |
216 |             let vm_flags = vma_guard.vm_flags();
217 |             let is_shared = vm_flags.contains(VmFlags::VM_SHARED);
218 |             let region = *vma_guard.region();
219 |             let page_flags = vma_guard.flags();
220 |
221 |             // 创建新的VMA
222 |             let new_vma = LockedVMA::new(vma_guard.clone_info_only());
223 |             new_guard.mappings.vmas.insert(new_vma.clone());
224 |
225 |             // 根据VMA类型进行不同的页面复制策略
226 |             let start_page = region.start();
227 |             let end_page = region.end();
228 |             let mut current_page = start_page;
229 |
230 |             let old_mapper = &amp;mut self.user_mapper.utable;
231 |             let new_mapper = &amp;mut new_guard.user_mapper.utable;
232 |             let mut page_manager_guard = page_manager_lock_irqsave();
233 |
234 |             while current_page &lt; end_page {
235 |                 if let Some((phys_addr, old_flags)) = old_mapper.translate(current_page) {
236 |                     unsafe {
237 |                         if is_shared {
238 |                             // 共享映射：直接映射到相同的物理页，不使用COW
239 |                             // 保持原有的flags
240 |                             if new_mapper
241 |                                 .map_phys(current_page, phys_addr, page_flags)
242 |                                 .is_none()
243 |                             {
244 |                                 warn!(&#34;Failed to map shared page at {:?} to phys {:?} in child process (current_pid: {:?})&#34;,
245 |                                       current_page, phys_addr, ProcessManager::current_pcb().raw_pid());
246 |                             }
247 |                         } else {
248 |                             // 私有映射：使用COW机制
249 |                             // 将父进程和子进程的页表项都设置为只读
250 |                             let cow_flags = page_flags.set_write(false);
251 |
252 |                             // 更新父进程的页表项为只读
253 |                             if old_flags.has_write() {
254 |                                 if let Some(flush) = old_mapper.remap(current_page, cow_flags) {
255 |                                     flush.flush();
256 |                                 }
257 |                             }
258 |
259 |                             // 子进程也映射为只读
260 |                             if new_mapper
261 |                                 .map_phys(current_page, phys_addr, cow_flags)
262 |                                 .is_none()
263 |                             {
264 |                                 warn!(&#34;Failed to map COW page at {:?} to phys {:?} in child process (current_pid: {:?})&#34;,
265 |                                       current_page, phys_addr, ProcessManager::current_pcb().raw_pid());
266 |                             }
267 |                         }
268 |                         // 为新进程的VMA添加反向映射
269 |                         if let Some(page) = page_manager_guard.get(&amp;phys_addr) {
270 |                             page.write_irqsave().insert_vma(new_vma.clone());
271 |                         }
272 |                     }
273 |                 }
274 |                 current_page = VirtAddr::new(current_page.data() + MMArch::PAGE_SIZE);
275 |             }
276 |             drop(page_manager_guard);
277 |
278 |             drop(vma_guard);
279 |         }
280 |
281 |         drop(new_guard);
282 |         drop(irq_guard);
283 |         return Ok(new_addr_space);
    |                   -------------- Use-after-free (confidence 99%): Location in file src/mm/ucontext.rs line 283.
    | MIR detail: Value _278(_, src/mm/ucontext.rs:281) and _4(new_addr_space, src/mm/ucontext.rs:183) are alias.
    | MIR detail: _278(_, src/mm/ucontext.rs:281) is dropped at BB33(src/mm/ucontext.rs:281); _4(new_addr_space, src/mm/ucontext.rs:183) is used at BB149(src/mm/ucontext.rs:284).
284 |     }
    |
warning: Dangling pointer detected.
   --&gt; src/mm/ucontext.rs:181:1
    |
181 | / pub fn try_clone(&amp;mut self) -&gt; Result&lt;Arc&lt;AddressSpace&gt;, SystemError&gt; {
182 | |         let irq_guard = unsafe { CurrentIrqArch::save_and_disable_irq() };
183 | |         let new_addr_space = AddressSpace::new(false)?;
184 | |         let mut new_guard = new_addr_space.write();
185 | |
186 | |         // 仅拷贝用户栈的结构体信息（元数据），实际的用户栈页面内容会在下面的 VMA 循环中处理
187 | |         unsafe {
188 | |             new_guard.user_stack = Some(self.user_stack.as_ref().unwrap().clone_info_only());
189 | |         }
190 | |
191 | |         // 拷贝空洞
192 | |         new_guard.mappings.vm_holes = self.mappings.vm_holes.clone();
193 | |
194 | |         // 拷贝其他地址空间属性
195 | |         new_guard.brk = self.brk;
196 | |         new_guard.brk_start = self.brk_start;
197 | |         new_guard.mmap_min = self.mmap_min;
198 | |         new_guard.elf_brk = self.elf_brk;
199 | |         new_guard.elf_brk_start = self.elf_brk_start;
200 | |         new_guard.start_code = self.start_code;
201 | |         new_guard.end_code = self.end_code;
202 | |         new_guard.start_data = self.start_data;
203 | |         new_guard.end_data = self.end_data;
204 | |
205 | |         // 遍历父进程的每个VMA，根据VMA属性进行适当的复制
206 | |         // 参考 Linux: https://code.dragonos.org.cn/xref/linux-6.6.21/mm/memory.c#copy_page_range
207 | |         for vma in self.mappings.vmas.iter() {
208 | |             let vma_guard = vma.lock_irqsave();
209 | |
210 | |             // VM_DONTCOPY: 跳过不复制的VMA (例如 MADV_DONTFORK 标记的)
211 | |             if vma_guard.vm_flags().contains(VmFlags::VM_DONTCOPY) {
212 | |                 drop(vma_guard);
213 | |                 continue;
214 | |             }
215 | |
216 | |             let vm_flags = vma_guard.vm_flags();
217 | |             let is_shared = vm_flags.contains(VmFlags::VM_SHARED);
218 | |             let region = *vma_guard.region();
219 | |             let page_flags = vma_guard.flags();
220 | |
221 | |             // 创建新的VMA
222 | |             let new_vma = LockedVMA::new(vma_guard.clone_info_only());
223 | |             new_guard.mappings.vmas.insert(new_vma.clone());
224 | |
225 | |             // 根据VMA类型进行不同的页面复制策略
226 | |             let start_page = region.start();
227 | |             let end_page = region.end();
228 | |             let mut current_page = start_page;
229 | |
230 | |             let old_mapper = &amp;mut self.user_mapper.utable;
231 | |             let new_mapper = &amp;mut new_guard.user_mapper.utable;
232 | |             let mut page_manager_guard = page_manager_lock_irqsave();
233 | |
234 | |             while current_page &lt; end_page {
235 | |                 if let Some((phys_addr, old_flags)) = old_mapper.translate(current_page) {
236 | |                     unsafe {
237 | |                         if is_shared {
238 | |                             // 共享映射：直接映射到相同的物理页，不使用COW
239 | |                             // 保持原有的flags
240 | |                             if new_mapper
241 | |                                 .map_phys(current_page, phys_addr, page_flags)
242 | |                                 .is_none()
243 | |                             {
244 | |                                 warn!(&#34;Failed to map shared page at {:?} to phys {:?} in child process (current_pid: {:?})&#34;,
245 | |                                       current_page, phys_addr, ProcessManager::current_pcb().raw_pid());
246 | |                             }
247 | |                         } else {
248 | |                             // 私有映射：使用COW机制
249 | |                             // 将父进程和子进程的页表项都设置为只读
250 | |                             let cow_flags = page_flags.set_write(false);
251 | |
252 | |                             // 更新父进程的页表项为只读
253 | |                             if old_flags.has_write() {
254 | |                                 if let Some(flush) = old_mapper.remap(current_page, cow_flags) {
255 | |                                     flush.flush();
256 | |                                 }
257 | |                             }
258 | |
259 | |                             // 子进程也映射为只读
260 | |                             if new_mapper
261 | |                                 .map_phys(current_page, phys_addr, cow_flags)
262 | |                                 .is_none()
263 | |                             {
264 | |                                 warn!(&#34;Failed to map COW page at {:?} to phys {:?} in child process (current_pid: {:?})&#34;,
265 | |                                       current_page, phys_addr, ProcessManager::current_pcb().raw_pid());
266 | |                             }
267 | |                         }
268 | |                         // 为新进程的VMA添加反向映射
269 | |                         if let Some(page) = page_manager_guard.get(&amp;phys_addr) {
270 | |                             page.write_irqsave().insert_vma(new_vma.clone());
271 | |                         }
272 | |                     }
273 | |                 }
274 | |                 current_page = VirtAddr::new(current_page.data() + MMArch::PAGE_SIZE);
275 | |             }
276 | |             drop(page_manager_guard);
277 | |
278 | |             drop(vma_guard);
279 | |         }
280 | |
281 | |         drop(new_guard);
282 | |         drop(irq_guard);
283 | |         return Ok(new_addr_space);
284 | |     }
    | |_____- Dangling pointer (confidence 99%): Location in file src/mm/ucontext.rs line 181.
    | MIR detail: Value _278(_, src/mm/ucontext.rs:281) and _0(_, src/mm/ucontext.rs:181) are alias.
    | MIR detail: _278(_, src/mm/ucontext.rs:281) is dropped at BB33(src/mm/ucontext.rs:281); _0(_, src/mm/ucontext.rs:181) became dangling.
    |
render dot for DefId(0:25070 ~ dragonos_kernel[9e38]::mm::ucontext::{impl#3}::try_clone)
</pre>
                </div>
            

            
                <div class="column">
                    <div class="file-header">
                        <h2>MIR Content</h2>
                        <button class="copy-btn" onclick="copyText('mirContent')">Copy</button>
                    </div>
                    <div id="mirContent" class="mir-content scrollable">bb0 at src/mm/ucontext.rs:182:13: 182:22
bb1 at src/mm/ucontext.rs:183:13: 183:27
bb3 at src/mm/ucontext.rs:183:54: 183:55
bb5 at src/mm/ucontext.rs:183:30: 183:55
bb6 at src/mm/ucontext.rs:183:54: 183:55
bb7 at src/mm/ucontext.rs:183:54: 183:55
bb8 at src/mm/ucontext.rs:184:29: 184:43
bb9 at src/mm/ucontext.rs:184:29: 184:43
bb10 at src/mm/ucontext.rs:184:50: 184:51
bb11 at src/mm/ucontext.rs:188:64: 188:65
bb12 at src/mm/ucontext.rs:188:41: 188:74
bb13 at src/mm/ucontext.rs:188:91: 188:92
bb14 at src/mm/ucontext.rs:188:21: 188:22
bb15 at src/mm/ucontext.rs:192:68: 192:69
bb16 at src/mm/ucontext.rs:192:17: 192:18
bb17 at src/mm/ucontext.rs:192:9: 192:36
bb18 at src/mm/ucontext.rs:192:9: 192:36
bb19 at src/mm/ucontext.rs:195:17: 195:18
bb20 at src/mm/ucontext.rs:196:17: 196:18
bb21 at src/mm/ucontext.rs:197:17: 197:18
bb22 at src/mm/ucontext.rs:198:17: 198:18
bb23 at src/mm/ucontext.rs:199:17: 199:18
bb24 at src/mm/ucontext.rs:200:17: 200:18
bb25 at src/mm/ucontext.rs:201:17: 201:18
bb26 at src/mm/ucontext.rs:202:17: 202:18
bb27 at src/mm/ucontext.rs:203:17: 203:18
bb28 at src/mm/ucontext.rs:207:44: 207:45
bb29 at src/mm/ucontext.rs:207:44: 207:45
bb30 at src/mm/ucontext.rs:207:20: 207:45
bb31 at src/mm/ucontext.rs:207:44: 207:45
bb32 at src/mm/ucontext.rs:207:13: 207:16
bb33 at src/mm/ucontext.rs:207:9: 279:10
bb34 at src/mm/ucontext.rs:208:29: 208:32
bb35 at src/mm/ucontext.rs:208:46: 208:47
bb36 at src/mm/ucontext.rs:211:16: 211:25
bb37 at src/mm/ucontext.rs:211:16: 211:36
bb39 at src/mm/ucontext.rs:211:66: 211:67
bb40 at src/mm/ucontext.rs:212:31: 212:32
bb41 at src/mm/ucontext.rs:211:66: 211:67
bb42 at src/mm/ucontext.rs:216:28: 216:37
bb43 at src/mm/ucontext.rs:216:47: 216:48
bb44 at src/mm/ucontext.rs:217:65: 217:66
bb45 at src/mm/ucontext.rs:218:27: 218:36
bb46 at src/mm/ucontext.rs:218:44: 218:45
bb47 at src/mm/ucontext.rs:219:30: 219:39
bb48 at src/mm/ucontext.rs:219:46: 219:47
bb49 at src/mm/ucontext.rs:222:42: 222:51
bb50 at src/mm/ucontext.rs:222:68: 222:69
bb51 at src/mm/ucontext.rs:222:69: 222:70
bb52 at src/mm/ucontext.rs:223:21: 223:22
bb53 at src/mm/ucontext.rs:223:58: 223:59
bb54 at src/mm/ucontext.rs:223:59: 223:60
bb55 at src/mm/ucontext.rs:226:43: 226:44
bb56 at src/mm/ucontext.rs:227:39: 227:40
bb57 at src/mm/ucontext.rs:231:43: 231:44
bb58 at src/mm/ucontext.rs:234:13: 275:14
bb59 at src/mm/ucontext.rs:234:19: 234:42
bb61 at src/mm/ucontext.rs:234:41: 234:42
bb62 at src/mm/ucontext.rs:235:88: 235:89
bb63 at src/mm/ucontext.rs:235:30: 235:39
bb64 at src/mm/ucontext.rs:240:32: 242:43
bb65 at src/mm/ucontext.rs:240:32: 241:79
bb68 at src/mm/ucontext.rs:242:42: 242:43
bb70 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:42: 137:43
bb71 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:54: 137:73
bb73 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:72: 137:73
bb74 at src/mm/ucontext.rs:245:64: 245:93
bb75 at src/mm/ucontext.rs:245:64: 245:93
bb76 at src/mm/ucontext.rs:245:102: 245:103
bb77 at src/mm/ucontext.rs:244:72: 244:73
bb78 at src/mm/ucontext.rs:244:85: 244:86
bb79 at src/mm/ucontext.rs:244:121: 244:122
bb80 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:140:61: 140:62
bb81 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:142:67: 142:95
bb82 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:144:13: 144:14
bb83 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:144:14: 144:15
bb84 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:72: 137:73
bb85 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:42: 137:43
bb86 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:145:10: 145:10
bb87 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:145:9: 145:10
bb89 at src/mm/ucontext.rs:242:42: 242:43
bb90 at src/mm/ucontext.rs:246:29: 246:30
bb91 at src/mm/ucontext.rs:250:33: 250:42
bb92 at src/mm/ucontext.rs:250:71: 250:72
bb94 at src/mm/ucontext.rs:253:52: 253:53
bb95 at src/mm/ucontext.rs:254:94: 254:95
bb96 at src/mm/ucontext.rs:254:45: 254:50
bb97 at src/mm/ucontext.rs:255:49: 255:50
bb98 at src/mm/ucontext.rs:256:34: 256:34
bb99 at src/mm/ucontext.rs:253:52: 253:53
bb100 at src/mm/ucontext.rs:257:29: 257:30
bb101 at src/mm/ucontext.rs:260:32: 261:78
bb104 at src/mm/ucontext.rs:262:42: 262:43
bb106 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:42: 137:43
bb107 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:54: 137:73
bb109 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:72: 137:73
bb110 at src/mm/ucontext.rs:265:64: 265:93
bb111 at src/mm/ucontext.rs:265:64: 265:93
bb112 at src/mm/ucontext.rs:265:102: 265:103
bb113 at src/mm/ucontext.rs:264:69: 264:70
bb114 at src/mm/ucontext.rs:264:82: 264:83
bb115 at src/mm/ucontext.rs:264:118: 264:119
bb116 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:140:61: 140:62
bb117 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:142:67: 142:95
bb118 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:144:13: 144:14
bb119 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:144:14: 144:15
bb120 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:72: 137:73
bb121 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:137:42: 137:43
bb122 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:145:10: 145:10
bb123 at /home/yuzhili/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/log-0.4.27/src/macros.rs:145:9: 145:10
bb125 at src/mm/ucontext.rs:262:42: 262:43
bb126 at src/mm/ucontext.rs:266:29: 266:30
bb127 at src/mm/ucontext.rs:267:25: 267:26
bb128 at src/mm/ucontext.rs:269:45: 269:63
bb129 at src/mm/ucontext.rs:269:78: 269:79
bb130 at src/mm/ucontext.rs:269:37: 269:41
bb131 at src/mm/ucontext.rs:270:29: 270:33
bb132 at src/mm/ucontext.rs:270:29: 270:49
bb133 at src/mm/ucontext.rs:270:29: 270:49
bb134 at src/mm/ucontext.rs:270:75: 270:76
bb135 at src/mm/ucontext.rs:270:76: 270:77
bb136 at src/mm/ucontext.rs:270:77: 270:78
bb137 at src/mm/ucontext.rs:271:26: 271:26
bb138 at src/mm/ucontext.rs:271:25: 271:26
bb139 at src/mm/ucontext.rs:273:18: 273:18
bb140 at src/mm/ucontext.rs:273:17: 273:18
bb141 at src/mm/ucontext.rs:274:64: 274:65
bb142 at src/mm/ucontext.rs:274:46: 274:85
bb143 at src/mm/ucontext.rs:274:85: 274:86
bb144 at src/mm/ucontext.rs:234:41: 234:42
bb145 at src/mm/ucontext.rs:276:36: 276:37
bb146 at src/mm/ucontext.rs:278:27: 278:28
bb147 at src/mm/ucontext.rs:279:9: 279:10
bb148 at src/mm/ucontext.rs:281:23: 281:24
bb149 at src/mm/ucontext.rs:282:23: 282:24
bb150 at src/mm/ucontext.rs:284:5: 284:6
bb151 at src/mm/ucontext.rs:284:5: 284:6
bb161 at src/mm/ucontext.rs:257:29: 257:30
bb162 at src/mm/ucontext.rs:273:17: 273:18
bb164 at src/mm/ucontext.rs:273:17: 273:18
bb165 at src/mm/ucontext.rs:257:29: 257:30
bb174 at src/mm/ucontext.rs:183:55: 183:56
fn mm::ucontext::InnerAddressSpace::try_clone
_0:  @ core::result::Result&lt;alloc::sync::Arc&lt;mm::ucontext::AddressSpace, alloc::alloc::Global&gt;, system_error::SystemError&gt; 
_1:  @ &amp;&#39;{erased} mut mm::ucontext::InnerAddressSpace 
_2:  @ ! 
_3:  @ exception::IrqFlagsGuard 
_4:  @ alloc::sync::Arc&lt;mm::ucontext::AddressSpace, alloc::alloc::Global&gt; 
_5:  @ core::ops::ControlFlow&lt;core::result::Result&lt;core::convert::Infallible, system_error::SystemError&gt;, alloc::sync::Arc&lt;mm::ucontext::AddressSpace, alloc::alloc::Global&gt;&gt; 
_6:  @ core::result::Result&lt;alloc::sync::Arc&lt;mm::ucontext::AddressSpace, alloc::alloc::Global&gt;, system_error::SystemError&gt; 
_7:  @ isize 
_8:  @ core::result::Result&lt;core::convert::Infallible, system_error::SystemError&gt; 
_9:  @ ! 
_10:  @ core::result::Result&lt;core::convert::Infallible, system_error::SystemError&gt; 
_11:  @ alloc::sync::Arc&lt;mm::ucontext::AddressSpace, alloc::alloc::Global&gt; 
_12:  @ libs::rwlock::RwLockWriteGuard&lt;&#39;{erased}, mm::ucontext::InnerAddressSpace&gt; 
_13:  @ &amp;&#39;{erased} libs::rwlock::RwLock&lt;mm::ucontext::InnerAddressSpace&gt; 
_14:  @ &amp;&#39;{erased} libs::rwlock::RwLock&lt;mm::ucontext::InnerAddressSpace&gt; 
_15:  @ &amp;&#39;{erased} mm::ucontext::AddressSpace 
_16:  @ &amp;&#39;{erased} mm::ucontext::AddressSpace 
_17:  @ &amp;&#39;{erased} alloc::sync::Arc&lt;mm::ucontext::AddressSpace, alloc::alloc::Global&gt; 
_18:  @ () 
_19:  @ core::option::Option&lt;mm::ucontext::UserStack&gt; 
_20:  @ mm::ucontext::UserStack 
_21:  @ &amp;&#39;{erased} mm::ucontext::UserStack 
_22:  @ &amp;&#39;{erased} mm::ucontext::UserStack 
_23:  @ core::option::Option&lt;&amp;&#39;{erased} mm::ucontext::UserStack&gt; 
_24:  @ &amp;&#39;{erased} core::option::Option&lt;mm::ucontext::UserStack&gt; 
_25:  @ &amp;&#39;{erased} mut mm::ucontext::InnerAddressSpace 
_26:  @ &amp;&#39;{erased} mut libs::rwlock::RwLockWriteGuard&lt;&#39;{erased}, mm::ucontext::InnerAddressSpace&gt; 
_27:  @ alloc::collections::BTreeMap&lt;mm::VirtAddr, usize, alloc::alloc::Global&gt; 
_28:  @ &amp;&#39;{erased} alloc::collections::BTreeMap&lt;mm::VirtAddr, usize, alloc::alloc::Global&gt; 
_29:  @ &amp;&#39;{erased} mut mm::ucontext::InnerAddressSpace 
_30:  @ &amp;&#39;{erased} mut libs::rwlock::RwLockWriteGuard&lt;&#39;{erased}, mm::ucontext::InnerAddressSpace&gt; 
_31:  @ mm::VirtAddr 
_32:  @ &amp;&#39;{erased} mut mm::ucontext::InnerAddressSpace 
_33:  @ &amp;&#39;{erased} mut libs::rwlock::RwLockWriteGuard&lt;&#39;{erased}, mm::ucontext::InnerAddressSpace&gt; 
_34:  @ mm::VirtAddr 
_35:  @ &amp;&#39;{erased} mut mm::ucontext::InnerAddressSpace 
_36:  @ &amp;&#39;{erased} mut libs::rwlock::RwLockWriteGuard&lt;&#39;{erased}, mm::ucontext::InnerAddressSpace&gt; 
_37:  @ mm::VirtAddr 
_38:  @ &amp;&#39;{erased} mut mm::ucontext::InnerAddressSpace 
_39:  @ &amp;&#39;{erased} mut libs::rwlock::RwLockWriteGuard&lt;&#39;{erased}, mm::ucontext::InnerAddressSpace&gt; 
_40:  @ mm::VirtAddr 
_41:  @ &amp;&#39;{erased} mut mm::ucontext::InnerAddressSpace 
_42:  @ &amp;&#39;{erased} mut libs::rwlock::RwLockWriteGuard&lt;&#39;{erased}, mm::ucontext::InnerAddressSpace&gt; 
_43:  @ mm::VirtAddr 
_44:  @ &amp;&#39;{erased} mut mm::ucontext::InnerAddressSpace 
_45:  @ &amp;&#39;{erased} mut libs::rwlock::RwLockWriteGuard&lt;&#39;{erased}, mm::ucontext::InnerAddressSpace&gt; 
_46:  @ mm::VirtAddr 
_47:  @ &amp;&#39;{erased} mut mm::ucontext::InnerAddressSpace 
_48:  @ &amp;&#39;{erased} mut libs::rwlock::RwLockWriteGuard&lt;&#39;{erased}, mm::ucontext::InnerAddressSpace&gt; 
_49:  @ mm::VirtAddr 
_50:  @ &amp;&#39;{erased} mut mm::ucontext::InnerAddressSpace 
_51:  @ &amp;&#39;{erased} mut libs::rwlock::RwLockWriteGuard&lt;&#39;{erased}, mm::ucontext::InnerAddressSpace&gt; 
_52:  @ mm::VirtAddr 
_53:  @ &amp;&#39;{erased} mut mm::ucontext::InnerAddressSpace 
_54:  @ &amp;&#39;{erased} mut libs::rwlock::RwLockWriteGuard&lt;&#39;{erased}, mm::ucontext::InnerAddressSpace&gt; 
_55:  @ mm::VirtAddr 
_56:  @ &amp;&#39;{erased} mut mm::ucontext::InnerAddressSpace 
_57:  @ &amp;&#39;{erased} mut libs::rwlock::RwLockWriteGuard&lt;&#39;{erased}, mm::ucontext::InnerAddressSpace&gt; 
_58:  @ () 
_59:  @ hashbrown::hash_set::Iter&lt;&#39;{erased}, alloc::sync::Arc&lt;mm::ucontext::LockedVMA, alloc::alloc::Global&gt;&gt; 
_60:  @ hashbrown::hash_set::Iter&lt;&#39;{erased}, alloc::sync::Arc&lt;mm::ucontext::LockedVMA, alloc::alloc::Global&gt;&gt; 
_61:  @ &amp;&#39;{erased} hashbrown::HashSet&lt;alloc::sync::Arc&lt;mm::ucontext::LockedVMA, alloc::alloc::Global&gt;, core::hash::BuildHasherDefault&lt;ahash::fallback_hash::AHasher&gt;, hashbrown::raw::alloc::inner::Global&gt; 
_62:  @ hashbrown::hash_set::Iter&lt;&#39;{erased}, alloc::sync::Arc&lt;mm::ucontext::LockedVMA, alloc::alloc::Global&gt;&gt; 
_63:  @ () 
_64:  @ () 
_65:  @ core::option::Option&lt;&amp;&#39;{erased} alloc::sync::Arc&lt;mm::ucontext::LockedVMA, alloc::alloc::Global&gt;&gt; 
_66:  @ &amp;&#39;{erased} mut hashbrown::hash_set::Iter&lt;&#39;{erased}, alloc::sync::Arc&lt;mm::ucontext::LockedVMA, alloc::alloc::Global&gt;&gt; 
_67:  @ &amp;&#39;{erased} mut hashbrown::hash_set::Iter&lt;&#39;{erased}, alloc::sync::Arc&lt;mm::ucontext::LockedVMA, alloc::alloc::Global&gt;&gt; 
_68:  @ isize 
_69:  @ ! 
_70:  @ &amp;&#39;{erased} alloc::sync::Arc&lt;mm::ucontext::LockedVMA, alloc::alloc::Global&gt; 
_71:  @ libs::spinlock::SpinLockGuard&lt;&#39;{erased}, mm::ucontext::VMA&gt; 
_72:  @ &amp;&#39;{erased} mm::ucontext::LockedVMA 
_73:  @ &amp;&#39;{erased} mm::ucontext::LockedVMA 
_74:  @ &amp;&#39;{erased} alloc::sync::Arc&lt;mm::ucontext::LockedVMA, alloc::alloc::Global&gt; 
_75:  @ () 
_76:  @ bool 
_77:  @ &amp;&#39;{erased} mm::VmFlags 
_78:  @ &amp;&#39;{erased} mm::VmFlags 
_79:  @ &amp;&#39;{erased} mm::ucontext::VMA 
_80:  @ &amp;&#39;{erased} mm::ucontext::VMA 
_81:  @ &amp;&#39;{erased} libs::spinlock::SpinLockGuard&lt;&#39;{erased}, mm::ucontext::VMA&gt; 
_82:  @ ! 
_83:  @ () 
_84:  @ libs::spinlock::SpinLockGuard&lt;&#39;{erased}, mm::ucontext::VMA&gt; 
_85:  @ &amp;&#39;{erased} mm::VmFlags 
_86:  @ &amp;&#39;{erased} mm::ucontext::VMA 
_87:  @ &amp;&#39;{erased} mm::ucontext::VMA 
_88:  @ &amp;&#39;{erased} libs::spinlock::SpinLockGuard&lt;&#39;{erased}, mm::ucontext::VMA&gt; 
_89:  @ bool 
_90:  @ &amp;&#39;{erased} mm::VmFlags 
_91:  @ mm::VirtRegion 
_92:  @ &amp;&#39;{erased} mm::VirtRegion 
_93:  @ &amp;&#39;{erased} mm::ucontext::VMA 
_94:  @ &amp;&#39;{erased} mm::ucontext::VMA 
_95:  @ &amp;&#39;{erased} libs::spinlock::SpinLockGuard&lt;&#39;{erased}, mm::ucontext::VMA&gt; 
_96:  @ mm::page::EntryFlags&lt;arch::x86_64::mm::X86_64MMArch&gt; 
_97:  @ &amp;&#39;{erased} mm::ucontext::VMA 
_98:  @ &amp;&#39;{erased} mm::ucontext::VMA 
_99:  @ &amp;&#39;{erased} libs::spinlock::SpinLockGuard&lt;&#39;{erased}, mm::ucontext::VMA&gt; 
_100:  @ alloc::sync::Arc&lt;mm::ucontext::LockedVMA, alloc::alloc::Global&gt; 
_101:  @ mm::ucontext::VMA 
_102:  @ &amp;&#39;{erased} mm::ucontext::VMA 
_103:  @ &amp;&#39;{erased} mm::ucontext::VMA 
_104:  @ &amp;&#39;{erased} libs::spinlock::SpinLockGuard&lt;&#39;{erased}, mm::ucontext::VMA&gt; 
_105:  @ bool 
_106:  @ &amp;&#39;{erased} mut hashbrown::HashSet&lt;alloc::sync::Arc&lt;mm::ucontext::LockedVMA, alloc::alloc::Global&gt;, core::hash::BuildHasherDefault&lt;ahash::fallback_hash::AHasher&gt;, hashbrown::raw::alloc::inner::Global&gt; 
_107:  @ &amp;&#39;{erased} mut mm::ucontext::InnerAddressSpace 
_108:  @ &amp;&#39;{erased} mut libs::rwlock::RwLockWriteGuard&lt;&#39;{erased}, mm::ucontext::InnerAddressSpace&gt; 
_109:  @ alloc::sync::Arc&lt;mm::ucontext::LockedVMA, alloc::alloc::Global&gt; 
_110:  @ &amp;&#39;{erased} alloc::sync::Arc&lt;mm::ucontext::LockedVMA, alloc::alloc::Global&gt; 
_111:  @ mm::VirtAddr 
_112:  @ &amp;&#39;{erased} mm::VirtRegion 
_113:  @ mm::VirtAddr 
_114:  @ &amp;&#39;{erased} mm::VirtRegion 
_115:  @ mm::VirtAddr 
_116:  @ &amp;&#39;{erased} mut mm::page::PageMapper&lt;arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator&gt; 
_117:  @ &amp;&#39;{erased} mut mm::page::PageMapper&lt;arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator&gt; 
_118:  @ &amp;&#39;{erased} mut mm::ucontext::InnerAddressSpace 
_119:  @ &amp;&#39;{erased} mut libs::rwlock::RwLockWriteGuard&lt;&#39;{erased}, mm::ucontext::InnerAddressSpace&gt; 
_120:  @ libs::spinlock::SpinLockGuard&lt;&#39;{erased}, mm::page::PageManager&gt; 
_121:  @ () 
_122:  @ bool 
_123:  @ &amp;&#39;{erased} mm::VirtAddr 
_124:  @ &amp;&#39;{erased} mm::VirtAddr 
_125:  @ () 
_126:  @ core::option::Option&lt;(mm::PhysAddr, mm::page::EntryFlags&lt;arch::x86_64::mm::X86_64MMArch&gt;)&gt; 
_127:  @ &amp;&#39;{erased} mm::page::PageMapper&lt;arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator&gt; 
_128:  @ mm::VirtAddr 
_129:  @ isize 
_130:  @ mm::PhysAddr 
_131:  @ mm::page::EntryFlags&lt;arch::x86_64::mm::X86_64MMArch&gt; 
_132:  @ () 
_133:  @ bool 
_134:  @ bool 
_135:  @ &amp;&#39;{erased} core::option::Option&lt;mm::page::PageFlush&lt;arch::x86_64::mm::X86_64MMArch&gt;&gt; 
_136:  @ core::option::Option&lt;mm::page::PageFlush&lt;arch::x86_64::mm::X86_64MMArch&gt;&gt; 
_137:  @ &amp;&#39;{erased} mut mm::page::PageMapper&lt;arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator&gt; 
_138:  @ mm::VirtAddr 
_139:  @ mm::PhysAddr 
_140:  @ mm::page::EntryFlags&lt;arch::x86_64::mm::X86_64MMArch&gt; 
_141:  @ () 
_142:  @ log::Level 
_143:  @ bool 
_144:  @ &amp;&#39;{erased} log::Level 
_145:  @ &amp;&#39;{erased} log::LevelFilter 
_146:  @ log::LevelFilter 
_147:  @ bool 
_148:  @ &amp;&#39;{erased} log::Level 
_149:  @ &amp;&#39;{erased} log::LevelFilter 
_150:  @ log::LevelFilter 
_151:  @ () 
_152:  @ log::__private_api::GlobalLogger 
_153:  @ core::fmt::Arguments&lt;&#39;{erased}&gt; 
_154:  @ (&amp;&#39;{erased} mm::VirtAddr, &amp;&#39;{erased} mm::PhysAddr, &amp;&#39;{erased} process::RawPid) 
_155:  @ &amp;&#39;{erased} mm::VirtAddr 
_156:  @ &amp;&#39;{erased} mm::PhysAddr 
_157:  @ &amp;&#39;{erased} process::RawPid 
_158:  @ process::RawPid 
_159:  @ &amp;&#39;{erased} process::ProcessControlBlock 
_160:  @ &amp;&#39;{erased} process::ProcessControlBlock 
_161:  @ &amp;&#39;{erased} alloc::sync::Arc&lt;process::ProcessControlBlock, alloc::alloc::Global&gt; 
_162:  @ alloc::sync::Arc&lt;process::ProcessControlBlock, alloc::alloc::Global&gt; 
_163:  @ [core::fmt::rt::Argument&lt;&#39;{erased}&gt;; 3_usize] 
_164:  @ core::fmt::rt::Argument&lt;&#39;{erased}&gt; 
_165:  @ &amp;&#39;{erased} mm::VirtAddr 
_166:  @ core::fmt::rt::Argument&lt;&#39;{erased}&gt; 
_167:  @ &amp;&#39;{erased} mm::PhysAddr 
_168:  @ core::fmt::rt::Argument&lt;&#39;{erased}&gt; 
_169:  @ &amp;&#39;{erased} process::RawPid 
_170:  @ &amp;&#39;{erased} [&amp;&#39;{erased} str; 4_usize] 
_171:  @ &amp;&#39;{erased} [&amp;&#39;{erased} str; 4_usize] 
_172:  @ [&amp;&#39;{erased} str; 4_usize] 
_173:  @ &amp;&#39;{erased} [core::fmt::rt::Argument&lt;&#39;{erased}&gt;; 3_usize] 
_174:  @ &amp;&#39;{erased} [core::fmt::rt::Argument&lt;&#39;{erased}&gt;; 3_usize] 
_175:  @ log::Level 
_176:  @ &amp;&#39;{erased} (&amp;&#39;{erased} str, &amp;&#39;{erased} str, &amp;&#39;{erased} core::panic::Location&lt;&#39;{erased}&gt;) 
_177:  @ &amp;&#39;{erased} (&amp;&#39;{erased} str, &amp;&#39;{erased} str, &amp;&#39;{erased} core::panic::Location&lt;&#39;{erased}&gt;) 
_178:  @ (&amp;&#39;{erased} str, &amp;&#39;{erased} str, &amp;&#39;{erased} core::panic::Location&lt;&#39;{erased}&gt;) 
_179:  @ &amp;&#39;{erased} str 
_180:  @ &amp;&#39;{erased} str 
_181:  @ &amp;&#39;{erased} core::panic::Location&lt;&#39;{erased}&gt; 
_182:  @ &amp;&#39;{erased} core::panic::Location&lt;&#39;{erased}&gt; 
_183:  @ () 
_184:  @ mm::page::EntryFlags&lt;arch::x86_64::mm::X86_64MMArch&gt; 
_185:  @ mm::page::EntryFlags&lt;arch::x86_64::mm::X86_64MMArch&gt; 
_186:  @ () 
_187:  @ bool 
_188:  @ &amp;&#39;{erased} mm::page::EntryFlags&lt;arch::x86_64::mm::X86_64MMArch&gt; 
_189:  @ core::option::Option&lt;mm::page::PageFlush&lt;arch::x86_64::mm::X86_64MMArch&gt;&gt; 
_190:  @ &amp;&#39;{erased} mut mm::page::PageMapper&lt;arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator&gt; 
_191:  @ mm::VirtAddr 
_192:  @ mm::page::EntryFlags&lt;arch::x86_64::mm::X86_64MMArch&gt; 
_193:  @ isize 
_194:  @ mm::page::PageFlush&lt;arch::x86_64::mm::X86_64MMArch&gt; 
_195:  @ () 
_196:  @ mm::page::PageFlush&lt;arch::x86_64::mm::X86_64MMArch&gt; 
_197:  @ bool 
_198:  @ &amp;&#39;{erased} core::option::Option&lt;mm::page::PageFlush&lt;arch::x86_64::mm::X86_64MMArch&gt;&gt; 
_199:  @ core::option::Option&lt;mm::page::PageFlush&lt;arch::x86_64::mm::X86_64MMArch&gt;&gt; 
_200:  @ &amp;&#39;{erased} mut mm::page::PageMapper&lt;arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator&gt; 
_201:  @ mm::VirtAddr 
_202:  @ mm::PhysAddr 
_203:  @ mm::page::EntryFlags&lt;arch::x86_64::mm::X86_64MMArch&gt; 
_204:  @ () 
_205:  @ log::Level 
_206:  @ bool 
_207:  @ &amp;&#39;{erased} log::Level 
_208:  @ &amp;&#39;{erased} log::LevelFilter 
_209:  @ log::LevelFilter 
_210:  @ bool 
_211:  @ &amp;&#39;{erased} log::Level 
_212:  @ &amp;&#39;{erased} log::LevelFilter 
_213:  @ log::LevelFilter 
_214:  @ () 
_215:  @ log::__private_api::GlobalLogger 
_216:  @ core::fmt::Arguments&lt;&#39;{erased}&gt; 
_217:  @ (&amp;&#39;{erased} mm::VirtAddr, &amp;&#39;{erased} mm::PhysAddr, &amp;&#39;{erased} process::RawPid) 
_218:  @ &amp;&#39;{erased} mm::VirtAddr 
_219:  @ &amp;&#39;{erased} mm::PhysAddr 
_220:  @ &amp;&#39;{erased} process::RawPid 
_221:  @ process::RawPid 
_222:  @ &amp;&#39;{erased} process::ProcessControlBlock 
_223:  @ &amp;&#39;{erased} process::ProcessControlBlock 
_224:  @ &amp;&#39;{erased} alloc::sync::Arc&lt;process::ProcessControlBlock, alloc::alloc::Global&gt; 
_225:  @ alloc::sync::Arc&lt;process::ProcessControlBlock, alloc::alloc::Global&gt; 
_226:  @ [core::fmt::rt::Argument&lt;&#39;{erased}&gt;; 3_usize] 
_227:  @ core::fmt::rt::Argument&lt;&#39;{erased}&gt; 
_228:  @ &amp;&#39;{erased} mm::VirtAddr 
_229:  @ core::fmt::rt::Argument&lt;&#39;{erased}&gt; 
_230:  @ &amp;&#39;{erased} mm::PhysAddr 
_231:  @ core::fmt::rt::Argument&lt;&#39;{erased}&gt; 
_232:  @ &amp;&#39;{erased} process::RawPid 
_233:  @ &amp;&#39;{erased} [&amp;&#39;{erased} str; 4_usize] 
_234:  @ &amp;&#39;{erased} [&amp;&#39;{erased} str; 4_usize] 
_235:  @ [&amp;&#39;{erased} str; 4_usize] 
_236:  @ &amp;&#39;{erased} [core::fmt::rt::Argument&lt;&#39;{erased}&gt;; 3_usize] 
_237:  @ &amp;&#39;{erased} [core::fmt::rt::Argument&lt;&#39;{erased}&gt;; 3_usize] 
_238:  @ log::Level 
_239:  @ &amp;&#39;{erased} (&amp;&#39;{erased} str, &amp;&#39;{erased} str, &amp;&#39;{erased} core::panic::Location&lt;&#39;{erased}&gt;) 
_240:  @ &amp;&#39;{erased} (&amp;&#39;{erased} str, &amp;&#39;{erased} str, &amp;&#39;{erased} core::panic::Location&lt;&#39;{erased}&gt;) 
_241:  @ (&amp;&#39;{erased} str, &amp;&#39;{erased} str, &amp;&#39;{erased} core::panic::Location&lt;&#39;{erased}&gt;) 
_242:  @ &amp;&#39;{erased} str 
_243:  @ &amp;&#39;{erased} str 
_244:  @ &amp;&#39;{erased} core::panic::Location&lt;&#39;{erased}&gt; 
_245:  @ &amp;&#39;{erased} core::panic::Location&lt;&#39;{erased}&gt; 
_246:  @ () 
_247:  @ core::option::Option&lt;alloc::sync::Arc&lt;mm::page::Page, alloc::alloc::Global&gt;&gt; 
_248:  @ &amp;&#39;{erased} mut mm::page::PageManager 
_249:  @ &amp;&#39;{erased} mut mm::page::PageManager 
_250:  @ &amp;&#39;{erased} mut libs::spinlock::SpinLockGuard&lt;&#39;{erased}, mm::page::PageManager&gt; 
_251:  @ &amp;&#39;{erased} mm::PhysAddr 
_252:  @ &amp;&#39;{erased} mm::PhysAddr 
_253:  @ isize 
_254:  @ alloc::sync::Arc&lt;mm::page::Page, alloc::alloc::Global&gt; 
_255:  @ () 
_256:  @ &amp;&#39;{erased} mut mm::page::InnerPage 
_257:  @ &amp;&#39;{erased} mut mm::page::InnerPage 
_258:  @ &amp;&#39;{erased} mut libs::rwlock::RwLockWriteGuard&lt;&#39;{erased}, mm::page::InnerPage&gt; 
_259:  @ libs::rwlock::RwLockWriteGuard&lt;&#39;{erased}, mm::page::InnerPage&gt; 
_260:  @ &amp;&#39;{erased} mm::page::Page 
_261:  @ &amp;&#39;{erased} mm::page::Page 
_262:  @ &amp;&#39;{erased} alloc::sync::Arc&lt;mm::page::Page, alloc::alloc::Global&gt; 
_263:  @ alloc::sync::Arc&lt;mm::ucontext::LockedVMA, alloc::alloc::Global&gt; 
_264:  @ &amp;&#39;{erased} alloc::sync::Arc&lt;mm::ucontext::LockedVMA, alloc::alloc::Global&gt; 
_265:  @ mm::VirtAddr 
_266:  @ usize 
_267:  @ usize 
_268:  @ &amp;&#39;{erased} mm::VirtAddr 
_269:  @ (usize, bool) 
_270:  @ ! 
_271:  @ () 
_272:  @ ! 
_273:  @ () 
_274:  @ libs::spinlock::SpinLockGuard&lt;&#39;{erased}, mm::page::PageManager&gt; 
_275:  @ () 
_276:  @ libs::spinlock::SpinLockGuard&lt;&#39;{erased}, mm::ucontext::VMA&gt; 
_277:  @ () 
_278:  @ libs::rwlock::RwLockWriteGuard&lt;&#39;{erased}, mm::ucontext::InnerAddressSpace&gt; 
_279:  @ () 
_280:  @ exception::IrqFlagsGuard 
_281:  @ alloc::sync::Arc&lt;mm::ucontext::AddressSpace, alloc::alloc::Global&gt; 
_282:  @ &amp;&#39;{erased} [&amp;&#39;{erased} str; 4_usize] 
_283:  @ &amp;&#39;{erased} log::LevelFilter 
_284:  @ &amp;&#39;{erased} [&amp;&#39;{erased} str; 4_usize] 
_285:  @ &amp;&#39;{erased} log::LevelFilter 
_286:  @ &amp;&#39;{erased} mm::VirtAddr 
_287:  @ &amp;&#39;{erased} mm::PhysAddr 
_288:  @ &amp;&#39;{erased} process::RawPid 
_289:  @ &amp;&#39;{erased} mm::VirtAddr 
_290:  @ &amp;&#39;{erased} mm::PhysAddr 
_291:  @ &amp;&#39;{erased} process::RawPid 
_292:  @ bool 
_293:  @ bool 
_294:  @ bool 
_295:  @ bool 
_296:  @ bool 
_297:  @ bool 
_298:  @ bool 
_299:  @ isize 
_300:  @ isize 
_301:  @ isize 
_302:  @ isize 
_303:  @ isize 
_304:  @ isize 
_305:  @ isize 
_306:  @ isize 
_307:  @ isize 
_308:  @ isize 
_309:  @ isize 

bb 0 {
CleanUp: false
    Assign((_294, const false)) @ _294=const false @ Use
    Assign((_298, const false)) @ _298=const false @ Use
    Assign((_297, const false)) @ _297=const false @ Use
    Assign((_296, const false)) @ _296=const false @ Use
    Assign((_295, const false)) @ _295=const false @ Use
    Assign((_292, const false)) @ _292=const false @ Use
    Assign((_293, const false)) @ _293=const false @ Use
    StorageLive(_3) @ StorageLive
    Assign((_294, const true)) @ _294=const true @ Use
    _3 = &lt;arch::x86_64::interrupt::X86_64InterruptArch as exception::InterruptArch&gt;::save_and_disable_irq() -&gt; [return: bb1, unwind continue] @ Call: FnDid: 16949
}
bb 1 {
CleanUp: false
    StorageLive(_4) @ StorageLive
    StorageLive(_5) @ StorageLive
    StorageLive(_6) @ StorageLive
    _6 = mm::ucontext::AddressSpace::new(const false) -&gt; [return: bb2, unwind: bb176] @ Call: FnDid: 25059
}
bb 2 {
CleanUp: false
    _5 = &lt;core::result::Result&lt;alloc::sync::Arc&lt;mm::ucontext::AddressSpace&gt;, system_error::SystemError&gt; as core::ops::Try&gt;::branch(move _6) -&gt; [return: bb3, unwind: bb176] @ Call: FnDid: 4199
}
bb 3 {
CleanUp: false
    StorageDead(_6) @ StorageDead
    Assign((_7, discriminant(_5))) @ _7=discriminant(_5) @ Discriminant
    switchInt(move _7) -&gt; [0: bb5, 1: bb6, otherwise: bb4] @ SwitchInt
}
bb 4 {
CleanUp: false
    unreachable @ Unreachable
}
bb 5 {
CleanUp: false
    StorageLive(_11) @ StorageLive
    Assign((_11, move ((_5 as Continue).0: alloc::sync::Arc&lt;mm::ucontext::AddressSpace&gt;))) @ _11=move ((_5 as Continue).0: alloc::sync::Arc&lt;mm::ucontext::AddressSpace&gt;) @ Use
    Assign((_4, move _11)) @ _4=move _11 @ Use
    StorageDead(_11) @ StorageDead
    Assign((_301, discriminant(_5))) @ _301=discriminant(_5) @ Discriminant
    StorageDead(_5) @ StorageDead
    StorageLive(_12) @ StorageLive
    StorageLive(_13) @ StorageLive
    StorageLive(_14) @ StorageLive
    StorageLive(_15) @ StorageLive
    StorageLive(_16) @ StorageLive
    StorageLive(_17) @ StorageLive
    Assign((_17, &amp;_4)) @ _17=&amp;_4 @ Ref
    _16 = &lt;alloc::sync::Arc&lt;mm::ucontext::AddressSpace&gt; as lazy_static::__Deref&gt;::deref(move _17) -&gt; [return: bb8, unwind: bb159] @ Call: FnDid: 3903
}
bb 6 {
CleanUp: false
    StorageLive(_8) @ StorageLive
    Assign((_8, move ((_5 as Break).0: core::result::Result&lt;core::convert::Infallible, system_error::SystemError&gt;))) @ _8=move ((_5 as Break).0: core::result::Result&lt;core::convert::Infallible, system_error::SystemError&gt;) @ Use
    StorageLive(_10) @ StorageLive
    Assign((_10, move _8)) @ _10=move _8 @ Use
    _0 = &lt;core::result::Result&lt;alloc::sync::Arc&lt;mm::ucontext::AddressSpace&gt;, system_error::SystemError&gt; as core::ops::FromResidual&lt;core::result::Result&lt;core::convert::Infallible, system_error::SystemError&gt;&gt;&gt;::from_residual(move _10) -&gt; [return: bb7, unwind: bb174] @ Call: FnDid: 4202
}
bb 7 {
CleanUp: false
    StorageDead(_10) @ StorageDead
    StorageDead(_8) @ StorageDead
    Assign((_299, discriminant(_5))) @ _299=discriminant(_5) @ Discriminant
    StorageDead(_5) @ StorageDead
    goto -&gt; bb150 @ Goto
}
bb 8 {
CleanUp: false
    Assign((_15, &amp;(*_16))) @ _15=&amp;(*_16) @ Ref
    _14 = &lt;mm::ucontext::AddressSpace as lazy_static::__Deref&gt;::deref(move _15) -&gt; [return: bb9, unwind: bb159] @ Call: FnDid: 3903
}
bb 9 {
CleanUp: false
    Assign((_13, &amp;(*_14))) @ _13=&amp;(*_14) @ Ref
    StorageDead(_17) @ StorageDead
    StorageDead(_15) @ StorageDead
    _12 = libs::rwlock::RwLock::&lt;mm::ucontext::InnerAddressSpace&gt;::write(move _13) -&gt; [return: bb10, unwind: bb159] @ Call: FnDid: 5165
}
bb 10 {
CleanUp: false
    Assign((_298, const true)) @ _298=const true @ Use
    StorageDead(_13) @ StorageDead
    StorageDead(_16) @ StorageDead
    StorageDead(_14) @ StorageDead
    StorageLive(_18) @ StorageLive
    StorageLive(_19) @ StorageLive
    StorageLive(_20) @ StorageLive
    StorageLive(_21) @ StorageLive
    StorageLive(_22) @ StorageLive
    StorageLive(_23) @ StorageLive
    StorageLive(_24) @ StorageLive
    Assign((_24, &amp;((*_1).3: core::option::Option&lt;mm::ucontext::UserStack&gt;))) @ _24=&amp;((*_1).3: core::option::Option&lt;mm::ucontext::UserStack&gt;) @ Ref
    _23 = core::option::Option::&lt;mm::ucontext::UserStack&gt;::as_ref(move _24) -&gt; [return: bb11, unwind: bb173] @ Call: FnDid: 10149
}
bb 11 {
CleanUp: false
    StorageDead(_24) @ StorageDead
    _22 = core::option::Option::&lt;&amp;mm::ucontext::UserStack&gt;::unwrap(move _23) -&gt; [return: bb12, unwind: bb173] @ Call: FnDid: 10157
}
bb 12 {
CleanUp: false
    Assign((_21, &amp;(*_22))) @ _21=&amp;(*_22) @ Ref
    StorageDead(_23) @ StorageDead
    _20 = mm::ucontext::UserStack::clone_info_only(move _21) -&gt; [return: bb13, unwind: bb173] @ Call: FnDid: 25199
}
bb 13 {
CleanUp: false
    StorageDead(_21) @ StorageDead
    Assign((_19, core::option::Option::&lt;mm::ucontext::UserStack&gt;::Some(move _20))) @ _19=core::option::Option::&lt;mm::ucontext::UserStack&gt;::Some(move _20) @ Aggregate
    StorageDead(_20) @ StorageDead
    StorageLive(_25) @ StorageLive
    StorageLive(_26) @ StorageLive
    Assign((_26, &amp;mut _12)) @ _26=&amp;mut _12 @ Ref
    _25 = &lt;libs::rwlock::RwLockWriteGuard&lt;&#39;_, mm::ucontext::InnerAddressSpace&gt; as core::ops::DerefMut&gt;::deref_mut(move _26) -&gt; [return: bb14, unwind: bb173] @ Call: FnDid: 3915
}
bb 14 {
CleanUp: false
    StorageDead(_26) @ StorageDead
    Assign((((*_25).3: core::option::Option&lt;mm::ucontext::UserStack&gt;), move _19)) @ ((*_25).3: core::option::Option&lt;mm::ucontext::UserStack&gt;)=move _19 @ Use
    StorageDead(_19) @ StorageDead
    StorageDead(_25) @ StorageDead
    StorageDead(_22) @ StorageDead
    Assign((_18, const ())) @ _18=const () @ Use
    StorageDead(_18) @ StorageDead
    StorageLive(_27) @ StorageLive
    StorageLive(_28) @ StorageLive
    Assign((_28, &amp;(((*_1).1: mm::ucontext::UserMappings).1: alloc::collections::BTreeMap&lt;mm::VirtAddr, usize&gt;))) @ _28=&amp;(((*_1).1: mm::ucontext::UserMappings).1: alloc::collections::BTreeMap&lt;mm::VirtAddr, usize&gt;) @ Ref
    _27 = &lt;alloc::collections::BTreeMap&lt;mm::VirtAddr, usize&gt; as core::clone::Clone&gt;::clone(move _28) -&gt; [return: bb15, unwind: bb173] @ Call: FnDid: 3116
}
bb 15 {
CleanUp: false
    Assign((_297, const true)) @ _297=const true @ Use
    StorageDead(_28) @ StorageDead
    StorageLive(_29) @ StorageLive
    StorageLive(_30) @ StorageLive
    Assign((_30, &amp;mut _12)) @ _30=&amp;mut _12 @ Ref
    _29 = &lt;libs::rwlock::RwLockWriteGuard&lt;&#39;_, mm::ucontext::InnerAddressSpace&gt; as core::ops::DerefMut&gt;::deref_mut(move _30) -&gt; [return: bb16, unwind: bb171] @ Call: FnDid: 3915
}
bb 16 {
CleanUp: false
    StorageDead(_30) @ StorageDead
    drop((((*_29).1: mm::ucontext::UserMappings).1: alloc::collections::BTreeMap&lt;mm::VirtAddr, usize&gt;)) -&gt; [return: bb17, unwind: bb18] @ Drop
}
bb 17 {
CleanUp: false
    Assign((_297, const false)) @ _297=const false @ Use
    Assign(((((*_29).1: mm::ucontext::UserMappings).1: alloc::collections::BTreeMap&lt;mm::VirtAddr, usize&gt;), move _27)) @ (((*_29).1: mm::ucontext::UserMappings).1: alloc::collections::BTreeMap&lt;mm::VirtAddr, usize&gt;)=move _27 @ Use
    Assign((_297, const false)) @ _297=const false @ Use
    StorageDead(_27) @ StorageDead
    StorageDead(_29) @ StorageDead
    StorageLive(_31) @ StorageLive
    Assign((_31, copy ((*_1).7: mm::VirtAddr))) @ _31=copy ((*_1).7: mm::VirtAddr) @ Use
    StorageLive(_32) @ StorageLive
    StorageLive(_33) @ StorageLive
    Assign((_33, &amp;mut _12)) @ _33=&amp;mut _12 @ Ref
    _32 = &lt;libs::rwlock::RwLockWriteGuard&lt;&#39;_, mm::ucontext::InnerAddressSpace&gt; as core::ops::DerefMut&gt;::deref_mut(move _33) -&gt; [return: bb19, unwind: bb173] @ Call: FnDid: 3915
}
bb 18 {
CleanUp: true
    Assign((_297, const false)) @ _297=const false @ Use
    Assign(((((*_29).1: mm::ucontext::UserMappings).1: alloc::collections::BTreeMap&lt;mm::VirtAddr, usize&gt;), move _27)) @ (((*_29).1: mm::ucontext::UserMappings).1: alloc::collections::BTreeMap&lt;mm::VirtAddr, usize&gt;)=move _27 @ Use
    goto -&gt; bb171 @ Goto
}
bb 19 {
CleanUp: false
    StorageDead(_33) @ StorageDead
    Assign((((*_32).7: mm::VirtAddr), move _31)) @ ((*_32).7: mm::VirtAddr)=move _31 @ Use
    StorageDead(_31) @ StorageDead
    StorageDead(_32) @ StorageDead
    StorageLive(_34) @ StorageLive
    Assign((_34, copy ((*_1).6: mm::VirtAddr))) @ _34=copy ((*_1).6: mm::VirtAddr) @ Use
    StorageLive(_35) @ StorageLive
    StorageLive(_36) @ StorageLive
    Assign((_36, &amp;mut _12)) @ _36=&amp;mut _12 @ Ref
    _35 = &lt;libs::rwlock::RwLockWriteGuard&lt;&#39;_, mm::ucontext::InnerAddressSpace&gt; as core::ops::DerefMut&gt;::deref_mut(move _36) -&gt; [return: bb20, unwind: bb173] @ Call: FnDid: 3915
}
bb 20 {
CleanUp: false
    StorageDead(_36) @ StorageDead
    Assign((((*_35).6: mm::VirtAddr), move _34)) @ ((*_35).6: mm::VirtAddr)=move _34 @ Use
    StorageDead(_34) @ StorageDead
    StorageDead(_35) @ StorageDead
    StorageLive(_37) @ StorageLive
    Assign((_37, copy ((*_1).2: mm::VirtAddr))) @ _37=copy ((*_1).2: mm::VirtAddr) @ Use
    StorageLive(_38) @ StorageLive
    StorageLive(_39) @ StorageLive
    Assign((_39, &amp;mut _12)) @ _39=&amp;mut _12 @ Ref
    _38 = &lt;libs::rwlock::RwLockWriteGuard&lt;&#39;_, mm::ucontext::InnerAddressSpace&gt; as core::ops::DerefMut&gt;::deref_mut(move _39) -&gt; [return: bb21, unwind: bb173] @ Call: FnDid: 3915
}
bb 21 {
CleanUp: false
    StorageDead(_39) @ StorageDead
    Assign((((*_38).2: mm::VirtAddr), move _37)) @ ((*_38).2: mm::VirtAddr)=move _37 @ Use
    StorageDead(_37) @ StorageDead
    StorageDead(_38) @ StorageDead
    StorageLive(_40) @ StorageLive
    Assign((_40, copy ((*_1).5: mm::VirtAddr))) @ _40=copy ((*_1).5: mm::VirtAddr) @ Use
    StorageLive(_41) @ StorageLive
    StorageLive(_42) @ StorageLive
    Assign((_42, &amp;mut _12)) @ _42=&amp;mut _12 @ Ref
    _41 = &lt;libs::rwlock::RwLockWriteGuard&lt;&#39;_, mm::ucontext::InnerAddressSpace&gt; as core::ops::DerefMut&gt;::deref_mut(move _42) -&gt; [return: bb22, unwind: bb173] @ Call: FnDid: 3915
}
bb 22 {
CleanUp: false
    StorageDead(_42) @ StorageDead
    Assign((((*_41).5: mm::VirtAddr), move _40)) @ ((*_41).5: mm::VirtAddr)=move _40 @ Use
    StorageDead(_40) @ StorageDead
    StorageDead(_41) @ StorageDead
    StorageLive(_43) @ StorageLive
    Assign((_43, copy ((*_1).4: mm::VirtAddr))) @ _43=copy ((*_1).4: mm::VirtAddr) @ Use
    StorageLive(_44) @ StorageLive
    StorageLive(_45) @ StorageLive
    Assign((_45, &amp;mut _12)) @ _45=&amp;mut _12 @ Ref
    _44 = &lt;libs::rwlock::RwLockWriteGuard&lt;&#39;_, mm::ucontext::InnerAddressSpace&gt; as core::ops::DerefMut&gt;::deref_mut(move _45) -&gt; [return: bb23, unwind: bb173] @ Call: FnDid: 3915
}
bb 23 {
CleanUp: false
    StorageDead(_45) @ StorageDead
    Assign((((*_44).4: mm::VirtAddr), move _43)) @ ((*_44).4: mm::VirtAddr)=move _43 @ Use
    StorageDead(_43) @ StorageDead
    StorageDead(_44) @ StorageDead
    StorageLive(_46) @ StorageLive
    Assign((_46, copy ((*_1).8: mm::VirtAddr))) @ _46=copy ((*_1).8: mm::VirtAddr) @ Use
    StorageLive(_47) @ StorageLive
    StorageLive(_48) @ StorageLive
    Assign((_48, &amp;mut _12)) @ _48=&amp;mut _12 @ Ref
    _47 = &lt;libs::rwlock::RwLockWriteGuard&lt;&#39;_, mm::ucontext::InnerAddressSpace&gt; as core::ops::DerefMut&gt;::deref_mut(move _48) -&gt; [return: bb24, unwind: bb173] @ Call: FnDid: 3915
}
bb 24 {
CleanUp: false
    StorageDead(_48) @ StorageDead
    Assign((((*_47).8: mm::VirtAddr), move _46)) @ ((*_47).8: mm::VirtAddr)=move _46 @ Use
    StorageDead(_46) @ StorageDead
    StorageDead(_47) @ StorageDead
    StorageLive(_49) @ StorageLive
    Assign((_49, copy ((*_1).9: mm::VirtAddr))) @ _49=copy ((*_1).9: mm::VirtAddr) @ Use
    StorageLive(_50) @ StorageLive
    StorageLive(_51) @ StorageLive
    Assign((_51, &amp;mut _12)) @ _51=&amp;mut _12 @ Ref
    _50 = &lt;libs::rwlock::RwLockWriteGuard&lt;&#39;_, mm::ucontext::InnerAddressSpace&gt; as core::ops::DerefMut&gt;::deref_mut(move _51) -&gt; [return: bb25, unwind: bb173] @ Call: FnDid: 3915
}
bb 25 {
CleanUp: false
    StorageDead(_51) @ StorageDead
    Assign((((*_50).9: mm::VirtAddr), move _49)) @ ((*_50).9: mm::VirtAddr)=move _49 @ Use
    StorageDead(_49) @ StorageDead
    StorageDead(_50) @ StorageDead
    StorageLive(_52) @ StorageLive
    Assign((_52, copy ((*_1).10: mm::VirtAddr))) @ _52=copy ((*_1).10: mm::VirtAddr) @ Use
    StorageLive(_53) @ StorageLive
    StorageLive(_54) @ StorageLive
    Assign((_54, &amp;mut _12)) @ _54=&amp;mut _12 @ Ref
    _53 = &lt;libs::rwlock::RwLockWriteGuard&lt;&#39;_, mm::ucontext::InnerAddressSpace&gt; as core::ops::DerefMut&gt;::deref_mut(move _54) -&gt; [return: bb26, unwind: bb173] @ Call: FnDid: 3915
}
bb 26 {
CleanUp: false
    StorageDead(_54) @ StorageDead
    Assign((((*_53).10: mm::VirtAddr), move _52)) @ ((*_53).10: mm::VirtAddr)=move _52 @ Use
    StorageDead(_52) @ StorageDead
    StorageDead(_53) @ StorageDead
    StorageLive(_55) @ StorageLive
    Assign((_55, copy ((*_1).11: mm::VirtAddr))) @ _55=copy ((*_1).11: mm::VirtAddr) @ Use
    StorageLive(_56) @ StorageLive
    StorageLive(_57) @ StorageLive
    Assign((_57, &amp;mut _12)) @ _57=&amp;mut _12 @ Ref
    _56 = &lt;libs::rwlock::RwLockWriteGuard&lt;&#39;_, mm::ucontext::InnerAddressSpace&gt; as core::ops::DerefMut&gt;::deref_mut(move _57) -&gt; [return: bb27, unwind: bb173] @ Call: FnDid: 3915
}
bb 27 {
CleanUp: false
    StorageDead(_57) @ StorageDead
    Assign((((*_56).11: mm::VirtAddr), move _55)) @ ((*_56).11: mm::VirtAddr)=move _55 @ Use
    StorageDead(_55) @ StorageDead
    StorageDead(_56) @ StorageDead
    StorageLive(_58) @ StorageLive
    StorageLive(_59) @ StorageLive
    StorageLive(_60) @ StorageLive
    StorageLive(_61) @ StorageLive
    Assign((_61, &amp;(((*_1).1: mm::ucontext::UserMappings).0: hashbrown::HashSet&lt;alloc::sync::Arc&lt;mm::ucontext::LockedVMA&gt;&gt;))) @ _61=&amp;(((*_1).1: mm::ucontext::UserMappings).0: hashbrown::HashSet&lt;alloc::sync::Arc&lt;mm::ucontext::LockedVMA&gt;&gt;) @ Ref
    _60 = hashbrown::HashSet::&lt;alloc::sync::Arc&lt;mm::ucontext::LockedVMA&gt;&gt;::iter(move _61) -&gt; [return: bb28, unwind: bb173] @ Call: FnDid: 1615
}
bb 28 {
CleanUp: false
    StorageDead(_61) @ StorageDead
    _59 = &lt;hashbrown::hash_set::Iter&lt;&#39;_, alloc::sync::Arc&lt;mm::ucontext::LockedVMA&gt;&gt; as core::iter::IntoIterator&gt;::into_iter(move _60) -&gt; [return: bb29, unwind: bb173] @ Call: FnDid: 9224
}
bb 29 {
CleanUp: false
    StorageDead(_60) @ StorageDead
    StorageLive(_62) @ StorageLive
    Assign((_62, move _59)) @ _62=move _59 @ Use
    goto -&gt; bb30 @ Goto
}
bb 30 {
CleanUp: false
    StorageLive(_64) @ StorageLive
    StorageLive(_65) @ StorageLive
    StorageLive(_66) @ StorageLive
    StorageLive(_67) @ StorageLive
    Assign((_67, &amp;mut _62)) @ _67=&amp;mut _62 @ Ref
    Assign((_66, &amp;mut (*_67))) @ _66=&amp;mut (*_67) @ Ref
    _65 = &lt;hashbrown::hash_set::Iter&lt;&#39;_, alloc::sync::Arc&lt;mm::ucontext::LockedVMA&gt;&gt; as core::iter::Iterator&gt;::next(move _66) -&gt; [return: bb31, unwind: bb173] @ Call: FnDid: 9356
}
bb 31 {
CleanUp: false
    StorageDead(_66) @ StorageDead
    Assign((_68, discriminant(_65))) @ _68=discriminant(_65) @ Discriminant
    switchInt(move _68) -&gt; [0: bb33, 1: bb32, otherwise: bb4] @ SwitchInt
}
bb 32 {
CleanUp: false
    StorageLive(_70) @ StorageLive
    Assign((_70, copy ((_65 as Some).0: &amp;alloc::sync::Arc&lt;mm::ucontext::LockedVMA&gt;))) @ _70=copy ((_65 as Some).0: &amp;alloc::sync::Arc&lt;mm::ucontext::LockedVMA&gt;) @ Use
    StorageLive(_71) @ StorageLive
    StorageLive(_72) @ StorageLive
    StorageLive(_73) @ StorageLive
    StorageLive(_74) @ StorageLive
    Assign((_74, &amp;(*_70))) @ _74=&amp;(*_70) @ Ref
    _73 = &lt;alloc::sync::Arc&lt;mm::ucontext::LockedVMA&gt; as lazy_static::__Deref&gt;::deref(move _74) -&gt; [return: bb34, unwind: bb173] @ Call: FnDid: 3903
}
bb 33 {
CleanUp: false
    Assign((_58, const ())) @ _58=const () @ Use
    StorageDead(_67) @ StorageDead
    StorageDead(_65) @ StorageDead
    StorageDead(_64) @ StorageDead
    StorageDead(_62) @ StorageDead
    StorageDead(_59) @ StorageDead
    StorageDead(_58) @ StorageDead
    StorageLive(_277) @ StorageLive
    StorageLive(_278) @ StorageLive
    Assign((_298, const false)) @ _298=const false @ Use
    Assign((_278, move _12)) @ _278=move _12 @ Use
    _277 = core::mem::drop::&lt;libs::rwlock::RwLockWriteGuard&lt;&#39;_, mm::ucontext::InnerAddressSpace&gt;&gt;(move _278) -&gt; [return: bb148, unwind: bb173] @ Call: FnDid: 2323
}
bb 34 {
CleanUp: false
    Assign((_72, &amp;(*_73))) @ _72=&amp;(*_73) @ Ref
    StorageDead(_74) @ StorageDead
    _71 = mm::ucontext::LockedVMA::lock_irqsave(move _72) -&gt; [return: bb35, unwind: bb173] @ Call: FnDid: 25130
}
bb 35 {
CleanUp: false
    Assign((_296, const true)) @ _296=const true @ Use
    StorageDead(_72) @ StorageDead
    StorageDead(_73) @ StorageDead
    StorageLive(_75) @ StorageLive
    StorageLive(_76) @ StorageLive
    StorageLive(_77) @ StorageLive
    StorageLive(_78) @ StorageLive
    StorageLive(_79) @ StorageLive
    StorageLive(_80) @ StorageLive
    StorageLive(_81) @ StorageLive
    Assign((_81, &amp;_71)) @ _81=&amp;_71 @ Ref
    _80 = &lt;libs::spinlock::SpinLockGuard&lt;&#39;_, mm::ucontext::VMA&gt; as lazy_static::__Deref&gt;::deref(move _81) -&gt; [return: bb36, unwind: bb169] @ Call: FnDid: 3903
}
bb 36 {
CleanUp: false
    Assign((_79, &amp;(*_80))) @ _79=&amp;(*_80) @ Ref
    StorageDead(_81) @ StorageDead
    _78 = mm::ucontext::VMA::vm_flags(move _79) -&gt; [return: bb37, unwind: bb169] @ Call: FnDid: 25162
}
bb 37 {
CleanUp: false
    Assign((_77, &amp;(*_78))) @ _77=&amp;(*_78) @ Ref
    StorageDead(_79) @ StorageDead
    _76 = mm::VmFlags::contains(move _77, const mm::VmFlags::VM_DONTCOPY) -&gt; [return: bb38, unwind: bb169] @ Call: FnDid: 60147
}
bb 38 {
CleanUp: false
    switchInt(move _76) -&gt; [0: bb41, otherwise: bb39] @ SwitchInt
}
bb 39 {
CleanUp: false
    StorageDead(_80) @ StorageDead
    StorageDead(_78) @ StorageDead
    StorageDead(_77) @ StorageDead
    StorageLive(_83) @ StorageLive
    StorageLive(_84) @ StorageLive
    Assign((_296, const false)) @ _296=const false @ Use
    Assign((_84, move _71)) @ _84=move _71 @ Use
    _83 = core::mem::drop::&lt;libs::spinlock::SpinLockGuard&lt;&#39;_, mm::ucontext::VMA&gt;&gt;(move _84) -&gt; [return: bb40, unwind: bb169] @ Call: FnDid: 2323
}
bb 40 {
CleanUp: false
    StorageDead(_84) @ StorageDead
    StorageDead(_83) @ StorageDead
    StorageDead(_76) @ StorageDead
    StorageDead(_75) @ StorageDead
    Assign((_296, const false)) @ _296=const false @ Use
    StorageDead(_71) @ StorageDead
    StorageDead(_70) @ StorageDead
    StorageDead(_67) @ StorageDead
    StorageDead(_65) @ StorageDead
    StorageDead(_64) @ StorageDead
    goto -&gt; bb30 @ Goto
}
bb 41 {
CleanUp: false
    StorageDead(_80) @ StorageDead
    StorageDead(_78) @ StorageDead
    StorageDead(_77) @ StorageDead
    Assign((_75, const ())) @ _75=const () @ Use
    StorageDead(_76) @ StorageDead
    StorageDead(_75) @ StorageDead
    StorageLive(_85) @ StorageLive
    StorageLive(_86) @ StorageLive
    StorageLive(_87) @ StorageLive
    StorageLive(_88) @ StorageLive
    Assign((_88, &amp;_71)) @ _88=&amp;_71 @ Ref
    _87 = &lt;libs::spinlock::SpinLockGuard&lt;&#39;_, mm::ucontext::VMA&gt; as lazy_static::__Deref&gt;::deref(move _88) -&gt; [return: bb42, unwind: bb169] @ Call: FnDid: 3903
}
bb 42 {
CleanUp: false
    Assign((_86, &amp;(*_87))) @ _86=&amp;(*_87) @ Ref
    StorageDead(_88) @ StorageDead
    _85 = mm::ucontext::VMA::vm_flags(move _86) -&gt; [return: bb43, unwind: bb169] @ Call: FnDid: 25162
}
bb 43 {
CleanUp: false
    StorageDead(_86) @ StorageDead
    StorageDead(_87) @ StorageDead
    StorageLive(_89) @ StorageLive
    StorageLive(_90) @ StorageLive
    Assign((_90, &amp;(*_85))) @ _90=&amp;(*_85) @ Ref
    _89 = mm::VmFlags::contains(move _90, const mm::VmFlags::VM_SHARED) -&gt; [return: bb44, unwind: bb169] @ Call: FnDid: 60147
}
bb 44 {
CleanUp: false
    StorageDead(_90) @ StorageDead
    StorageLive(_91) @ StorageLive
    StorageLive(_92) @ StorageLive
    StorageLive(_93) @ StorageLive
    StorageLive(_94) @ StorageLive
    StorageLive(_95) @ StorageLive
    Assign((_95, &amp;_71)) @ _95=&amp;_71 @ Ref
    _94 = &lt;libs::spinlock::SpinLockGuard&lt;&#39;_, mm::ucontext::VMA&gt; as lazy_static::__Deref&gt;::deref(move _95) -&gt; [return: bb45, unwind: bb169] @ Call: FnDid: 3903
}
bb 45 {
CleanUp: false
    Assign((_93, &amp;(*_94))) @ _93=&amp;(*_94) @ Ref
    StorageDead(_95) @ StorageDead
    _92 = mm::ucontext::VMA::region(move _93) -&gt; [return: bb46, unwind: bb169] @ Call: FnDid: 25161
}
bb 46 {
CleanUp: false
    StorageDead(_93) @ StorageDead
    Assign((_91, copy (*_92))) @ _91=copy (*_92) @ Use
    StorageDead(_94) @ StorageDead
    StorageDead(_92) @ StorageDead
    StorageLive(_96) @ StorageLive
    StorageLive(_97) @ StorageLive
    StorageLive(_98) @ StorageLive
    StorageLive(_99) @ StorageLive
    Assign((_99, &amp;_71)) @ _99=&amp;_71 @ Ref
    _98 = &lt;libs::spinlock::SpinLockGuard&lt;&#39;_, mm::ucontext::VMA&gt; as lazy_static::__Deref&gt;::deref(move _99) -&gt; [return: bb47, unwind: bb169] @ Call: FnDid: 3903
}
bb 47 {
CleanUp: false
    Assign((_97, &amp;(*_98))) @ _97=&amp;(*_98) @ Ref
    StorageDead(_99) @ StorageDead
    _96 = mm::ucontext::VMA::flags(move _97) -&gt; [return: bb48, unwind: bb169] @ Call: FnDid: 25172
}
bb 48 {
CleanUp: false
    StorageDead(_97) @ StorageDead
    StorageDead(_98) @ StorageDead
    StorageLive(_100) @ StorageLive
    StorageLive(_101) @ StorageLive
    StorageLive(_102) @ StorageLive
    StorageLive(_103) @ StorageLive
    StorageLive(_104) @ StorageLive
    Assign((_104, &amp;_71)) @ _104=&amp;_71 @ Ref
    _103 = &lt;libs::spinlock::SpinLockGuard&lt;&#39;_, mm::ucontext::VMA&gt; as lazy_static::__Deref&gt;::deref(move _104) -&gt; [return: bb49, unwind: bb169] @ Call: FnDid: 3903
}
bb 49 {
CleanUp: false
    Assign((_102, &amp;(*_103))) @ _102=&amp;(*_103) @ Ref
    StorageDead(_104) @ StorageDead
    _101 = mm::ucontext::VMA::clone_info_only(move _102) -&gt; [return: bb50, unwind: bb169] @ Call: FnDid: 25171
}
bb 50 {
CleanUp: false
    StorageDead(_102) @ StorageDead
    _100 = mm::ucontext::LockedVMA::new(move _101) -&gt; [return: bb51, unwind: bb169] @ Call: FnDid: 25127
}
bb 51 {
CleanUp: false
    StorageDead(_101) @ StorageDead
    StorageDead(_103) @ StorageDead
    StorageLive(_105) @ StorageLive
    StorageLive(_106) @ StorageLive
    StorageLive(_107) @ StorageLive
    StorageLive(_108) @ StorageLive
    Assign((_108, &amp;mut _12)) @ _108=&amp;mut _12 @ Ref
    _107 = &lt;libs::rwlock::RwLockWriteGuard&lt;&#39;_, mm::ucontext::InnerAddressSpace&gt; as core::ops::DerefMut&gt;::deref_mut(move _108) -&gt; [return: bb52, unwind: bb158] @ Call: FnDid: 3915
}
bb 52 {
CleanUp: false
    StorageDead(_108) @ StorageDead
    Assign((_106, &amp;mut (((*_107).1: mm::ucontext::UserMappings).0: hashbrown::HashSet&lt;alloc::sync::Arc&lt;mm::ucontext::LockedVMA&gt;&gt;))) @ _106=&amp;mut (((*_107).1: mm::ucontext::UserMappings).0: hashbrown::HashSet&lt;alloc::sync::Arc&lt;mm::ucontext::LockedVMA&gt;&gt;) @ Ref
    StorageLive(_109) @ StorageLive
    StorageLive(_110) @ StorageLive
    Assign((_110, &amp;_100)) @ _110=&amp;_100 @ Ref
    _109 = &lt;alloc::sync::Arc&lt;mm::ucontext::LockedVMA&gt; as core::clone::Clone&gt;::clone(move _110) -&gt; [return: bb53, unwind: bb158] @ Call: FnDid: 3116
}
bb 53 {
CleanUp: false
    StorageDead(_110) @ StorageDead
    _105 = hashbrown::HashSet::&lt;alloc::sync::Arc&lt;mm::ucontext::LockedVMA&gt;&gt;::insert(move _106, move _109) -&gt; [return: bb54, unwind: bb158] @ Call: FnDid: 1672
}
bb 54 {
CleanUp: false
    StorageDead(_109) @ StorageDead
    StorageDead(_106) @ StorageDead
    StorageDead(_107) @ StorageDead
    StorageDead(_105) @ StorageDead
    StorageLive(_111) @ StorageLive
    StorageLive(_112) @ StorageLive
    Assign((_112, &amp;_91)) @ _112=&amp;_91 @ Ref
    _111 = mm::VirtRegion::start(move _112) -&gt; [return: bb55, unwind: bb158] @ Call: FnDid: 25369
}
bb 55 {
CleanUp: false
    StorageDead(_112) @ StorageDead
    StorageLive(_113) @ StorageLive
    StorageLive(_114) @ StorageLive
    Assign((_114, &amp;_91)) @ _114=&amp;_91 @ Ref
    _113 = mm::VirtRegion::end(move _114) -&gt; [return: bb56, unwind: bb158] @ Call: FnDid: 25370
}
bb 56 {
CleanUp: false
    StorageDead(_114) @ StorageDead
    StorageLive(_115) @ StorageLive
    Assign((_115, copy _111)) @ _115=copy _111 @ Use
    StorageLive(_116) @ StorageLive
    Assign((_116, &amp;mut (((*_1).0: mm::ucontext::UserMapper).0: mm::page::PageMapper&lt;arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator&gt;))) @ _116=&amp;mut (((*_1).0: mm::ucontext::UserMapper).0: mm::page::PageMapper&lt;arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator&gt;) @ Ref
    StorageLive(_117) @ StorageLive
    StorageLive(_118) @ StorageLive
    StorageLive(_119) @ StorageLive
    Assign((_119, &amp;mut _12)) @ _119=&amp;mut _12 @ Ref
    _118 = &lt;libs::rwlock::RwLockWriteGuard&lt;&#39;_, mm::ucontext::InnerAddressSpace&gt; as core::ops::DerefMut&gt;::deref_mut(move _119) -&gt; [return: bb57, unwind: bb158] @ Call: FnDid: 3915
}
bb 57 {
CleanUp: false
    StorageDead(_119) @ StorageDead
    Assign((_117, &amp;mut (((*_118).0: mm::ucontext::UserMapper).0: mm::page::PageMapper&lt;arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator&gt;))) @ _117=&amp;mut (((*_118).0: mm::ucontext::UserMapper).0: mm::page::PageMapper&lt;arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator&gt;) @ Ref
    StorageLive(_120) @ StorageLive
    _120 = mm::page::page_manager_lock_irqsave() -&gt; [return: bb58, unwind: bb158] @ Call: FnDid: 24300
}
bb 58 {
CleanUp: false
    Assign((_295, const true)) @ _295=const true @ Use
    StorageLive(_121) @ StorageLive
    goto -&gt; bb59 @ Goto
}
bb 59 {
CleanUp: false
    StorageLive(_122) @ StorageLive
    StorageLive(_123) @ StorageLive
    Assign((_123, &amp;_115)) @ _123=&amp;_115 @ Ref
    StorageLive(_124) @ StorageLive
    Assign((_124, &amp;_113)) @ _124=&amp;_113 @ Ref
    _122 = &lt;mm::VirtAddr as core::cmp::PartialOrd&gt;::lt(move _123, move _124) -&gt; [return: bb60, unwind: bb167] @ Call: FnDid: 3214
}
bb 60 {
CleanUp: false
    switchInt(move _122) -&gt; [0: bb144, otherwise: bb61] @ SwitchInt
}
bb 61 {
CleanUp: false
    StorageDead(_124) @ StorageDead
    StorageDead(_123) @ StorageDead
    StorageLive(_125) @ StorageLive
    StorageLive(_126) @ StorageLive
    StorageLive(_127) @ StorageLive
    Assign((_127, &amp;(*_116))) @ _127=&amp;(*_116) @ Ref
    StorageLive(_128) @ StorageLive
    Assign((_128, copy _115)) @ _128=copy _115 @ Use
    _126 = mm::page::PageMapper::&lt;arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator&gt;::translate(move _127, move _128) -&gt; [return: bb62, unwind: bb167] @ Call: FnDid: 24445
}
bb 62 {
CleanUp: false
    StorageDead(_128) @ StorageDead
    StorageDead(_127) @ StorageDead
    Assign((_129, discriminant(_126))) @ _129=discriminant(_126) @ Discriminant
    switchInt(move _129) -&gt; [1: bb63, otherwise: bb139] @ SwitchInt
}
bb 63 {
CleanUp: false
    StorageLive(_130) @ StorageLive
    Assign((_130, copy (((_126 as Some).0: (mm::PhysAddr, mm::page::EntryFlags&lt;arch::x86_64::mm::X86_64MMArch&gt;)).0: mm::PhysAddr))) @ _130=copy (((_126 as Some).0: (mm::PhysAddr, mm::page::EntryFlags&lt;arch::x86_64::mm::X86_64MMArch&gt;)).0: mm::PhysAddr) @ Use
    StorageLive(_131) @ StorageLive
    Assign((_131, copy (((_126 as Some).0: (mm::PhysAddr, mm::page::EntryFlags&lt;arch::x86_64::mm::X86_64MMArch&gt;)).1: mm::page::EntryFlags&lt;arch::x86_64::mm::X86_64MMArch&gt;))) @ _131=copy (((_126 as Some).0: (mm::PhysAddr, mm::page::EntryFlags&lt;arch::x86_64::mm::X86_64MMArch&gt;)).1: mm::page::EntryFlags&lt;arch::x86_64::mm::X86_64MMArch&gt;) @ Use
    StorageLive(_132) @ StorageLive
    StorageLive(_133) @ StorageLive
    Assign((_133, copy _89)) @ _133=copy _89 @ Use
    switchInt(move _133) -&gt; [0: bb91, otherwise: bb64] @ SwitchInt
}
bb 64 {
CleanUp: false
    StorageLive(_134) @ StorageLive
    StorageLive(_135) @ StorageLive
    StorageLive(_136) @ StorageLive
    StorageLive(_137) @ StorageLive
    Assign((_137, &amp;mut (*_117))) @ _137=&amp;mut (*_117) @ Ref
    StorageLive(_138) @ StorageLive
    Assign((_138, copy _115)) @ _138=copy _115 @ Use
    StorageLive(_139) @ StorageLive
    Assign((_139, copy _130)) @ _139=copy _130 @ Use
    StorageLive(_140) @ StorageLive
    Assign((_140, copy _96)) @ _140=copy _96 @ Use
    _136 = mm::page::PageMapper::&lt;arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator&gt;::map_phys(move _137, move _138, move _139, move _140) -&gt; [return: bb65, unwind: bb167] @ Call: FnDid: 24435
}
bb 65 {
CleanUp: false
    Assign((_135, &amp;_136)) @ _135=&amp;_136 @ Ref
    StorageDead(_140) @ StorageDead
    StorageDead(_139) @ StorageDead
    StorageDead(_138) @ StorageDead
    StorageDead(_137) @ StorageDead
    _134 = core::option::Option::&lt;mm::page::PageFlush&lt;arch::x86_64::mm::X86_64MMArch&gt;&gt;::is_none(move _135) -&gt; [return: bb66, unwind: bb157] @ Call: FnDid: 10146
}
bb 66 {
CleanUp: false
    switchInt(move _134) -&gt; [0: bb88, otherwise: bb67] @ SwitchInt
}
bb 67 {
CleanUp: false
    drop(_136) -&gt; [return: bb68, unwind: bb167] @ Drop
}
bb 68 {
CleanUp: false
    StorageDead(_136) @ StorageDead
    StorageDead(_135) @ StorageDead
    StorageLive(_141) @ StorageLive
    StorageLive(_142) @ StorageLive
    Assign((_142, log::Level::Warn)) @ _142=log::Level::Warn @ Aggregate
    StorageLive(_143) @ StorageLive
    StorageLive(_144) @ StorageLive
    Assign((_144, &amp;_142)) @ _144=&amp;_142 @ Ref
    StorageLive(_145) @ StorageLive
    Assign((_283, const mm::ucontext::InnerAddressSpace::try_clone::promoted[1])) @ _283=const mm::ucontext::InnerAddressSpace::try_clone::promoted[1] @ Use
    Assign((_145, &amp;(*_283))) @ _145=&amp;(*_283) @ Ref
    _143 = &lt;log::Level as core::cmp::PartialOrd&lt;log::LevelFilter&gt;&gt;::le(move _144, move _145) -&gt; [return: bb69, unwind: bb167] @ Call: FnDid: 3215
}
bb 69 {
CleanUp: false
    switchInt(move _143) -&gt; [0: bb85, otherwise: bb70] @ SwitchInt
}
bb 70 {
CleanUp: false
    StorageDead(_145) @ StorageDead
    StorageDead(_144) @ StorageDead
    StorageLive(_147) @ StorageLive
    StorageLive(_148) @ StorageLive
    Assign((_148, &amp;_142)) @ _148=&amp;_142 @ Ref
    StorageLive(_149) @ StorageLive
    StorageLive(_150) @ StorageLive
    _150 = log::max_level() -&gt; [return: bb71, unwind: bb167] @ Call: FnDid: 134
}
bb 71 {
CleanUp: false
    Assign((_149, &amp;_150)) @ _149=&amp;_150 @ Ref
    _147 = &lt;log::Level as core::cmp::PartialOrd&lt;log::LevelFilter&gt;&gt;::le(move _148, move _149) -&gt; [return: bb72, unwind: bb167] @ Call: FnDid: 3215
}
bb 72 {
CleanUp: false
    switchInt(move _147) -&gt; [0: bb84, otherwise: bb73] @ SwitchInt
}
bb 73 {
CleanUp: false
    StorageDead(_150) @ StorageDead
    StorageDead(_149) @ StorageDead
    StorageDead(_148) @ StorageDead
    StorageLive(_151) @ StorageLive
    StorageLive(_152) @ StorageLive
    Assign((_152, log::__private_api::GlobalLogger)) @ _152=log::__private_api::GlobalLogger @ Aggregate
    StorageLive(_153) @ StorageLive
    StorageLive(_154) @ StorageLive
    StorageLive(_155) @ StorageLive
    Assign((_155, &amp;_115)) @ _155=&amp;_115 @ Ref
    StorageLive(_156) @ StorageLive
    Assign((_156, &amp;_130)) @ _156=&amp;_130 @ Ref
    StorageLive(_157) @ StorageLive
    StorageLive(_158) @ StorageLive
    StorageLive(_159) @ StorageLive
    StorageLive(_160) @ StorageLive
    StorageLive(_161) @ StorageLive
    StorageLive(_162) @ StorageLive
    _162 = process::ProcessManager::current_pcb() -&gt; [return: bb74, unwind: bb167] @ Call: FnDid: 29866
}
bb 74 {
CleanUp: false
    Assign((_161, &amp;_162)) @ _161=&amp;_162 @ Ref
    _160 = &lt;alloc::sync::Arc&lt;process::ProcessControlBlock&gt; as lazy_static::__Deref&gt;::deref(move _161) -&gt; [return: bb75, unwind: bb156] @ Call: FnDid: 3903
}
bb 75 {
CleanUp: false
    Assign((_159, &amp;(*_160))) @ _159=&amp;(*_160) @ Ref
    StorageDead(_161) @ StorageDead
    _158 = process::ProcessControlBlock::raw_pid(move _159) -&gt; [return: bb76, unwind: bb156] @ Call: FnDid: 29942
}
bb 76 {
CleanUp: false
    StorageDead(_159) @ StorageDead
    Assign((_157, &amp;_158)) @ _157=&amp;_158 @ Ref
    Assign((_154, (move _155, move _156, move _157))) @ _154=(move _155, move _156, move _157) @ Aggregate
    StorageDead(_157) @ StorageDead
    StorageDead(_156) @ StorageDead
    StorageDead(_155) @ StorageDead
    StorageLive(_163) @ StorageLive
    StorageLive(_164) @ StorageLive
    StorageLive(_165) @ StorageLive
    Assign((_286, deref_copy (_154.0: &amp;mm::VirtAddr))) @ _286=deref_copy (_154.0: &amp;mm::VirtAddr) @ CopyForDeref
    Assign((_165, &amp;(*_286))) @ _165=&amp;(*_286) @ Ref
    _164 = core::fmt::rt::Argument::&lt;&#39;_&gt;::new_debug::&lt;mm::VirtAddr&gt;(move _165) -&gt; [return: bb77, unwind: bb156] @ Call: FnDid: 11809
}
bb 77 {
CleanUp: false
    StorageDead(_165) @ StorageDead
    StorageLive(_166) @ StorageLive
    StorageLive(_167) @ StorageLive
    Assign((_287, deref_copy (_154.1: &amp;mm::PhysAddr))) @ _287=deref_copy (_154.1: &amp;mm::PhysAddr) @ CopyForDeref
    Assign((_167, &amp;(*_287))) @ _167=&amp;(*_287) @ Ref
    _166 = core::fmt::rt::Argument::&lt;&#39;_&gt;::new_debug::&lt;mm::PhysAddr&gt;(move _167) -&gt; [return: bb78, unwind: bb156] @ Call: FnDid: 11809
}
bb 78 {
CleanUp: false
    StorageDead(_167) @ StorageDead
    StorageLive(_168) @ StorageLive
    StorageLive(_169) @ StorageLive
    Assign((_288, deref_copy (_154.2: &amp;process::RawPid))) @ _288=deref_copy (_154.2: &amp;process::RawPid) @ CopyForDeref
    Assign((_169, &amp;(*_288))) @ _169=&amp;(*_288) @ Ref
    _168 = core::fmt::rt::Argument::&lt;&#39;_&gt;::new_debug::&lt;process::RawPid&gt;(move _169) -&gt; [return: bb79, unwind: bb156] @ Call: FnDid: 11809
}
bb 79 {
CleanUp: false
    StorageDead(_169) @ StorageDead
    Assign((_163, [move _164, move _166, move _168])) @ _163=[move _164, move _166, move _168] @ Aggregate
    StorageDead(_168) @ StorageDead
    StorageDead(_166) @ StorageDead
    StorageDead(_164) @ StorageDead
    StorageLive(_170) @ StorageLive
    StorageLive(_171) @ StorageLive
    Assign((_282, const mm::ucontext::InnerAddressSpace::try_clone::promoted[0])) @ _282=const mm::ucontext::InnerAddressSpace::try_clone::promoted[0] @ Use
    Assign((_171, &amp;(*_282))) @ _171=&amp;(*_282) @ Ref
    Assign((_170, &amp;(*_171))) @ _170=&amp;(*_171) @ Ref
    StorageLive(_173) @ StorageLive
    StorageLive(_174) @ StorageLive
    Assign((_174, &amp;_163)) @ _174=&amp;_163 @ Ref
    Assign((_173, &amp;(*_174))) @ _173=&amp;(*_174) @ Ref
    _153 = core::fmt::rt::&lt;impl core::fmt::Arguments&lt;&#39;_&gt;&gt;::new_v1::&lt;4, 3&gt;(move _170, move _173) -&gt; [return: bb80, unwind: bb156] @ Call: FnDid: 11836
}
bb 80 {
CleanUp: false
    StorageDead(_174) @ StorageDead
    StorageDead(_173) @ StorageDead
    StorageDead(_171) @ StorageDead
    StorageDead(_170) @ StorageDead
    StorageLive(_175) @ StorageLive
    Assign((_175, copy _142)) @ _175=copy _142 @ Use
    StorageLive(_176) @ StorageLive
    StorageLive(_177) @ StorageLive
    StorageLive(_178) @ StorageLive
    StorageLive(_179) @ StorageLive
    StorageLive(_180) @ StorageLive
    Assign((_180, const &#34;dragonos_kernel::mm::ucontext&#34;)) @ _180=const &#34;dragonos_kernel::mm::ucontext&#34; @ Use
    Assign((_179, &amp;(*_180))) @ _179=&amp;(*_180) @ Ref
    StorageLive(_181) @ StorageLive
    StorageLive(_182) @ StorageLive
    _182 = log::__private_api::loc() -&gt; [return: bb81, unwind: bb156] @ Call: FnDid: 184
}
bb 81 {
CleanUp: false
    Assign((_181, &amp;(*_182))) @ _181=&amp;(*_182) @ Ref
    Assign((_178, (move _179, const &#34;dragonos_kernel::mm::ucontext&#34;, move _181))) @ _178=(move _179, const &#34;dragonos_kernel::mm::ucontext&#34;, move _181) @ Aggregate
    StorageDead(_181) @ StorageDead
    StorageDead(_179) @ StorageDead
    Assign((_177, &amp;_178)) @ _177=&amp;_178 @ Ref
    Assign((_176, &amp;(*_177))) @ _176=&amp;(*_177) @ Ref
    StorageLive(_183) @ StorageLive
    Assign((_183, ())) @ _183=() @ Aggregate
    _151 = log::__private_api::log::&lt;&#39;_, (), log::__private_api::GlobalLogger&gt;(move _152, move _153, move _175, move _176, move _183) -&gt; [return: bb82, unwind: bb156] @ Call: FnDid: 178
}
bb 82 {
CleanUp: false
    StorageDead(_183) @ StorageDead
    StorageDead(_176) @ StorageDead
    StorageDead(_175) @ StorageDead
    StorageDead(_153) @ StorageDead
    StorageDead(_152) @ StorageDead
    StorageDead(_182) @ StorageDead
    StorageDead(_180) @ StorageDead
    StorageDead(_178) @ StorageDead
    StorageDead(_177) @ StorageDead
    StorageDead(_163) @ StorageDead
    drop(_162) -&gt; [return: bb83, unwind: bb167] @ Drop
}
bb 83 {
CleanUp: false
    StorageDead(_162) @ StorageDead
    StorageDead(_160) @ StorageDead
    StorageDead(_158) @ StorageDead
    StorageDead(_154) @ StorageDead
    StorageDead(_151) @ StorageDead
    Assign((_141, const ())) @ _141=const () @ Use
    goto -&gt; bb87 @ Goto
}
bb 84 {
CleanUp: false
    StorageDead(_150) @ StorageDead
    StorageDead(_149) @ StorageDead
    StorageDead(_148) @ StorageDead
    goto -&gt; bb86 @ Goto
}
bb 85 {
CleanUp: false
    StorageDead(_145) @ StorageDead
    StorageDead(_144) @ StorageDead
    goto -&gt; bb86 @ Goto
}
bb 86 {
CleanUp: false
    Assign((_141, const ())) @ _141=const () @ Use
    goto -&gt; bb87 @ Goto
}
bb 87 {
CleanUp: false
    StorageDead(_147) @ StorageDead
    StorageDead(_143) @ StorageDead
    StorageDead(_142) @ StorageDead
    StorageDead(_141) @ StorageDead
    Assign((_132, const ())) @ _132=const () @ Use
    goto -&gt; bb90 @ Goto
}
bb 88 {
CleanUp: false
    drop(_136) -&gt; [return: bb89, unwind: bb167] @ Drop
}
bb 89 {
CleanUp: false
    StorageDead(_136) @ StorageDead
    StorageDead(_135) @ StorageDead
    Assign((_132, const ())) @ _132=const () @ Use
    goto -&gt; bb90 @ Goto
}
bb 90 {
CleanUp: false
    StorageDead(_134) @ StorageDead
    goto -&gt; bb127 @ Goto
}
bb 91 {
CleanUp: false
    StorageLive(_184) @ StorageLive
    StorageLive(_185) @ StorageLive
    Assign((_185, copy _96)) @ _185=copy _96 @ Use
    _184 = mm::page::EntryFlags::&lt;arch::x86_64::mm::X86_64MMArch&gt;::set_write(move _185, const false) -&gt; [return: bb92, unwind: bb167] @ Call: FnDid: 24407
}
bb 92 {
CleanUp: false
    StorageDead(_185) @ StorageDead
    StorageLive(_186) @ StorageLive
    StorageLive(_187) @ StorageLive
    StorageLive(_188) @ StorageLive
    Assign((_188, &amp;_131)) @ _188=&amp;_131 @ Ref
    _187 = mm::page::EntryFlags::&lt;arch::x86_64::mm::X86_64MMArch&gt;::has_write(move _188) -&gt; [return: bb93, unwind: bb167] @ Call: FnDid: 24408
}
bb 93 {
CleanUp: false
    switchInt(move _187) -&gt; [0: bb99, otherwise: bb94] @ SwitchInt
}
bb 94 {
CleanUp: false
    StorageDead(_188) @ StorageDead
    StorageLive(_189) @ StorageLive
    StorageLive(_190) @ StorageLive
    Assign((_190, &amp;mut (*_116))) @ _190=&amp;mut (*_116) @ Ref
    StorageLive(_191) @ StorageLive
    Assign((_191, copy _115)) @ _191=copy _115 @ Use
    StorageLive(_192) @ StorageLive
    Assign((_192, copy _184)) @ _192=copy _184 @ Use
    _189 = mm::page::PageMapper::&lt;arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator&gt;::remap(move _190, move _191, move _192) -&gt; [return: bb95, unwind: bb167] @ Call: FnDid: 24443
}
bb 95 {
CleanUp: false
    Assign((_292, const true)) @ _292=const true @ Use
    StorageDead(_192) @ StorageDead
    StorageDead(_191) @ StorageDead
    StorageDead(_190) @ StorageDead
    Assign((_193, discriminant(_189))) @ _193=discriminant(_189) @ Discriminant
    switchInt(move _193) -&gt; [1: bb96, otherwise: bb98] @ SwitchInt
}
bb 96 {
CleanUp: false
    StorageLive(_194) @ StorageLive
    Assign((_194, move ((_189 as Some).0: mm::page::PageFlush&lt;arch::x86_64::mm::X86_64MMArch&gt;))) @ _194=move ((_189 as Some).0: mm::page::PageFlush&lt;arch::x86_64::mm::X86_64MMArch&gt;) @ Use
    StorageLive(_195) @ StorageLive
    StorageLive(_196) @ StorageLive
    Assign((_196, move _194)) @ _196=move _194 @ Use
    _195 = mm::page::PageFlush::&lt;arch::x86_64::mm::X86_64MMArch&gt;::flush(move _196) -&gt; [return: bb97, unwind: bb165] @ Call: FnDid: 24472
}
bb 97 {
CleanUp: false
    StorageDead(_196) @ StorageDead
    StorageDead(_195) @ StorageDead
    Assign((_186, const ())) @ _186=const () @ Use
    StorageDead(_194) @ StorageDead
    goto -&gt; bb161 @ Goto
}
bb 98 {
CleanUp: false
    Assign((_186, const ())) @ _186=const () @ Use
    goto -&gt; bb161 @ Goto
}
bb 99 {
CleanUp: false
    StorageDead(_188) @ StorageDead
    Assign((_186, const ())) @ _186=const () @ Use
    goto -&gt; bb100 @ Goto
}
bb 100 {
CleanUp: false
    StorageDead(_187) @ StorageDead
    StorageDead(_186) @ StorageDead
    StorageLive(_197) @ StorageLive
    StorageLive(_198) @ StorageLive
    StorageLive(_199) @ StorageLive
    StorageLive(_200) @ StorageLive
    Assign((_200, &amp;mut (*_117))) @ _200=&amp;mut (*_117) @ Ref
    StorageLive(_201) @ StorageLive
    Assign((_201, copy _115)) @ _201=copy _115 @ Use
    StorageLive(_202) @ StorageLive
    Assign((_202, copy _130)) @ _202=copy _130 @ Use
    StorageLive(_203) @ StorageLive
    Assign((_203, copy _184)) @ _203=copy _184 @ Use
    _199 = mm::page::PageMapper::&lt;arch::x86_64::mm::X86_64MMArch, arch::x86_64::mm::LockedFrameAllocator&gt;::map_phys(move _200, move _201, move _202, move _203) -&gt; [return: bb101, unwind: bb167] @ Call: FnDid: 24435
}
bb 101 {
CleanUp: false
    Assign((_198, &amp;_199)) @ _198=&amp;_199 @ Ref
    StorageDead(_203) @ StorageDead
    StorageDead(_202) @ StorageDead
    StorageDead(_201) @ StorageDead
    StorageDead(_200) @ StorageDead
    _197 = core::option::Option::&lt;mm::page::PageFlush&lt;arch::x86_64::mm::X86_64MMArch&gt;&gt;::is_none(move _198) -&gt; [return: bb102, unwind: bb155] @ Call: FnDid: 10146
}
bb 102 {
CleanUp: false
    switchInt(move _197) -&gt; [0: bb124, otherwise: bb103] @ SwitchInt
}
bb 103 {
CleanUp: false
    drop(_199) -&gt; [return: bb104, unwind: bb167] @ Drop
}
bb 104 {
CleanUp: false
    StorageDead(_199) @ StorageDead
    StorageDead(_198) @ StorageDead
    StorageLive(_204) @ StorageLive
    StorageLive(_205) @ StorageLive
    Assign((_205, log::Level::Warn)) @ _205=log::Level::Warn @ Aggregate
    StorageLive(_206) @ StorageLive
    StorageLive(_207) @ StorageLive
    Assign((_207, &amp;_205)) @ _207=&amp;_205 @ Ref
    StorageLive(_208) @ StorageLive
    Assign((_285, const mm::ucontext::InnerAddressSpace::try_clone::promoted[3])) @ _285=const mm::ucontext::InnerAddressSpace::try_clone::promoted[3] @ Use
    Assign((_208, &amp;(*_285))) @ _208=&amp;(*_285) @ Ref
    _206 = &lt;log::Level as core::cmp::PartialOrd&lt;log::LevelFilter&gt;&gt;::le(move _207, move _208) -&gt; [return: bb105, unwind: bb167] @ Call: FnDid: 3215
}
bb 105 {
CleanUp: false
    switchInt(move _206) -&gt; [0: bb121, otherwise: bb106] @ SwitchInt
}
bb 106 {
CleanUp: false
    StorageDead(_208) @ StorageDead
    StorageDead(_207) @ StorageDead
    StorageLive(_210) @ StorageLive
    StorageLive(_211) @ StorageLive
    Assign((_211, &amp;_205)) @ _211=&amp;_205 @ Ref
    StorageLive(_212) @ StorageLive
    StorageLive(_213) @ StorageLive
    _213 = log::max_level() -&gt; [return: bb107, unwind: bb167] @ Call: FnDid: 134
}
bb 107 {
CleanUp: false
    Assign((_212, &amp;_213)) @ _212=&amp;_213 @ Ref
    _210 = &lt;log::Level as core::cmp::PartialOrd&lt;log::LevelFilter&gt;&gt;::le(move _211, move _212) -&gt; [return: bb108, unwind: bb167] @ Call: FnDid: 3215
}
bb 108 {
CleanUp: false
    switchInt(move _210) -&gt; [0: bb120, otherwise: bb109] @ SwitchInt
}
bb 109 {
CleanUp: false
    StorageDead(_213) @ StorageDead
    StorageDead(_212) @ StorageDead
    StorageDead(_211) @ StorageDead
    StorageLive(_214) @ StorageLive
    StorageLive(_215) @ StorageLive
    Assign((_215, log::__private_api::GlobalLogger)) @ _215=log::__private_api::GlobalLogger @ Aggregate
    StorageLive(_216) @ StorageLive
    StorageLive(_217) @ StorageLive
    StorageLive(_218) @ StorageLive
    Assign((_218, &amp;_115)) @ _218=&amp;_115 @ Ref
    StorageLive(_219) @ StorageLive
    Assign((_219, &amp;_130)) @ _219=&amp;_130 @ Ref
    StorageLive(_220) @ StorageLive
    StorageLive(_221) @ StorageLive
    StorageLive(_222) @ StorageLive
    StorageLive(_223) @ StorageLive
    StorageLive(_224) @ StorageLive
    StorageLive(_225) @ StorageLive
    _225 = process::ProcessManager::current_pcb() -&gt; [return: bb110, unwind: bb167] @ Call: FnDid: 29866
}
bb 110 {
CleanUp: false
    Assign((_224, &amp;_225)) @ _224=&amp;_225 @ Ref
    _223 = &lt;alloc::sync::Arc&lt;process::ProcessControlBlock&gt; as lazy_static::__Deref&gt;::deref(move _224) -&gt; [return: bb111, unwind: bb154] @ Call: FnDid: 3903
}
bb 111 {
CleanUp: false
    Assign((_222, &amp;(*_223))) @ _222=&amp;(*_223) @ Ref
    StorageDead(_224) @ StorageDead
    _221 = process::ProcessControlBlock::raw_pid(move _222) -&gt; [return: bb112, unwind: bb154] @ Call: FnDid: 29942
}
bb 112 {
CleanUp: false
    StorageDead(_222) @ StorageDead
    Assign((_220, &amp;_221)) @ _220=&amp;_221 @ Ref
    Assign((_217, (move _218, move _219, move _220))) @ _217=(move _218, move _219, move _220) @ Aggregate
    StorageDead(_220) @ StorageDead
    StorageDead(_219) @ StorageDead
    StorageDead(_218) @ StorageDead
    StorageLive(_226) @ StorageLive
    StorageLive(_227) @ StorageLive
    StorageLive(_228) @ StorageLive
    Assign((_289, deref_copy (_217.0: &amp;mm::VirtAddr))) @ _289=deref_copy (_217.0: &amp;mm::VirtAddr) @ CopyForDeref
    Assign((_228, &amp;(*_289))) @ _228=&amp;(*_289) @ Ref
    _227 = core::fmt::rt::Argument::&lt;&#39;_&gt;::new_debug::&lt;mm::VirtAddr&gt;(move _228) -&gt; [return: bb113, unwind: bb154] @ Call: FnDid: 11809
}
bb 113 {
CleanUp: false
    StorageDead(_228) @ StorageDead
    StorageLive(_229) @ StorageLive
    StorageLive(_230) @ StorageLive
    Assign((_290, deref_copy (_217.1: &amp;mm::PhysAddr))) @ _290=deref_copy (_217.1: &amp;mm::PhysAddr) @ CopyForDeref
    Assign((_230, &amp;(*_290))) @ _230=&amp;(*_290) @ Ref
    _229 = core::fmt::rt::Argument::&lt;&#39;_&gt;::new_debug::&lt;mm::PhysAddr&gt;(move _230) -&gt; [return: bb114, unwind: bb154] @ Call: FnDid: 11809
}
bb 114 {
CleanUp: false
    StorageDead(_230) @ StorageDead
    StorageLive(_231) @ StorageLive
    StorageLive(_232) @ StorageLive
    Assign((_291, deref_copy (_217.2: &amp;process::RawPid))) @ _291=deref_copy (_217.2: &amp;process::RawPid) @ CopyForDeref
    Assign((_232, &amp;(*_291))) @ _232=&amp;(*_291) @ Ref
    _231 = core::fmt::rt::Argument::&lt;&#39;_&gt;::new_debug::&lt;process::RawPid&gt;(move _232) -&gt; [return: bb115, unwind: bb154] @ Call: FnDid: 11809
}
bb 115 {
CleanUp: false
    StorageDead(_232) @ StorageDead
    Assign((_226, [move _227, move _229, move _231])) @ _226=[move _227, move _229, move _231] @ Aggregate
    StorageDead(_231) @ StorageDead
    StorageDead(_229) @ StorageDead
    StorageDead(_227) @ StorageDead
    StorageLive(_233) @ StorageLive
    StorageLive(_234) @ StorageLive
    Assign((_284, const mm::ucontext::InnerAddressSpace::try_clone::promoted[2])) @ _284=const mm::ucontext::InnerAddressSpace::try_clone::promoted[2] @ Use
    Assign((_234, &amp;(*_284))) @ _234=&amp;(*_284) @ Ref
    Assign((_233, &amp;(*_234))) @ _233=&amp;(*_234) @ Ref
    StorageLive(_236) @ StorageLive
    StorageLive(_237) @ StorageLive
    Assign((_237, &amp;_226)) @ _237=&amp;_226 @ Ref
    Assign((_236, &amp;(*_237))) @ _236=&amp;(*_237) @ Ref
    _216 = core::fmt::rt::&lt;impl core::fmt::Arguments&lt;&#39;_&gt;&gt;::new_v1::&lt;4, 3&gt;(move _233, move _236) -&gt; [return: bb116, unwind: bb154] @ Call: FnDid: 11836
}
bb 116 {
CleanUp: false
    StorageDead(_237) @ StorageDead
    StorageDead(_236) @ StorageDead
    StorageDead(_234) @ StorageDead
    StorageDead(_233) @ StorageDead
    StorageLive(_238) @ StorageLive
    Assign((_238, copy _205)) @ _238=copy _205 @ Use
    StorageLive(_239) @ StorageLive
    StorageLive(_240) @ StorageLive
    StorageLive(_241) @ StorageLive
    StorageLive(_242) @ StorageLive
    StorageLive(_243) @ StorageLive
    Assign((_243, const &#34;dragonos_kernel::mm::ucontext&#34;)) @ _243=const &#34;dragonos_kernel::mm::ucontext&#34; @ Use
    Assign((_242, &amp;(*_243))) @ _242=&amp;(*_243) @ Ref
    StorageLive(_244) @ StorageLive
    StorageLive(_245) @ StorageLive
    _245 = log::__private_api::loc() -&gt; [return: bb117, unwind: bb154] @ Call: FnDid: 184
}
bb 117 {
CleanUp: false
    Assign((_244, &amp;(*_245))) @ _244=&amp;(*_245) @ Ref
    Assign((_241, (move _242, const &#34;dragonos_kernel::mm::ucontext&#34;, move _244))) @ _241=(move _242, const &#34;dragonos_kernel::mm::ucontext&#34;, move _244) @ Aggregate
    StorageDead(_244) @ StorageDead
    StorageDead(_242) @ StorageDead
    Assign((_240, &amp;_241)) @ _240=&amp;_241 @ Ref
    Assign((_239, &amp;(*_240))) @ _239=&amp;(*_240) @ Ref
    StorageLive(_246) @ StorageLive
    Assign((_246, ())) @ _246=() @ Aggregate
    _214 = log::__private_api::log::&lt;&#39;_, (), log::__private_api::GlobalLogger&gt;(move _215, move _216, move _238, move _239, move _246) -&gt; [return: bb118, unwind: bb154] @ Call: FnDid: 178
}
bb 118 {
CleanUp: false
    StorageDead(_246) @ StorageDead
    StorageDead(_239) @ StorageDead
    StorageDead(_238) @ StorageDead
    StorageDead(_216) @ StorageDead
    StorageDead(_215) @ StorageDead
    StorageDead(_245) @ StorageDead
    StorageDead(_243) @ StorageDead
    StorageDead(_241) @ StorageDead
    StorageDead(_240) @ StorageDead
    StorageDead(_226) @ StorageDead
    drop(_225) -&gt; [return: bb119, unwind: bb167] @ Drop
}
bb 119 {
CleanUp: false
    StorageDead(_225) @ StorageDead
    StorageDead(_223) @ StorageDead
    StorageDead(_221) @ StorageDead
    StorageDead(_217) @ StorageDead
    StorageDead(_214) @ StorageDead
    Assign((_204, const ())) @ _204=const () @ Use
    goto -&gt; bb123 @ Goto
}
bb 120 {
CleanUp: false
    StorageDead(_213) @ StorageDead
    StorageDead(_212) @ StorageDead
    StorageDead(_211) @ StorageDead
    goto -&gt; bb122 @ Goto
}
bb 121 {
CleanUp: false
    StorageDead(_208) @ StorageDead
    StorageDead(_207) @ StorageDead
    goto -&gt; bb122 @ Goto
}
bb 122 {
CleanUp: false
    Assign((_204, const ())) @ _204=const () @ Use
    goto -&gt; bb123 @ Goto
}
bb 123 {
CleanUp: false
    StorageDead(_210) @ StorageDead
    StorageDead(_206) @ StorageDead
    StorageDead(_205) @ StorageDead
    StorageDead(_204) @ StorageDead
    Assign((_132, const ())) @ _132=const () @ Use
    goto -&gt; bb126 @ Goto
}
bb 124 {
CleanUp: false
    drop(_199) -&gt; [return: bb125, unwind: bb167] @ Drop
}
bb 125 {
CleanUp: false
    StorageDead(_199) @ StorageDead
    StorageDead(_198) @ StorageDead
    Assign((_132, const ())) @ _132=const () @ Use
    goto -&gt; bb126 @ Goto
}
bb 126 {
CleanUp: false
    StorageDead(_197) @ StorageDead
    StorageDead(_184) @ StorageDead
    goto -&gt; bb127 @ Goto
}
bb 127 {
CleanUp: false
    StorageDead(_133) @ StorageDead
    StorageDead(_132) @ StorageDead
    StorageLive(_247) @ StorageLive
    StorageLive(_248) @ StorageLive
    StorageLive(_249) @ StorageLive
    StorageLive(_250) @ StorageLive
    Assign((_250, &amp;mut _120)) @ _250=&amp;mut _120 @ Ref
    _249 = &lt;libs::spinlock::SpinLockGuard&lt;&#39;_, mm::page::PageManager&gt; as core::ops::DerefMut&gt;::deref_mut(move _250) -&gt; [return: bb128, unwind: bb167] @ Call: FnDid: 3915
}
bb 128 {
CleanUp: false
    Assign((_248, &amp;mut (*_249))) @ _248=&amp;mut (*_249) @ Ref
    StorageDead(_250) @ StorageDead
    StorageLive(_251) @ StorageLive
    StorageLive(_252) @ StorageLive
    Assign((_252, &amp;_130)) @ _252=&amp;_130 @ Ref
    Assign((_251, &amp;(*_252))) @ _251=&amp;(*_252) @ Ref
    _247 = mm::page::PageManager::get(move _248, move _251) -&gt; [return: bb129, unwind: bb167] @ Call: FnDid: 24306
}
bb 129 {
CleanUp: false
    Assign((_293, const true)) @ _293=const true @ Use
    StorageDead(_251) @ StorageDead
    StorageDead(_248) @ StorageDead
    Assign((_253, discriminant(_247))) @ _253=discriminant(_247) @ Discriminant
    switchInt(move _253) -&gt; [1: bb130, otherwise: bb137] @ SwitchInt
}
bb 130 {
CleanUp: false
    StorageLive(_254) @ StorageLive
    Assign((_254, move ((_247 as Some).0: alloc::sync::Arc&lt;mm::page::Page&gt;))) @ _254=move ((_247 as Some).0: alloc::sync::Arc&lt;mm::page::Page&gt;) @ Use
    StorageLive(_255) @ StorageLive
    StorageLive(_256) @ StorageLive
    StorageLive(_257) @ StorageLive
    StorageLive(_258) @ StorageLive
    StorageLive(_259) @ StorageLive
    StorageLive(_260) @ StorageLive
    StorageLive(_261) @ StorageLive
    StorageLive(_262) @ StorageLive
    Assign((_262, &amp;_254)) @ _262=&amp;_254 @ Ref
    _261 = &lt;alloc::sync::Arc&lt;mm::page::Page&gt; as lazy_static::__Deref&gt;::deref(move _262) -&gt; [return: bb131, unwind: bb153] @ Call: FnDid: 3903
}
bb 131 {
CleanUp: false
    Assign((_260, &amp;(*_261))) @ _260=&amp;(*_261) @ Ref
    StorageDead(_262) @ StorageDead
    _259 = mm::page::Page::write_irqsave(move _260) -&gt; [return: bb132, unwind: bb153] @ Call: FnDid: 24337
}
bb 132 {
CleanUp: false
    Assign((_258, &amp;mut _259)) @ _258=&amp;mut _259 @ Ref
    _257 = &lt;libs::rwlock::RwLockWriteGuard&lt;&#39;_, mm::page::InnerPage&gt; as core::ops::DerefMut&gt;::deref_mut(move _258) -&gt; [return: bb133, unwind: bb152] @ Call: FnDid: 3915
}
bb 133 {
CleanUp: false
    Assign((_256, &amp;mut (*_257))) @ _256=&amp;mut (*_257) @ Ref
    StorageDead(_260) @ StorageDead
    StorageDead(_258) @ StorageDead
    StorageLive(_263) @ StorageLive
    StorageLive(_264) @ StorageLive
    Assign((_264, &amp;_100)) @ _264=&amp;_100 @ Ref
    _263 = &lt;alloc::sync::Arc&lt;mm::ucontext::LockedVMA&gt; as core::clone::Clone&gt;::clone(move _264) -&gt; [return: bb134, unwind: bb152] @ Call: FnDid: 3116
}
bb 134 {
CleanUp: false
    StorageDead(_264) @ StorageDead
    _255 = mm::page::InnerPage::insert_vma(move _256, move _263) -&gt; [return: bb135, unwind: bb152] @ Call: FnDid: 24340
}
bb 135 {
CleanUp: false
    StorageDead(_263) @ StorageDead
    StorageDead(_256) @ StorageDead
    drop(_259) -&gt; [return: bb136, unwind: bb153] @ Drop
}
bb 136 {
CleanUp: false
    StorageDead(_261) @ StorageDead
    StorageDead(_259) @ StorageDead
    StorageDead(_257) @ StorageDead
    StorageDead(_255) @ StorageDead
    Assign((_125, const ())) @ _125=const () @ Use
    drop(_254) -&gt; [return: bb138, unwind: bb164] @ Drop
}
bb 137 {
CleanUp: false
    Assign((_125, const ())) @ _125=const () @ Use
    goto -&gt; bb162 @ Goto
}
bb 138 {
CleanUp: false
    StorageDead(_254) @ StorageDead
    goto -&gt; bb162 @ Goto
}
bb 139 {
CleanUp: false
    Assign((_125, const ())) @ _125=const () @ Use
    goto -&gt; bb140 @ Goto
}
bb 140 {
CleanUp: false
    StorageDead(_126) @ StorageDead
    StorageDead(_125) @ StorageDead
    StorageLive(_265) @ StorageLive
    StorageLive(_266) @ StorageLive
    StorageLive(_267) @ StorageLive
    StorageLive(_268) @ StorageLive
    Assign((_268, &amp;_115)) @ _268=&amp;_115 @ Ref
    _267 = mm::VirtAddr::data(move _268) -&gt; [return: bb141, unwind: bb167] @ Call: FnDid: 25246
}
bb 141 {
CleanUp: false
    StorageDead(_268) @ StorageDead
    Assign((_269, AddWithOverflow(copy _267, const &lt;arch::x86_64::mm::X86_64MMArch as mm::MemoryManagementArch&gt;::PAGE_SIZE))) @ _269=AddWithOverflow(copy _267, const &lt;arch::x86_64::mm::X86_64MMArch as mm::MemoryManagementArch&gt;::PAGE_SIZE) @ BinaryOp
    assert(!move (_269.1: bool), &#34;attempt to compute `{} + {}`, which would overflow&#34;, move _267, const &lt;arch::x86_64::mm::X86_64MMArch as mm::MemoryManagementArch&gt;::PAGE_SIZE) -&gt; [success: bb142, unwind: bb167] @ Assert
}
bb 142 {
CleanUp: false
    Assign((_266, move (_269.0: usize))) @ _266=move (_269.0: usize) @ Use
    StorageDead(_267) @ StorageDead
    _265 = mm::VirtAddr::new(move _266) -&gt; [return: bb143, unwind: bb167] @ Call: FnDid: 25245
}
bb 143 {
CleanUp: false
    StorageDead(_266) @ StorageDead
    Assign((_115, move _265)) @ _115=move _265 @ Use
    StorageDead(_265) @ StorageDead
    Assign((_63, const ())) @ _63=const () @ Use
    StorageDead(_122) @ StorageDead
    goto -&gt; bb59 @ Goto
}
bb 144 {
CleanUp: false
    StorageDead(_124) @ StorageDead
    StorageDead(_123) @ StorageDead
    StorageLive(_271) @ StorageLive
    Assign((_121, const ())) @ _121=const () @ Use
    StorageDead(_271) @ StorageDead
    StorageDead(_122) @ StorageDead
    StorageDead(_121) @ StorageDead
    StorageLive(_273) @ StorageLive
    StorageLive(_274) @ StorageLive
    Assign((_295, const false)) @ _295=const false @ Use
    Assign((_274, move _120)) @ _274=move _120 @ Use
    _273 = core::mem::drop::&lt;libs::spinlock::SpinLockGuard&lt;&#39;_, mm::page::PageManager&gt;&gt;(move _274) -&gt; [return: bb145, unwind: bb167] @ Call: FnDid: 2323
}
bb 145 {
CleanUp: false
    StorageDead(_274) @ StorageDead
    StorageDead(_273) @ StorageDead
    StorageLive(_275) @ StorageLive
    StorageLive(_276) @ StorageLive
    Assign((_296, const false)) @ _296=const false @ Use
    Assign((_276, move _71)) @ _276=move _71 @ Use
    _275 = core::mem::drop::&lt;libs::spinlock::SpinLockGuard&lt;&#39;_, mm::ucontext::VMA&gt;&gt;(move _276) -&gt; [return: bb146, unwind: bb167] @ Call: FnDid: 2323
}
bb 146 {
CleanUp: false
    StorageDead(_276) @ StorageDead
    StorageDead(_275) @ StorageDead
    Assign((_64, const ())) @ _64=const () @ Use
    Assign((_295, const false)) @ _295=const false @ Use
    StorageDead(_120) @ StorageDead
    StorageDead(_118) @ StorageDead
    StorageDead(_117) @ StorageDead
    StorageDead(_116) @ StorageDead
    StorageDead(_115) @ StorageDead
    StorageDead(_113) @ StorageDead
    StorageDead(_111) @ StorageDead
    drop(_100) -&gt; [return: bb147, unwind: bb169] @ Drop
}
bb 147 {
CleanUp: false
    StorageDead(_100) @ StorageDead
    StorageDead(_96) @ StorageDead
    StorageDead(_91) @ StorageDead
    StorageDead(_89) @ StorageDead
    StorageDead(_85) @ StorageDead
    Assign((_296, const false)) @ _296=const false @ Use
    StorageDead(_71) @ StorageDead
    StorageDead(_70) @ StorageDead
    StorageDead(_67) @ StorageDead
    StorageDead(_65) @ StorageDead
    StorageDead(_64) @ StorageDead
    Assign((_63, const ())) @ _63=const () @ Use
    goto -&gt; bb30 @ Goto
}
bb 148 {
CleanUp: false
    StorageDead(_278) @ StorageDead
    StorageDead(_277) @ StorageDead
    StorageLive(_279) @ StorageLive
    StorageLive(_280) @ StorageLive
    Assign((_294, const false)) @ _294=const false @ Use
    Assign((_280, move _3)) @ _280=move _3 @ Use
    _279 = core::mem::drop::&lt;exception::IrqFlagsGuard&gt;(move _280) -&gt; [return: bb149, unwind: bb173] @ Call: FnDid: 2323
}
bb 149 {
CleanUp: false
    StorageDead(_280) @ StorageDead
    StorageDead(_279) @ StorageDead
    StorageLive(_281) @ StorageLive
    Assign((_281, move _4)) @ _281=move _4 @ Use
    Assign((_0, core::result::Result::&lt;alloc::sync::Arc&lt;mm::ucontext::AddressSpace&gt;, system_error::SystemError&gt;::Ok(move _281))) @ _0=core::result::Result::&lt;alloc::sync::Arc&lt;mm::ucontext::AddressSpace&gt;, system_error::SystemError&gt;::Ok(move _281) @ Aggregate
    StorageDead(_281) @ StorageDead
    Assign((_298, const false)) @ _298=const false @ Use
    StorageDead(_12) @ StorageDead
    goto -&gt; bb150 @ Goto
}
bb 150 {
CleanUp: false
    StorageDead(_4) @ StorageDead
    switchInt(copy _294) -&gt; [0: bb151, otherwise: bb163] @ SwitchInt
}
bb 151 {
CleanUp: false
    Assign((_294, const false)) @ _294=const false @ Use
    StorageDead(_3) @ StorageDead
    return @ Return
}
bb 152 {
CleanUp: true
    drop(_259) -&gt; [return: bb153, unwind terminate(cleanup)] @ Drop
}
bb 153 {
CleanUp: true
    drop(_254) -&gt; [return: bb164, unwind terminate(cleanup)] @ Drop
}
bb 154 {
CleanUp: true
    drop(_225) -&gt; [return: bb167, unwind terminate(cleanup)] @ Drop
}
bb 155 {
CleanUp: true
    drop(_199) -&gt; [return: bb167, unwind terminate(cleanup)] @ Drop
}
bb 156 {
CleanUp: true
    drop(_162) -&gt; [return: bb167, unwind terminate(cleanup)] @ Drop
}
bb 157 {
CleanUp: true
    drop(_136) -&gt; [return: bb167, unwind terminate(cleanup)] @ Drop
}
bb 158 {
CleanUp: true
    drop(_100) -&gt; [return: bb169, unwind terminate(cleanup)] @ Drop
}
bb 159 {
CleanUp: true
    drop(_4) -&gt; [return: bb176, unwind terminate(cleanup)] @ Drop
}
bb 160 {
CleanUp: true
    resume @ UnwindResume
}
bb 161 {
CleanUp: false
    Assign((_303, discriminant(_189))) @ _303=discriminant(_189) @ Discriminant
    Assign((_292, const false)) @ _292=const false @ Use
    StorageDead(_189) @ StorageDead
    goto -&gt; bb100 @ Goto
}
bb 162 {
CleanUp: false
    Assign((_305, discriminant(_247))) @ _305=discriminant(_247) @ Discriminant
    StorageDead(_252) @ StorageDead
    StorageDead(_249) @ StorageDead
    Assign((_293, const false)) @ _293=const false @ Use
    StorageDead(_247) @ StorageDead
    StorageDead(_131) @ StorageDead
    StorageDead(_130) @ StorageDead
    goto -&gt; bb140 @ Goto
}
bb 163 {
CleanUp: false
    drop(_3) -&gt; [return: bb151, unwind: bb160] @ Drop
}
bb 164 {
CleanUp: true
    Assign((_307, discriminant(_247))) @ _307=discriminant(_247) @ Discriminant
    goto -&gt; bb167 @ Goto
}
bb 165 {
CleanUp: true
    Assign((_308, discriminant(_189))) @ _308=discriminant(_189) @ Discriminant
    goto -&gt; bb167 @ Goto
}
bb 166 {
CleanUp: true
    drop(_120) -&gt; [return: bb158, unwind terminate(cleanup)] @ Drop
}
bb 167 {
CleanUp: true
    switchInt(copy _295) -&gt; [0: bb158, otherwise: bb166] @ SwitchInt
}
bb 168 {
CleanUp: true
    drop(_71) -&gt; [return: bb173, unwind terminate(cleanup)] @ Drop
}
bb 169 {
CleanUp: true
    switchInt(copy _296) -&gt; [0: bb173, otherwise: bb168] @ SwitchInt
}
bb 170 {
CleanUp: true
    drop(_27) -&gt; [return: bb173, unwind terminate(cleanup)] @ Drop
}
bb 171 {
CleanUp: true
    switchInt(copy _297) -&gt; [0: bb173, otherwise: bb170] @ SwitchInt
}
bb 172 {
CleanUp: true
    drop(_12) -&gt; [return: bb159, unwind terminate(cleanup)] @ Drop
}
bb 173 {
CleanUp: true
    switchInt(copy _298) -&gt; [0: bb159, otherwise: bb172] @ SwitchInt
}
bb 174 {
CleanUp: true
    Assign((_309, discriminant(_5))) @ _309=discriminant(_5) @ Discriminant
    goto -&gt; bb176 @ Goto
}
bb 175 {
CleanUp: true
    drop(_3) -&gt; [return: bb160, unwind terminate(cleanup)] @ Drop
}
bb 176 {
CleanUp: true
    switchInt(copy _294) -&gt; [0: bb160, otherwise: bb175] @ SwitchInt
}

</div>
                </div>
            
        </div>

        
    </div>
    <script>
    function copyText(id) {
        const text = document.getElementById(id).innerText;
        navigator.clipboard.writeText(text).then(() => {
            alert('Copied!');
        });
    }
    </script>
</body>
</html>
